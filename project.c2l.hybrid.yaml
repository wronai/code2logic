header:
  project: code2logic
  files: 53
  lines: 21903
  kb: 748.4
  languages:
    python: 53
  modules_count: 53
M:
- llm_profiler.py:490:20.4kb
- config.py:168:7.4kb
- file_formats.py:278:12.3kb
- project_reproducer.py:318:12.2kb
- base.py:49:1.8kb
- cli.py:801:34.5kb
- llm.py:375:14.5kb
- errors.py:371:13.6kb
- code_review.py:205:9.0kb
- analyzer.py:235:9.6kb
- quality.py:212:8.8kb
- shared_utils.py:279:11.6kb
- parsers.py:1584:76.8kb
- intent.py:429:20.5kb
- adaptive.py:473:19.9kb
- reproducer.py:533:22.0kb
- llm_clients.py:167:6.4kb
- prompts.py:120:4.0kb
- chunked_reproduction.py:355:14.0kb
- __init__.py:323:7.7kb
- metrics.py:446:22.7kb
- __main__.py:12:0.3kb
- refactor.py:308:11.2kb
- logicml.py:281:12.8kb
- function_logic.py:209:9.3kb
- utils.py:16:0.6kb
- generators.py:1763:85.7kb
- markdown_format.py:265:13.8kb
- models.py:296:10.6kb
- llm_clients_new.py:0
- similarity.py:178:7.8kb
- universal.py:829:39.6kb
- benchmark.py:349:14.3kb
- terminal.py:496:21.6kb
- toon_format.py:540:29.7kb
- dependency.py:187:7.5kb
- mcp_server.py:291:12.1kb
- reproduction.py:333:15.3kb
- gherkin.py:764:35.3kb
- schemas/logicml_schema.py:184:6.5kb
- schemas/__init__.py:25:0.7kb
- schemas/yaml_schema.py:164:6.7kb
- schemas/json_schema.py:206:7.2kb
- schemas/markdown_schema.py:118:4.0kb
- benchmarks/common.py:206:8.5kb
- benchmarks/runner.py:633:27.0kb
- benchmarks/__init__.py:19:0.4kb
- benchmarks/results.py:148:6.3kb
- core/__init__.py:20:0.7kb
- formats/__init__.py:27:1.2kb
- tools/__init__.py:21:1.0kb
- llm/__init__.py:28:0.8kb
- integrations/__init__.py:5:0.2kb
modules:
- p: llm_profiler.py
  l: 490
  kb: 20.4
  i:
  - json
  - time
  - hashlib
  - datetime
  - dataclasses.{asdict,dataclass,field}
  - difflib.SequenceMatcher
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  - utils.estimate_tokens
  e:
  - PROFILE_TEST_CASES
  - LLMProfile
  - ProfileTestResult
  - load_profiles
  - save_profile
  - get_profile
  - get_or_create_profile
  - LLMProfiler
  - AdaptiveChunker
  - profile_llm
  const:
  - n: PROFILE_TEST_CASES
    t: Dict
    keys:
    - simple_function
    - "\ndef calculate_sum(numbers: List[int]) -> int:\n    \"\"\"Calculate sum of numbers.\"\"\"\n    return sum(numbers)\n"
    - ",\n    "
    - ': '
  c:
  - n: LLMProfile
    d: Profile of LLM capabilities for code reproduction.
    dec:
    - dataclass
    fields:
    - n: provider
      t: str
    - n: model
      t: str
    - n: profile_id
      t: str
      default: '""'
    - n: created_at
      t: str
      default: '""'
    - n: effective_context
      t: int
      default: '4000'
    - n: max_output
      t: int
      default: '2000'
    - n: optimal_chunk_size
      t: int
      default: '1500'
    - n: syntax_accuracy
      t: float
      default: '0.0'
    - n: semantic_accuracy
      t: float
      default: '0.0'
    - n: type_hint_accuracy
      t: float
      default: '0.0'
    - n: docstring_accuracy
      t: float
      default: '0.0'
    - n: output_consistency
      t: float
      default: '0.0'
    - n: temperature_sensitivity
      t: float
      default: '0.0'
    - n: hallucination_rate
      t: float
      default: '0.0'
    - n: omission_rate
      t: float
      default: '0.0'
    - n: rewrite_rate
      t: float
      default: '0.0'
    - n: supports_patch_mode
      t: bool
      default: 'False'
    - n: supports_streaming
      t: bool
      default: 'True'
    - n: preferred_format
      t: str
      default: '"yaml"'
    - n: recommended_formats
      t: List[str]
      factory: 'lambda: ["yaml"'
    - n: chunk_strategy
      t: str
      default: '"by_function"'
    - n: test_results
      t: Dict[str, Any]
      factory: dict
    attrs:
    - n: provider
      t: str
    - n: model
      t: str
    - n: profile_id
      t: str
    - n: created_at
      t: str
    - n: effective_context
      t: int
    - n: max_output
      t: int
    - n: optimal_chunk_size
      t: int
    - n: syntax_accuracy
      t: float
    - n: semantic_accuracy
      t: float
    - n: type_hint_accuracy
      t: float
    m:
    - n: __post_init__
      sig: ()
      d: creates init
  - n: ProfileTestResult
    d: Result of a single profile test.
    dec:
    - dataclass
    fields:
    - n: test_name
      t: str
    - n: original_code
      t: str
    - n: reproduced_code
      t: str
    - n: syntax_ok
      t: bool
    - n: similarity
      t: float
    - n: time_seconds
      t: float
    - n: tokens_in
      t: int
    - n: tokens_out
      t: int
    - n: error
      t: str
      default: '""'
    attrs:
    - n: test_name
      t: str
    - n: original_code
      t: str
    - n: reproduced_code
      t: str
    - n: syntax_ok
      t: bool
    - n: similarity
      t: float
    - n: time_seconds
      t: float
    - n: tokens_in
      t: int
    - n: tokens_out
      t: int
    - n: error
      t: str
  - n: LLMProfiler
    d: Profile LLM capabilities for code reproduction.
    attrs:
    - n: client
    - n: verbose
    - n: provider
    - n: model
    m:
    - n: __init__
      sig: (client,verbose:bool=True)
      d: creates
    - n: run_profile
      sig: (quick:bool=False)
      ret: LLMProfile
      d: starts profile
    - n: _test_reproduction
      sig: (name:str,code:str)
      ret: ProfileTestResult
      d: checks reproduction
    - n: _code_to_spec
      sig: (code:str)
      ret: str
      d: code to spec
    - n: _extract_code
      sig: (response:str)
      ret: str
      d: parses code
    - n: _check_syntax
      sig: (code:str)
      ret: bool
      d: checks syntax
    - n: _calculate_similarity
      sig: (original:str,reproduced:str)
      ret: float
      d: processes similarity
    - n: _calculate_metrics
      sig: (profile:LLMProfile,results:List[ProfileTestResult])
      ret: LLMProfile
      d: processes metrics
    - n: _test_consistency
      sig: (profile:LLMProfile)
      ret: LLMProfile
      d: checks consistency
  - n: AdaptiveChunker
    d: Adaptive chunking based on LLM profile.
    attrs:
    - n: profile
    m:
    - n: __init__
      sig: (profile:Optional[LLMProfile]=None)
      d: creates
    - n: get_optimal_settings
      sig: ()
      ret: Dict[str, Any]
      d: retrieves optimal settings
    - n: chunk_spec
      sig: (spec:str,format:str='yaml')
      ret: List[Dict[str, Any]]
      d: chunk spec
    - n: recommend_format
      sig: (spec_size_tokens:int)
      ret: str
      d: recommend format
    - n: estimate_chunks_needed
      sig: (spec_size_tokens:int)
      ret: int
      d: estimate chunks needed
  f:
  - n: _get_profiles_path
    sig: ()
    ret: Path
    d: retrieves profiles path
  - n: load_profiles
    sig: ()
    ret: Dict[str, LLMProfile]
    d: retrieves profiles
  - n: save_profile
    sig: (profile:LLMProfile)
    d: caches profile
  - n: get_profile
    sig: (provider:str,model:str)
    ret: Optional[LLMProfile]
    d: retrieves profile
  - n: get_or_create_profile
    sig: (provider:str,model:str)
    ret: LLMProfile
    d: retrieves or create profile
  - n: _create_default_profile
    sig: (provider:str,model:str)
    ret: LLMProfile
    d: creates default profile
  - n: profile_llm
    sig: (client,quick:bool=False)
    ret: LLMProfile
    d: profile llm
  - n: get_adaptive_chunker
    sig: (provider:str,model:str)
    ret: AdaptiveChunker
    d: retrieves adaptive chunker
  dataclasses:
  - LLMProfile
  - ProfileTestResult
- p: config.py
  l: 168
  kb: 7.4
  i:
  - os
  - json
  - pathlib.Path
  - typing.{Any,Dict,Optional}
  e:
  - Config
  - load_env
  - get_api_key
  - get_model
  - SHELL_COMMANDS
  const:
  - n: SHELL_COMMANDS
    t: str
    v: '""" # ============================================================================= # Code2Logic API Configuration
      Co...'
  c:
  - n: Config
    d: Configuration manager for Code2Logic.
    attrs:
    - n: _config
      t: Dict
    m:
    - n: __init__
      sig: (env_file:str=None)
      d: creates
    - n: _load_env_file
      sig: (env_file:str=None)
      d: retrieves env file
    - n: _parse_env_file
      sig: (path:Path)
      d: parses env file
    - n: _load_config_file
      sig: ()
      d: retrieves config file
    - n: get_api_key
      sig: (provider:str)
      ret: Optional[str]
      d: retrieves api key
    - n: get_model
      sig: (provider:str)
      ret: str
      d: retrieves model
    - n: get_ollama_host
      sig: ()
      ret: str
      d: retrieves ollama host
    - n: get_default_provider
      sig: ()
      ret: str
      d: retrieves default provider
    - n: is_verbose
      sig: ()
      ret: bool
      d: is verbose
    - n: get_cache_dir
      sig: ()
      ret: Path
      d: retrieves cache dir
  f:
  - n: load_env
    sig: ()
    d: retrieves env
  - n: get_api_key
    sig: (provider:str)
    ret: Optional[str]
    d: retrieves api key
  - n: get_model
    sig: (provider:str)
    ret: str
    d: retrieves model
- p: file_formats.py
  l: 278
  kb: 12.3
  i:
  - json
  - pathlib.Path
  - typing.{Any,Dict}
  e:
  - generate_file_csv
  - generate_file_json
  - generate_file_yaml
  f:
  - n: generate_file_csv
    sig: (file_path:Path)
    ret: str
    d: creates file csv
  - n: generate_file_json
    sig: (file_path:Path)
    ret: str
    d: creates file json
  - n: generate_file_yaml
    sig: (file_path:Path)
    ret: str
    d: creates file yaml
  - n: _parse_file_elements
    sig: (content:str)
    ret: Dict[str, Any]
    d: parses file elements
- p: project_reproducer.py
  l: 318
  kb: 12.2
  i:
  - json
  - datetime
  - concurrent.futures.{ThreadPoolExecutor,as_completed}
  - dataclasses.{asdict,dataclass,field}
  - dotenv.load_dotenv
  - pathlib.Path
  - typing.{Dict,List,Optional,Set}
  - universal.{UniversalParser,UniversalReproducer}
  e:
  - SUPPORTED_EXTENSIONS
  - FileResult
  - ProjectResult
  - ProjectReproducer
  - reproduce_project
  const:
  - n: SUPPORTED_EXTENSIONS
    t: Dict
    keys:
    - .py
    - .js
    - .ts
    - .tsx
    - .go
    - .rs
    - .java
    - .sql
    - .cs
  c:
  - n: FileResult
    d: Result for a single file reproduction.
    dec:
    - dataclass
    fields:
    - n: file_path
      t: str
    - n: language
      t: str
    - n: source_chars
      t: int
    - n: logic_chars
      t: int
    - n: generated_chars
      t: int
    - n: compression
      t: float
    - n: similarity
      t: float
    - n: structural
      t: float
    - n: success
      t: bool
    - n: error
      t: Optional[str]
      default: None
    attrs:
    - n: file_path
      t: str
    - n: language
      t: str
    - n: source_chars
      t: int
    - n: logic_chars
      t: int
    - n: generated_chars
      t: int
    - n: compression
      t: float
    - n: similarity
      t: float
    - n: structural
      t: float
    - n: success
      t: bool
    - n: error
      t: Optional[str]
  - n: ProjectResult
    d: Result for project reproduction.
    dec:
    - dataclass
    fields:
    - n: project_path
      t: str
    - n: total_files
      t: int
    - n: successful_files
      t: int
    - n: failed_files
      t: int
    - n: total_source_chars
      t: int
    - n: total_logic_chars
      t: int
    - n: total_generated_chars
      t: int
    - n: avg_compression
      t: float
    - n: avg_similarity
      t: float
    - n: avg_structural
      t: float
    - n: files
      t: List[FileResult]
      factory: list
    - n: by_language
      t: Dict[str, Dict[str, float]]
      factory: dict
    attrs:
    - n: project_path
      t: str
    - n: total_files
      t: int
    - n: successful_files
      t: int
    - n: failed_files
      t: int
    - n: total_source_chars
      t: int
    - n: total_logic_chars
      t: int
    - n: total_generated_chars
      t: int
    - n: avg_compression
      t: float
    - n: avg_similarity
      t: float
    - n: avg_structural
      t: float
  - n: ProjectReproducer
    d: Multi-file project reproduction system.
    attrs:
    - n: client
    - n: max_workers
    - n: target_lang
    - n: use_llm
    - n: parser
    - n: reproducer
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,max_workers:int=4,target_lang:str=None,use_llm:bool=True)
      d: creates
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: retrieves client
    - n: find_source_files
      sig: (project_path:str,extensions:Set[str]=None,exclude_patterns:List[str]=None)
      ret: List[Path]
      d: retrieves source files
    - n: reproduce_file
      sig: (file_path:Path,output_dir:Path)
      ret: FileResult
      d: reproduce file
    - n: reproduce_project
      sig: (project_path:str,output_dir:str=None,parallel:bool=False)
      ret: ProjectResult
      d: reproduce project
    - n: _aggregate_results
      sig: (project_path:str,results:List[FileResult])
      ret: ProjectResult
      d: aggregate results
    - n: _save_report
      sig: (output_dir:Path,result:ProjectResult)
      d: caches report
  f:
  - n: reproduce_project
    sig: (project_path:str,output_dir:str=None,target_lang:str=None,parallel:bool=False,use_llm:bool=True)
    ret: ProjectResult
    d: reproduce project
  dataclasses:
  - FileResult
  - ProjectResult
  conditional_imports:
  - dotenv.load_dotenv
- p: base.py
  l: 49
  kb: 1.8
  i:
  - logging
  e:
  - VerboseMixin
  - BaseParser
  - BaseGenerator
  c:
  - n: VerboseMixin
    d: Mixin providing verbose logging functionality.
    attrs:
    - n: verbose
    - n: _logger
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: log
      sig: (msg:str,level:str='info')
      d: logs
    - n: debug
      sig: (msg:str)
      d: debug
    - n: info
      sig: (msg:str)
      d: info
    - n: warn
      sig: (msg:str)
      d: warn
    - n: error
      sig: (msg:str)
      d: error
  - n: BaseParser
    b:
    - VerboseMixin
    d: Base class for code parsers.
    attrs: []
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: parse
      sig: (content:str,language:str=None)
      d: parses
    - n: parse_file
      sig: (path:str)
      d: parses file
  - n: BaseGenerator
    b:
    - VerboseMixin
    d: Base class for output generators.
    attrs: []
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project,detail:str='full')
      ret: str
      d: creates
- p: cli.py
  l: 801
  kb: 34.5
  i:
  - argparse
  - os
  - sys
  - subprocess
  - time
  - json
  - signal
  - datetime
  - __version__
  e:
  - Colors
  - Logger
  - ensure_dependencies
  - main
  c:
  - n: Colors
    attrs: []
  - n: Logger
    d: Enhanced logger for CLI output.
    attrs:
    - n: verbose
    - n: debug
    - n: start_time
    - n: _step
    m:
    - n: __init__
      sig: (verbose:bool=False,debug:bool=False)
      d: creates
    - n: _elapsed
      sig: ()
      ret: str
      d: elapsed
    - n: info
      sig: (msg:str)
      d: info
    - n: success
      sig: (msg:str)
      d: success
    - n: warning
      sig: (msg:str)
      d: warning
    - n: error
      sig: (msg:str)
      d: error
    - n: step
      sig: (msg:str)
      d: step
    - n: detail
      sig: (msg:str)
      d: detail
    - n: debug_msg
      sig: (msg:str)
      d: debug msg
    - n: stats
      sig: (label:str,value)
      d: stats
  f:
  - n: ensure_dependencies
    sig: ()
    d: ensure dependencies
  - n: _get_env_file_path
    sig: ()
    ret: str
    d: retrieves env file path
  - n: _read_text_file
    sig: (path:str)
    ret: str
    d: retrieves text file
  - n: _write_text_file
    sig: (path:str,content:str)
    d: logs text file
  - n: _set_env_var
    sig: (var_name:str,value:str)
    ret: str
    d: updates env var
  - n: _unset_env_var
    sig: (var_name:str)
    ret: str
    d: unset env var
  - n: _get_litellm_config_path
    sig: ()
    ret: str
    d: retrieves litellm config path
  - n: _get_user_llm_config_path
    sig: ()
    ret: str
    d: retrieves user llm config path
  - n: _load_user_llm_config
    sig: ()
    ret: dict
    d: retrieves user llm config
  - n: _save_user_llm_config
    sig: (data:dict)
    ret: str
    d: caches user llm config
  - n: _load_litellm_yaml
    sig: ()
    ret: dict
    d: retrieves litellm yaml
  - n: _save_litellm_yaml
    sig: (data:dict)
    ret: str
    d: caches litellm yaml
- p: llm.py
  l: 375
  kb: 14.5
  i:
  - json
  - os
  - httpx
  - dataclasses.dataclass
  - litellm.completion
  - llm_clients.{LiteLLMClient,OllamaLocalClient,OpenRouterClient,get_client}
  - typing.{Any,Dict,List,Optional}
  e:
  - LLMConfig
  - OllamaClient
  - LiteLLMClient
  - CodeAnalyzer
  - get_available_backends
  c:
  - n: LLMConfig
    d: Configuration for LLM backend.
    dec:
    - dataclass
    fields:
    - n: provider
      t: str
      default: '"ollama"'
    - n: model
      t: str
      default: '"qwen2.5-coder:7b"'
    - n: base_url
      t: str
      default: '"http://localhost:11434"'
    - n: api_key
      t: Optional[str]
      default: None
    - n: timeout
      t: int
      default: '120'
    - n: temperature
      t: float
      default: '0.7'
    - n: max_tokens
      t: int
      default: '2000'
    attrs:
    - n: provider
      t: str
    - n: model
      t: str
    - n: base_url
      t: str
    - n: api_key
      t: Optional[str]
    - n: timeout
      t: int
    - n: temperature
      t: float
    - n: max_tokens
      t: int
  - n: OllamaClient
    d: Direct Ollama API client.
    attrs:
    - n: config
    - n: client
    m:
    - n: __init__
      sig: (config:LLMConfig)
      d: creates
    - n: generate
      sig: (prompt:str,system:Optional[str]=None)
      ret: str
      d: creates
    - n: chat
      sig: (messages:List[Dict[str,str]])
      ret: str
      d: chat
    - n: is_available
      sig: ()
      ret: bool
      d: is available
    - n: list_models
      sig: ()
      ret: List[str]
      d: list models
  - n: LiteLLMClient
    d: LiteLLM client for unified API access.
    attrs:
    - n: config
    m:
    - n: __init__
      sig: (config:LLMConfig)
      d: creates
    - n: generate
      sig: (prompt:str,system:Optional[str]=None)
      ret: str
      d: creates
    - n: chat
      sig: (messages:List[Dict[str,str]])
      ret: str
      d: chat
    - n: is_available
      sig: ()
      ret: bool
      d: is available
  - n: CodeAnalyzer
    d: LLM-powered code analysis for Code2Logic.
    attrs:
    - n: client
    - n: config
    m:
    - n: __init__
      sig: (model:str=None,provider:str=None,base_url:str=None,api_key:str=None)
      d: creates
    - n: is_available
      sig: ()
      ret: bool
      d: is available
    - n: suggest_refactoring
      sig: (project)
      ret: List[Dict[str, Any]]
      d: suggest refactoring
    - n: find_semantic_duplicates
      sig: (project)
      ret: List[Dict[str, Any]]
      d: retrieves semantic duplicates
    - n: generate_code
      sig: (project,target_lang:str,module_filter:Optional[str]=None)
      ret: Dict[str, str]
      d: creates code
    - n: translate_function
      sig: (name:str,signature:str,intent:str,source_lang:str,target_lang:str)
      ret: str
      d: converts function
    - n: _build_signature
      sig: (f)
      ret: str
      d: creates signature
  f:
  - n: get_available_backends
    sig: ()
    ret: Dict[str, bool]
    d: retrieves available backends
  dataclasses:
  - LLMConfig
  conditional_imports:
  - httpx
  - litellm.completion
- p: errors.py
  l: 371
  kb: 13.6
  i:
  - logging
  - dataclasses.{dataclass,field}
  - enum.Enum
  - pathlib.Path
  - typing.{Any,Callable,Dict,List,Optional}
  e:
  - ErrorSeverity
  - ErrorType
  - AnalysisError
  - AnalysisResult
  - ErrorHandler
  - create_error_handler
  c:
  - n: ErrorSeverity
    b:
    - Enum
    values:
    - WARNING="warning"
    - ERROR="error"
    - CRITICAL="critical"
    d: Error severity levels.
    attrs: []
  - n: ErrorType
    b:
    - Enum
    values:
    - FILE_NOT_FOUND="file_not_found"
    - PERMISSION_DENIED="permission_denied"
    - FILE_TOO_LARGE="file_too_large"
    - ENCODING_ERROR="encoding_error"
    - SYMLINK_LOOP="symlink_loop"
    - DISK_FULL="disk_full"
    - PATH_TOO_LONG="path_too_long"
    - SYNTAX_ERROR="syntax_error"
    - PARSE_TIMEOUT="parse_timeout"
    - UNSUPPORTED_LANGUAGE="unsupported_language"
    - BINARY_FILE="binary_file"
    - EMPTY_FILE="empty_file"
    - YAML_SERIALIZATION="yaml_serialization"
    - JSON_SERIALIZATION="json_serialization"
    - OUTPUT_WRITE_ERROR="output_write_error"
    - MEMORY_ERROR="memory_error"
    - TIMEOUT="timeout"
    - UNKNOWN="unknown"
    d: Types of errors that can occur during analysis.
    attrs: []
  - n: AnalysisError
    d: Represents an error during analysis.
    dec:
    - dataclass
    fields:
    - n: type
      t: ErrorType
    - n: severity
      t: ErrorSeverity
    - n: path
      t: str
    - n: message
      t: str
    - n: exception
      t: Optional[str]
      default: None
    - n: suggestion
      t: str
      default: '""'
    attrs:
    - n: type
      t: ErrorType
    - n: severity
      t: ErrorSeverity
    - n: path
      t: str
    - n: message
      t: str
    - n: exception
      t: Optional[str]
    - n: suggestion
      t: str
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: AnalysisResult
    d: Result of analysis with errors tracked.
    dec:
    - dataclass
    fields:
    - n: success
      t: bool
      default: 'True'
    - n: errors
      t: List[AnalysisError]
      factory: list
    - n: warnings
      t: List[AnalysisError]
      factory: list
    - n: skipped_files
      t: List[str]
      factory: list
    - n: processed_files
      t: int
      default: '0'
    - n: total_files
      t: int
      default: '0'
    attrs:
    - n: success
      t: bool
    - n: errors
      t: List[AnalysisError]
    - n: warnings
      t: List[AnalysisError]
    - n: skipped_files
      t: List[str]
    - n: processed_files
      t: int
    - n: total_files
      t: int
    m:
    - n: add_error
      sig: (error:AnalysisError)
      d: creates error
    - n: has_errors
      sig: ()
      ret: bool
      d: has errors
    - n: summary
      sig: ()
      ret: str
      d: summary
  - n: ErrorHandler
    d: Handles errors during analysis with configurable behavior.
    attrs:
    - n: mode
    - n: max_file_size
    - n: timeout
    - n: logger
    - n: result
    m:
    - n: __init__
      sig: (mode:str='lenient',max_file_size_mb:float=10.0,timeout_seconds:float=30.0,logger:Optional[Any]=None)
      d: creates
    - n: reset
      sig: ()
      d: reset
    - n: handle_error
      sig: (error_type:ErrorType,path:str,message:str,exception:Optional[Exception]=None,severity:Optional[ErrorSeverity]=None)
      ret: bool
      d: handles error
    - n: _default_severity
      sig: (error_type:ErrorType)
      ret: ErrorSeverity
      d: default severity
    - n: _log_error
      sig: (error:AnalysisError)
      d: logs error
    - n: safe_read_file
      sig: (path:Path)
      ret: Optional[str]
      d: safe read file
    - n: safe_write_file
      sig: (path:Path,content:str)
      ret: bool
      d: safe write file
    - n: safe_parse
      sig: (path:str,content:str,parser_func:Callable)
      ret: Any
      d: safe parse
  f:
  - n: create_error_handler
    sig: (mode:str='lenient',max_file_size_mb:float=10.0)
    ret: ErrorHandler
    d: creates error handler
  dataclasses:
  - AnalysisError
  - AnalysisResult
- p: code_review.py
  l: 205
  kb: 9.0
  i:
  - collections.defaultdict
  - typing.{Any,Dict,List}
  e:
  - SECURITY_PATTERNS
  - PERFORMANCE_PATTERNS
  - COMPLEXITY_HIGH
  - COMPLEXITY_MEDIUM
  - LINES_MAX
  - FILE_LINES_MAX
  - analyze_code_quality
  - check_security_issues
  - check_performance_issues
  - CodeReviewer
  const:
  - n: SECURITY_PATTERNS
    t: Dict
    keys:
    - sql_injection
    - execute
    - raw
    - cursor.execute
    - command_injection
    - os.system
    - subprocess.call
    - eval
    - exec
    - path_traversal
  - n: PERFORMANCE_PATTERNS
    t: Dict
    keys:
    - n_plus_one
    - 'for.*in.*:'
    - .all()
    - .filter(
    - large_memory
    - readlines()
    - list(
    - .to_list()
    - blocking_io
    - requests.get
  - n: COMPLEXITY_HIGH
    t: int
    v: '15'
  - n: COMPLEXITY_MEDIUM
    t: int
    v: '10'
  - n: LINES_MAX
    t: int
    v: '50'
  - n: FILE_LINES_MAX
    t: int
    v: '500'
  c:
  - n: CodeReviewer
    d: Automated code review with optional LLM enhancement.
    attrs:
    - n: client
    m:
    - n: __init__
      sig: (client=None)
      d: creates
    - n: review
      sig: (project,focus:str='all')
      ret: Dict[str, Any]
      d: review
    - n: generate_report
      sig: (results:Dict[str,Any],project_name:str='Project')
      ret: str
      d: creates report
  f:
  - n: analyze_code_quality
    sig: (project)
    ret: Dict[str, List[Dict]]
    d: processes code quality
  - n: check_security_issues
    sig: (project)
    ret: Dict[str, List[Dict]]
    d: checks security issues
  - n: check_performance_issues
    sig: (project)
    ret: Dict[str, List[Dict]]
    d: checks performance issues
- p: analyzer.py
  l: 235
  kb: 9.6
  i:
  - sys
  - datetime
  - collections.defaultdict
  - dependency.{DependencyAnalyzer,NETWORKX_AVAILABLE}
  - models.{ModuleInfo,ProjectInfo}
  - parsers.{TREE_SITTER_AVAILABLE,TreeSitterParser,UniversalParser}
  - pathlib.Path
  - similarity.{RAPIDFUZZ_AVAILABLE,SimilarityDetector}
  - typing.{Dict,List}
  e:
  - ProjectAnalyzer
  - analyze_project
  - get_library_status
  c:
  - n: ProjectAnalyzer
    d: Main class for analyzing software projects.
    attrs:
    - n: root_path
    - n: verbose
    - n: include_private
    - n: modules
      t: List
    - n: languages
    - n: ts_parser
    - n: fallback_parser
    - n: dep_analyzer
    - n: sim_detector
    m:
    - n: __init__
      sig: (root_path:str,use_treesitter:bool=True,verbose:bool=False,include_private:bool=False)
      d: creates
    - n: _print_status
      sig: ()
      d: logs status
    - n: analyze
      sig: ()
      ret: ProjectInfo
      d: processes
    - n: _scan_files
      sig: ()
      d: scan files
    - n: _detect_entrypoints
      sig: ()
      ret: List[str]
      d: detect entrypoints
    - n: get_statistics
      sig: ()
      ret: Dict
      d: retrieves statistics
  f:
  - n: analyze_project
    sig: (path:str,use_treesitter:bool=True,verbose:bool=False)
    ret: ProjectInfo
    d: processes project
  - n: get_library_status
    sig: ()
    ret: Dict[str, bool]
    d: retrieves library status
- p: quality.py
  l: 212
  kb: 8.8
  i:
  - dataclasses.{dataclass,field}
  - models.{ModuleInfo,ProjectInfo}
  - typing.{Any,Dict,List}
  e:
  - QualityIssue
  - QualityReport
  - QualityAnalyzer
  - analyze_quality
  - get_quality_summary
  c:
  - n: QualityIssue
    d: Represents a code quality issue.
    dec:
    - dataclass
    fields:
    - n: type
      t: str
    - n: severity
      t: str
    - n: file
      t: str
    - n: name
      t: str
    - n: value
      t: int
    - n: threshold
      t: int
    - n: recommendation
      t: str
    attrs:
    - n: type
      t: str
    - n: severity
      t: str
    - n: file
      t: str
    - n: name
      t: str
    - n: value
      t: int
    - n: threshold
      t: int
    - n: recommendation
      t: str
  - n: QualityReport
    d: Complete quality analysis report.
    dec:
    - dataclass
    fields:
    - n: issues
      t: List[QualityIssue]
      factory: list
    - n: metrics
      t: Dict[str, Any]
      factory: dict
    - n: score
      t: float
      default: '100.0'
    attrs:
    - n: issues
      t: List[QualityIssue]
    - n: metrics
      t: Dict[str, Any]
    - n: score
      t: float
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: QualityAnalyzer
    d: Analyzes code quality and generates recommendations.
    attrs:
    - n: thresholds
    m:
    - n: __init__
      sig: (thresholds:Dict[str,int]=None)
      d: creates
    - n: analyze
      sig: (project:ProjectInfo)
      ret: QualityReport
      d: processes
    - n: analyze_modules
      sig: (modules:List[ModuleInfo])
      ret: QualityReport
      d: processes modules
    - n: _analyze_module
      sig: (module:ModuleInfo,report:QualityReport)
      d: processes module
    - n: _check_function
      sig: (func,file_path:str,report:QualityReport)
      d: checks function
    - n: _check_class
      sig: (file_path:str,report:QualityReport)
      d: checks class
    - n: _get_file_recommendation
      sig: (module:ModuleInfo)
      ret: str
      d: retrieves file recommendation
  f:
  - n: analyze_quality
    sig: (project:ProjectInfo,thresholds:Dict[str,int]=None)
    ret: QualityReport
    d: processes quality
  - n: get_quality_summary
    sig: (report:QualityReport)
    ret: str
    d: retrieves quality summary
  dataclasses:
  - QualityIssue
  - QualityReport
- p: shared_utils.py
  l: 279
  kb: 11.6
  i:
  - hashlib
  - re
  - typing.{Dict,List,Optional,Set}
  e:
  - compact_imports
  - deduplicate_imports
  - TYPE_ABBREVIATIONS
  - abbreviate_type
  - expand_type
  - build_signature
  - remove_self_from_params
  - CATEGORY_PATTERNS
  - categorize_function
  - DOMAIN_KEYWORDS
  const:
  - n: TYPE_ABBREVIATIONS
    t: Dict
    keys:
    - str
    - s
    - int
    - i
    - bool
    - b
    - float
    - f
    - None
    - N
  - n: CATEGORY_PATTERNS
    t: Dict
    keys:
    - read
    - get
    - fetch
    - find
    - load
    - read
    - query
    - retrieve
    - list
    - create
  - n: DOMAIN_KEYWORDS
    t: List
    v: '[     ''auth'', ''user'', ''order'', ''payment'', ''product'', ''cart'',     ''config'', ''util'', ''api'', ''service'',
      ''model'', ''contro...'
  f:
  - n: compact_imports
    sig: (imports:List[str],max_items:int=10)
    ret: List[str]
    d: compact imports
  - n: deduplicate_imports
    sig: (imports:List[str])
    ret: List[str]
    d: deduplicate imports
  - n: abbreviate_type
    sig: (type_str:str)
    ret: str
    d: abbreviate type
  - n: expand_type
    sig: (abbrev:str)
    ret: str
    d: expand type
  - n: build_signature
    sig: (params:List[str],return_type:Optional[str]=None,include_self:bool=False,abbreviate:bool=False,max_params:int=6)
    ret: str
    d: creates signature
  - n: remove_self_from_params
    sig: (params:List[str])
    ret: List[str]
    d: deletes self from params
  - n: categorize_function
    sig: (name:str)
    ret: str
    d: categorize function
  - n: extract_domain
    sig: (path:str)
    ret: str
    d: parses domain
  - n: compute_hash
    sig: (name:str,signature:str,length:int=8)
    ret: str
    d: processes hash
  - n: truncate_docstring
    sig: (docstring:Optional[str],max_length:int=60)
    ret: str
    d: truncate docstring
  - n: escape_for_yaml
    sig: (text:str)
    ret: str
    d: escape for yaml
  - n: clean_identifier
    sig: (name:str)
    ret: str
    d: clean identifier
- p: parsers.py
  l: 1584
  kb: 76.8
  i:
  - ast
  - re
  - textwrap
  - tree_sitter_python
  - tree_sitter_javascript
  - intent.EnhancedIntentGenerator
  - models
  - typing.{List,Optional}
  e:
  - TREE_SITTER_AVAILABLE
  - TreeSitterParser
  - UniversalParser
  - is_tree_sitter_available
  const:
  - n: TREE_SITTER_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: _PyFunctionBodyAnalyzer
    b:
    - ast.NodeVisitor
    attrs:
    - n: calls
      t: List
    - n: raises
      t: List
    - n: complexity
    - n: _seen_calls
    - n: _seen_raises
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: _add_call
      sig: (name:str)
      d: creates call
    - n: _add_raise
      sig: (name:str)
      d: creates raise
    - n: visit_Call
      sig: (node)
      d: visit call
    - n: visit_Raise
      sig: (node)
      d: visit raise
    - n: visit_If
      sig: (node)
      d: visit if
    - n: visit_For
      sig: (node)
      d: visit for
    - n: visit_AsyncFor
      sig: (node)
      d: visit asyncfor
    - n: visit_While
      sig: (node)
      d: visit while
    - n: visit_IfExp
      sig: (node)
      d: visit ifexp
  - n: TreeSitterParser
    d: Parser using Tree-sitter for high-accuracy AST parsing.
    attrs:
    - n: parsers
      t: Dict
    - n: languages
      t: Dict
    - n: intent_gen
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: _init_parsers
      sig: ()
      d: creates parsers
    - n: is_available
      sig: (language:str)
      ret: bool
      d: is available
    - n: get_supported_languages
      sig: ()
      ret: List[str]
      dec:
      - classmethod
      d: retrieves supported languages
      classmethod: true
    - n: parse
      sig: (filepath:str,content:str,language:str)
      ret: Optional[ModuleInfo]
      d: parses
    - n: _parse_python
      sig: (filepath:str,content:str,tree)
      ret: ModuleInfo
      d: parses python
    - n: _extract_constants
      sig: (tree,content:str)
      ret: List[ConstantInfo]
      d: parses constants
    - n: _extract_type_checking_imports
      sig: (tree,content:str)
      ret: List[str]
      d: parses type checking imports
    - n: _extract_conditional_imports
      sig: (node,content:str)
      ret: List[str]
      d: parses conditional imports
    - n: _extract_aliases
      sig: (tree,content:str)
      ret: dict
      d: parses aliases
  - n: UniversalParser
    d: Fallback parser using Python AST and regex.
    attrs:
    - n: intent_gen
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: parse
      sig: (filepath:str,content:str,language:str)
      ret: Optional[ModuleInfo]
      d: parses
    - n: _parse_python
      sig: (filepath:str,content:str)
      ret: Optional[ModuleInfo]
      d: parses python
    - n: _extract_ast_enum
      sig: (node:Any)
      ret: Optional[TypeInfo]
      d: parses ast enum
    - n: _extract_ast_function
      sig: (node)
      ret: FunctionInfo
      d: parses ast function
    - n: _extract_ast_class
      sig: (node:Any)
      ret: ClassInfo
      d: parses ast class
    - n: _extract_ast_constant
      sig: (node:Any,content:str)
      ret: Optional[ConstantInfo]
      d: parses ast constant
    - n: _format_ast_value
      sig: (value_node:Any,content:str)
      ret: str
      d: formats ast value
    - n: _ann_str
      sig: (node)
      ret: str
      d: ann str
    - n: _parse_js_ts
      sig: (filepath:str,content:str,language:str)
      ret: ModuleInfo
      d: parses js ts
  f:
  - n: _normalize_import_path
    sig: (import_path:str)
    ret: str
    d: normalize import path
  - n: _clean_imports
    sig: (imports:List[str])
    ret: List[str]
    d: clean imports
  - n: _combine_import_name
    sig: (module_name:str,identifier:str)
    ret: str
    d: merges import name
  - n: _truncate_constant_value
    sig: (value_text:str,limit:int=400)
    ret: str
    d: truncate constant value
  - n: _py_expr_to_dotted_name
    sig: (expr)
    ret: str
    d: py expr to dotted name
  - n: _analyze_python_function_node
    sig: (func_node)
    d: processes python function node
  - n: is_tree_sitter_available
    sig: ()
    ret: bool
    d: is tree sitter available
  conditional_imports:
  - tree_sitter_python
  - tree_sitter_javascript
  - tree_sitter.Language
  - tree_sitter.Parser
- p: intent.py
  l: 429
  kb: 20.5
  i:
  - re
  - spacy
  - dataclasses.{dataclass,field}
  - enum.{Enum,auto}
  - nltk.stem.WordNetLemmatizer
  - typing.{Any,List,Optional,TYPE_CHECKING}
  e:
  - IntentType
  - Intent
  - EnhancedIntentGenerator
  - IntentAnalyzer
  c:
  - n: IntentType
    b:
    - Enum
    values:
    - REFACTOR=auto()
    - ANALYZE=auto()
    - OPTIMIZE=auto()
    - DEBUG=auto()
    - DOCUMENT=auto()
    - TEST=auto()
    d: Types of user intents for code analysis.
    attrs: []
  - n: Intent
    d: Represents a detected user intent.
    dec:
    - dataclass
    fields:
    - n: type
      t: IntentType
    - n: confidence
      t: float
    - n: target
      t: str
    - n: description
      t: str
    - n: suggestions
      t: List[str]
      factory: list
    attrs:
    - n: type
      t: IntentType
    - n: confidence
      t: float
    - n: target
      t: str
    - n: description
      t: str
    - n: suggestions
      t: List[str]
  - n: EnhancedIntentGenerator
    d: Generator intencji z NLP - lemmatyzacja, ekstrakcja z docstringÃ³w.
    attrs:
    - n: lang
    - n: lemmatizer
    - n: nlp
    m:
    - n: __init__
      sig: (lang:str='en')
      d: creates
    - n: generate
      sig: (name:str,docstring:Optional[str]=None)
      ret: str
      d: creates
    - n: _extract_from_docstring
      sig: (docstring:str)
      ret: Optional[str]
      d: parses from docstring
    - n: _split_name
      sig: (name:str)
      ret: List[str]
      d: splits name
    - n: get_available_features
      sig: ()
      ret: dict[str, bool]
      dec:
      - classmethod
      d: retrieves available features
      classmethod: true
  - n: IntentAnalyzer
    d: Analyzes user queries to detect intent and provide suggestions.
    attrs:
    - n: intent_patterns
    - n: code_smell_patterns
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: _extract_keywords
      sig: (query:str)
      ret: List[str]
      d: parses keywords
    - n: _calculate_intent_confidence
      sig: (keywords:List[str],patterns:List[str])
      ret: float
      d: processes intent confidence
    - n: _identify_target
      sig: (query:str,project:Any)
      ret: str
      d: identify target
    - n: _generate_description
      sig: (intent_type:IntentType,target:str)
      ret: str
      d: creates description
    - n: _generate_suggestions
      sig: (intent_type:IntentType,target:str,project:Any)
      ret: List[str]
      d: creates suggestions
    - n: analyze_intent
      sig: (query:str,project:Any)
      ret: List[Intent]
      d: processes intent
    - n: detect_code_smells
      sig: (project:Any)
      ret: List[dict]
      d: detect code smells
    - n: suggest_refactoring
      sig: (target:str,project:Any)
      ret: List[str]
      d: suggest refactoring
    - n: _find_target_object
      sig: (target:str,project:Any)
      ret: Any
      d: retrieves target object
  dataclasses:
  - Intent
  conditional_imports:
  - nltk
  - nltk.stem.WordNetLemmatizer
  - spacy
- p: adaptive.py
  l: 473
  kb: 19.9
  i:
  - dataclasses.dataclass
  - dotenv.load_dotenv
  - file_formats.{generate_file_csv,generate_file_json,generate_file_yaml}
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - reproduction.{compare_code,extract_code_block,generate_file_gherkin}
  - typing.{Any,Dict,List}
  e:
  - LLM_CAPABILITIES
  - ChunkInfo
  - AdaptiveResult
  - AdaptiveReproducer
  - get_llm_capabilities
  const:
  - n: LLM_CAPABILITIES
    t: Dict
    keys:
    - qwen/qwen-2.5-coder-32b-instruct
    - context_size
    - code_quality
    - best_formats
    - gherkin
    - yaml
    - json
    - max_output
    - supports_chunking
    - nvidia/nemotron-3-nano-30b-a3b:free
  c:
  - n: ChunkInfo
    d: Information about a code chunk.
    dec:
    - dataclass
    fields:
    - n: index
      t: int
    - n: total
      t: int
    - n: content
      t: str
    - n: element_type
      t: str
    - n: element_name
      t: str
    attrs:
    - n: index
      t: int
    - n: total
      t: int
    - n: content
      t: str
    - n: element_type
      t: str
    - n: element_name
      t: str
  - n: AdaptiveResult
    d: Result of adaptive reproduction.
    dec:
    - dataclass
    fields:
    - n: source_file
      t: str
    - n: source_chars
      t: int
    - n: format_used
      t: str
    - n: chunks_used
      t: int
    - n: spec_chars
      t: int
    - n: generated_chars
      t: int
    - n: similarity
      t: float
    - n: structural_score
      t: float
    - n: compression_ratio
      t: float
    - n: efficiency_score
      t: float
    attrs:
    - n: source_file
      t: str
    - n: source_chars
      t: int
    - n: format_used
      t: str
    - n: chunks_used
      t: int
    - n: spec_chars
      t: int
    - n: generated_chars
      t: int
    - n: similarity
      t: float
    - n: structural_score
      t: float
    - n: compression_ratio
      t: float
    - n: efficiency_score
      t: float
  - n: AdaptiveReproducer
    d: Adaptive code reproduction with LLM capability detection.
    attrs:
    - n: client
    - n: model
    - n: capabilities
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,model:str=None)
      d: creates
    - n: _get_capabilities
      sig: ()
      ret: Dict[str, Any]
      d: retrieves capabilities
    - n: select_format
      sig: (file_path:Path,content:str)
      ret: str
      d: retrieves format
    - n: should_chunk
      sig: (content:str)
      ret: bool
      d: checks chunk
    - n: chunk_content
      sig: (content:str,file_path:Path)
      ret: List[ChunkInfo]
      d: chunk content
    - n: generate_chunk_spec
      sig: (chunk:ChunkInfo,format_name:str)
      ret: str
      d: creates chunk spec
    - n: _gherkin_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: gherkin for chunk
    - n: _yaml_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: yaml for chunk
    - n: _json_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: json for chunk
    - n: reproduce
      sig: (file_path:str,output_dir:str=None)
      ret: AdaptiveResult
      d: reproduce
  f:
  - n: get_llm_capabilities
    sig: (model:str)
    ret: Dict[str, Any]
    d: retrieves llm capabilities
  dataclasses:
  - ChunkInfo
  - AdaptiveResult
  conditional_imports:
  - dotenv.load_dotenv
- p: reproducer.py
  l: 533
  kb: 22.0
  i:
  - yaml
  - json
  - re
  - dataclasses.{dataclass,field}
  - enum.Enum
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  e:
  - ReproductionStatus
  - FileValidation
  - ReproductionResult
  - SpecReproducer
  - SpecValidator
  - reproduce_project
  - validate_files
  c:
  - n: ReproductionStatus
    b:
    - Enum
    values:
    - SUCCESS="success"
    - PARTIAL="partial"
    - FAILED="failed"
    - SKIPPED="skipped"
    d: Status of file reproduction.
    attrs: []
  - n: FileValidation
    d: Validation result for a single file.
    dec:
    - dataclass
    fields:
    - n: path
      t: str
    - n: exists
      t: bool
      default: 'False'
    - n: syntax_ok
      t: bool
      default: 'False'
    - n: structure_match
      t: bool
      default: 'False'
    - n: classes_match
      t: int
      default: '0'
    - n: classes_expected
      t: int
      default: '0'
    - n: functions_match
      t: int
      default: '0'
    - n: functions_expected
      t: int
      default: '0'
    - n: errors
      t: List[str]
      factory: list
    attrs:
    - n: path
      t: str
    - n: exists
      t: bool
    - n: syntax_ok
      t: bool
    - n: structure_match
      t: bool
    - n: classes_match
      t: int
    - n: classes_expected
      t: int
    - n: functions_match
      t: int
    - n: functions_expected
      t: int
    - n: errors
      t: List[str]
    m:
    - n: score
      sig: ()
      ret: float
      dec:
      - property
      d: score
      property: true
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: ReproductionResult
    d: Result of reproduction process.
    dec:
    - dataclass
    fields:
    - n: output_dir
      t: str
    - n: total_files
      t: int
      default: '0'
    - n: generated_files
      t: int
      default: '0'
    - n: failed_files
      t: int
      default: '0'
    - n: skipped_files
      t: int
      default: '0'
    - n: validations
      t: List[FileValidation]
      factory: list
    - n: errors
      t: List[str]
      factory: list
    attrs:
    - n: output_dir
      t: str
    - n: total_files
      t: int
    - n: generated_files
      t: int
    - n: failed_files
      t: int
    - n: skipped_files
      t: int
    - n: validations
      t: List[FileValidation]
    - n: errors
      t: List[str]
    m:
    - n: success_rate
      sig: ()
      ret: float
      dec:
      - property
      d: success rate
      property: true
    - n: average_score
      sig: ()
      ret: float
      dec:
      - property
      d: average score
      property: true
    - n: summary
      sig: ()
      ret: str
      d: summary
  - n: SpecReproducer
    d: Reproduces code structure from logic specifications.
    attrs:
    - n: verbose
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: reproduce_from_yaml
      sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce from yaml
    - n: reproduce_from_json
      sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce from json
    - n: _reproduce
      sig: (spec:Dict[str,Any],output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce
    - n: _generate_file
      sig: (module:Dict[str,Any],output_path:Path)
      ret: bool
      d: creates file
    - n: _generate_python
      sig: (module:Dict[str,Any])
      ret: str
      d: creates python
    - n: _render_docstring
      sig: (text:str,indent:str)
      ret: List[str]
      d: formats docstring
    - n: _sanitize_python_property
      sig: (prop:str)
      ret: str
      d: sanitize python property
    - n: _generate_python_class
      sig: (cls:Dict[str,Any])
      ret: List[str]
      d: creates python class
    - n: _generate_python_method
      sig: (method:Dict[str,Any])
      ret: List[str]
      d: creates python method
  - n: SpecValidator
    d: Validates generated files against logic specification.
    attrs: []
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: validate
      sig: (spec_path:str,generated_dir:str,filter_paths:Optional[List[str]]=None)
      ret: List[FileValidation]
      d: validates
    - n: _validate_file
      sig: (module:Dict[str,Any],base_path:Path)
      ret: FileValidation
      d: validates file
    - n: _check_python_syntax
      sig: (content:str,validation:FileValidation)
      ret: bool
      d: checks python syntax
  f:
  - n: reproduce_project
    sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None,validate:bool=True,verbose:bool=True)
    ret: ReproductionResult
    d: reproduce project
  - n: validate_files
    sig: (spec_path:str,generated_dir:str,filter_paths:Optional[List[str]]=None)
    ret: List[FileValidation]
    d: validates files
  dataclasses:
  - FileValidation
  - ReproductionResult
- p: llm_clients.py
  l: 167
  kb: 6.4
  i:
  - os
  - json
  - lolm
  - typing.Optional
  e:
  - get_priority_mode
  - get_effective_provider_priorities
  aliases:
    OllamaLocalClient: OllamaClient
    _get_provider_priorities_from_litellm_yaml: get_provider_priorities_from_litellm
  f:
  - n: _get_user_llm_config_path
    sig: ()
    ret: str
    d: retrieves user llm config path
  - n: _load_user_llm_config
    sig: ()
    ret: Dict[str, Any]
    d: retrieves user llm config
  - n: _get_priority_mode
    sig: ()
    ret: str
    d: retrieves priority mode
  - n: get_priority_mode
    sig: ()
    ret: str
    d: retrieves priority mode
  - n: _get_provider_priority_overrides
    sig: ()
    ret: Dict[str, int]
    d: retrieves provider priority overrides
  - n: _get_model_priority_rules
    sig: ()
    ret: Dict[str, Dict[str, int]]
    d: retrieves model priority rules
  - n: _get_model_priority
    sig: (model_string:str)
    ret: Optional[int]
    d: retrieves model priority
  - n: _get_provider_model_string
    sig: (provider:str)
    ret: str
    d: retrieves provider model string
  - n: _get_priority_order
    sig: ()
    ret: List[str]
    d: retrieves priority order
  - n: _get_effective_provider_order
    sig: ()
    ret: List[tuple]
    d: retrieves effective provider order
  - n: get_effective_provider_priorities
    sig: ()
    ret: Dict[str, int]
    d: retrieves effective provider priorities
  - n: _candidate_litellm_yaml_paths
    sig: ()
    ret: List[str]
    d: candidate litellm yaml paths
  conditional_imports:
  - yaml
- p: prompts.py
  l: 120
  kb: 4.0
  i:
  - typing.Dict
  e:
  - FORMAT_HINTS
  - get_reproduction_prompt
  - get_review_prompt
  - get_fix_prompt
  const:
  - n: FORMAT_HINTS
    t: Dict
    keys:
    - yaml
    - modules
    - classes
    - methods
    - attrs
    - functions
    - signature
    - intent
    - logicml
    - 'sig: (params) -> Type'
  f:
  - n: get_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str,language:str='python',max_spec_length:int=5000)
    ret: str
    d: retrieves reproduction prompt
  - n: get_review_prompt
    sig: (code:str,spec:str,fmt:str)
    ret: str
    d: retrieves review prompt
  - n: get_fix_prompt
    sig: (code:str,issues:list,spec:str)
    ret: str
    d: retrieves fix prompt
- p: chunked_reproduction.py
  l: 355
  kb: 14.0
  i:
  - re
  - dataclasses.dataclass
  - typing.List
  - utils.estimate_tokens
  e:
  - LLM_CONTEXT_LIMITS
  - Chunk
  - ChunkedSpec
  - ChunkedResult
  - get_llm_limit
  - chunk_yaml_spec
  - chunk_gherkin_spec
  - chunk_markdown_spec
  - chunk_spec
  - get_chunk_prompt
  const:
  - n: LLM_CONTEXT_LIMITS
    t: Dict
    keys:
    - gpt-4
    - gpt-4-turbo
    - gpt-3.5-turbo
    - claude-3
    - claude-2
    - llama-7b
    - llama-13b
    - llama-70b
    - mistral-7b
    - mixtral-8x7b
  c:
  - n: Chunk
    d: A chunk of specification for reproduction.
    dec:
    - dataclass
    fields:
    - n: id
      t: int
    - n: content
      t: str
    - n: tokens
      t: int
    - n: elements
      t: List[str]
    - n: dependencies
      t: List[str]
    attrs:
    - n: id
      t: int
    - n: content
      t: str
    - n: tokens
      t: int
    - n: elements
      t: List[str]
    - n: dependencies
      t: List[str]
  - n: ChunkedSpec
    d: Chunked specification.
    dec:
    - dataclass
    fields:
    - n: chunks
      t: List[Chunk]
    - n: total_tokens
      t: int
    - n: format
      t: str
    - n: file_name
      t: str
    attrs:
    - n: chunks
      t: List[Chunk]
    - n: total_tokens
      t: int
    - n: format
      t: str
    - n: file_name
      t: str
  - n: ChunkedResult
    d: Result of chunked reproduction.
    dec:
    - dataclass
    fields:
    - n: file_name
      t: str
    - n: chunks_total
      t: int
    - n: chunks_success
      t: int
    - n: merged_code
      t: str
    - n: chunk_codes
      t: List[str]
    - n: errors
      t: List[str]
    attrs:
    - n: file_name
      t: str
    - n: chunks_total
      t: int
    - n: chunks_success
      t: int
    - n: merged_code
      t: str
    - n: chunk_codes
      t: List[str]
    - n: errors
      t: List[str]
  - n: ChunkedReproducer
    d: Reproduce code from chunked specifications.
    attrs:
    - n: client
    - n: model_name
    - n: max_tokens
    m:
    - n: __init__
      sig: (client,model_name:str='default')
      d: creates
    - n: reproduce
      sig: (spec:str,fmt:str,file_name:str)
      ret: ChunkedResult
      d: reproduce
    - n: _extract_code
      sig: (response:str)
      ret: str
      d: parses code
  f:
  - n: get_llm_limit
    sig: (model_name:str)
    ret: int
    d: retrieves llm limit
  - n: chunk_yaml_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: chunk yaml spec
  - n: chunk_gherkin_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: chunk gherkin spec
  - n: chunk_markdown_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: chunk markdown spec
  - n: chunk_spec
    sig: (spec:str,fmt:str,max_tokens:int=2000)
    ret: ChunkedSpec
    d: chunk spec
  - n: get_chunk_prompt
    sig: (chunk:Chunk,fmt:str,file_name:str,chunk_num:int,total_chunks:int)
    ret: str
    d: retrieves chunk prompt
  - n: merge_chunk_codes
    sig: (codes:List[str],file_name:str)
    ret: str
    d: merges chunk codes
  - n: auto_chunk_reproduce
    sig: (spec:str,fmt:str,file_name:str,client,model_name:str='default')
    ret: ChunkedResult
    d: auto chunk reproduce
  - n: adaptive_chunk_reproduce
    sig: (spec:str,fmt:str,file_name:str,...+1,provider:str='unknown',model:str='unknown')
    ret: ChunkedResult
    d: adaptive chunk reproduce
  dataclasses:
  - Chunk
  - ChunkedSpec
  - ChunkedResult
- p: __init__.py
  l: 323
  kb: 7.7
  i:
  - analyzer.{ProjectAnalyzer,analyze_project}
  - generators.{CSVGenerator,CompactGenerator,JSONGenerator,MarkdownGenerator,YAMLGenerator}
  - gherkin.{GherkinGenerator,StepDefinitionGenerator}
  - models
  e:
  - analyze_quality
  - reproduce_project
  aliases:
    _reproduce_project_from_source: reproduce_project
    _analyze_quality_from_path: analyze_quality
    _analyze_quality_from_project: analyze_quality
    SpecReproductionResult: ReproductionResult
    _reproduce_project_from_spec: reproduce_project
  f:
  - n: analyze_quality
    sig: (target)
    d: processes quality
  - n: reproduce_project
    sig: (source:str)
    d: reproduce project
- p: metrics.py
  l: 446
  kb: 22.7
  i:
  - re
  - difflib
  - logging
  - collections.Counter
  - dataclasses.{asdict,dataclass,field}
  - typing.{Any,Dict,List,Tuple}
  e:
  - TextMetrics
  - StructuralMetrics
  - SemanticMetrics
  - FormatMetrics
  - ReproductionResult
  - ReproductionMetrics
  - analyze_reproduction
  - compare_formats
  c:
  - n: TextMetrics
    d: Text-level similarity metrics.
    dec:
    - dataclass
    fields:
    - n: char_similarity
      t: float
      default: '0.0'
    - n: line_similarity
      t: float
      default: '0.0'
    - n: word_similarity
      t: float
      default: '0.0'
    - n: levenshtein_ratio
      t: float
      default: '0.0'
    - n: jaccard_similarity
      t: float
      default: '0.0'
    - n: cosine_similarity
      t: float
      default: '0.0'
    - n: diff_added
      t: int
      default: '0'
    - n: diff_removed
      t: int
      default: '0'
    - n: diff_changed
      t: int
      default: '0'
    attrs:
    - n: char_similarity
      t: float
    - n: line_similarity
      t: float
    - n: word_similarity
      t: float
    - n: levenshtein_ratio
      t: float
    - n: jaccard_similarity
      t: float
    - n: cosine_similarity
      t: float
    - n: diff_added
      t: int
    - n: diff_removed
      t: int
    - n: diff_changed
      t: int
  - n: StructuralMetrics
    d: Structural code metrics.
    dec:
    - dataclass
    fields:
    - n: classes_original
      t: int
      default: '0'
    - n: classes_generated
      t: int
      default: '0'
    - n: classes_match
      t: bool
      default: 'False'
    - n: functions_original
      t: int
      default: '0'
    - n: functions_generated
      t: int
      default: '0'
    - n: functions_match
      t: bool
      default: 'False'
    - n: methods_original
      t: int
      default: '0'
    - n: methods_generated
      t: int
      default: '0'
    - n: methods_match
      t: bool
      default: 'False'
    - n: imports_original
      t: int
      default: '0'
    - n: imports_generated
      t: int
      default: '0'
    - n: imports_match
      t: bool
      default: 'False'
    - n: attributes_original
      t: int
      default: '0'
    - n: attributes_generated
      t: int
      default: '0'
    - n: attributes_match
      t: bool
      default: 'False'
    - n: structural_score
      t: float
      default: '0.0'
    - n: element_coverage
      t: float
      default: '0.0'
    attrs:
    - n: classes_original
      t: int
    - n: classes_generated
      t: int
    - n: classes_match
      t: bool
    - n: functions_original
      t: int
    - n: functions_generated
      t: int
    - n: functions_match
      t: bool
    - n: methods_original
      t: int
    - n: methods_generated
      t: int
    - n: methods_match
      t: bool
    - n: imports_original
      t: int
  - n: SemanticMetrics
    d: Semantic preservation metrics.
    dec:
    - dataclass
    fields:
    - n: naming_similarity
      t: float
      default: '0.0'
    - n: docstring_present
      t: float
      default: '0.0'
    - n: type_hints_present
      t: float
      default: '0.0'
    - n: decorator_match
      t: float
      default: '0.0'
    - n: signature_match
      t: float
      default: '0.0'
    - n: intent_score
      t: float
      default: '0.0'
    attrs:
    - n: naming_similarity
      t: float
    - n: docstring_present
      t: float
    - n: type_hints_present
      t: float
    - n: decorator_match
      t: float
    - n: signature_match
      t: float
    - n: intent_score
      t: float
  - n: FormatMetrics
    d: Format-specific efficiency metrics.
    dec:
    - dataclass
    fields:
    - n: format_name
      t: str
      default: '""'
    - n: spec_chars
      t: int
      default: '0'
    - n: spec_lines
      t: int
      default: '0'
    - n: spec_tokens
      t: int
      default: '0'
    - n: original_chars
      t: int
      default: '0'
    - n: generated_chars
      t: int
      default: '0'
    - n: compression_ratio
      t: float
      default: '0.0'
    - n: expansion_ratio
      t: float
      default: '0.0'
    - n: efficiency_score
      t: float
      default: '0.0'
    - n: token_cost_estimate
      t: float
      default: '0.0'
    attrs:
    - n: format_name
      t: str
    - n: spec_chars
      t: int
    - n: spec_lines
      t: int
    - n: spec_tokens
      t: int
    - n: original_chars
      t: int
    - n: generated_chars
      t: int
    - n: compression_ratio
      t: float
    - n: expansion_ratio
      t: float
    - n: efficiency_score
      t: float
    - n: token_cost_estimate
      t: float
  - n: ReproductionResult
    d: Complete reproduction analysis result.
    dec:
    - dataclass
    fields:
    - n: source_file
      t: str
      default: '""'
    - n: format_used
      t: str
      default: '""'
    - n: timestamp
      t: str
      default: '""'
    - n: text
      t: TextMetrics
      factory: TextMetrics
    - n: structural
      t: StructuralMetrics
      factory: StructuralMetrics
    - n: semantic
      t: SemanticMetrics
      factory: SemanticMetrics
    - n: format
      t: FormatMetrics
      factory: FormatMetrics
    - n: overall_score
      t: float
      default: '0.0'
    - n: quality_grade
      t: str
      default: '""'
    - n: recommendations
      t: List[str]
      factory: list
    attrs:
    - n: source_file
      t: str
    - n: format_used
      t: str
    - n: timestamp
      t: str
    - n: text
      t: TextMetrics
    - n: structural
      t: StructuralMetrics
    - n: semantic
      t: SemanticMetrics
    - n: format
      t: FormatMetrics
    - n: overall_score
      t: float
    - n: quality_grade
      t: str
    - n: recommendations
      t: List[str]
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
    - n: to_report
      sig: ()
      ret: str
      d: converts report
  - n: ReproductionMetrics
    d: Analyze reproduction quality with multiple metrics.
    attrs:
    - n: verbose
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: analyze
      sig: (original:str,generated:str,spec:str='',format_name:str='',source_file:str='')
      ret: ReproductionResult
      d: processes
    - n: _compute_text_metrics
      sig: (original:str,generated:str)
      ret: TextMetrics
      d: processes text metrics
    - n: _cosine_similarity
      sig: (words1:List[str],words2:List[str])
      ret: float
      d: cosine similarity
    - n: _compute_structural_metrics
      sig: (original:str,generated:str)
      ret: StructuralMetrics
      d: processes structural metrics
    - n: _compute_semantic_metrics
      sig: (original:str,generated:str)
      ret: SemanticMetrics
      d: processes semantic metrics
    - n: _compute_format_metrics
      sig: (original:str,generated:str,spec:str,format_name:str)
      ret: FormatMetrics
      d: processes format metrics
    - n: _compute_overall_score
      sig: (result:ReproductionResult)
      ret: float
      d: processes overall score
    - n: _get_grade
      sig: (score:float)
      ret: str
      d: retrieves grade
    - n: _generate_recommendations
      sig: (result:ReproductionResult)
      ret: List[str]
      d: creates recommendations
  f:
  - n: analyze_reproduction
    sig: (original:str,generated:str,spec:str='',format_name:str='',verbose:bool=False)
    ret: ReproductionResult
    d: processes reproduction
  - n: compare_formats
    sig: (original:str,results:Dict[str,Tuple[str,str]],verbose:bool=False)
    ret: Dict[str, Any]
    d: compare formats
  dataclasses:
  - TextMetrics
  - StructuralMetrics
  - SemanticMetrics
- p: __main__.py
  l: 12
  kb: 0.3
  i:
  - cli.main
  conditional_imports:
  - cli.main
- p: refactor.py
  l: 308
  kb: 11.2
  i:
  - analyzer.analyze_project
  - code_review.{analyze_code_quality,check_security_issues}
  - dataclasses.{asdict,dataclass,field}
  - llm_clients.{BaseLLMClient,get_client}
  - typing.{Any,Dict,List}
  e:
  - DuplicateGroup
  - RefactoringSuggestion
  - RefactoringReport
  - find_duplicates
  - analyze_quality
  - suggest_refactoring
  - compare_codebases
  - quick_analyze
  c:
  - n: DuplicateGroup
    d: Group of duplicate functions.
    dec:
    - dataclass
    fields:
    - n: hash
      t: str
    - n: functions
      t: List[str]
    - n: suggestion
      t: str
    - n: effort
      t: str
      default: '"low"'
    attrs:
    - n: hash
      t: str
    - n: functions
      t: List[str]
    - n: suggestion
      t: str
    - n: effort
      t: str
  - n: RefactoringSuggestion
    d: Single refactoring suggestion.
    dec:
    - dataclass
    fields:
    - n: type
      t: str
    - n: severity
      t: str
    - n: location
      t: str
    - n: description
      t: str
    - n: suggestion
      t: str
    - n: effort
      t: str
    attrs:
    - n: type
      t: str
    - n: severity
      t: str
    - n: location
      t: str
    - n: description
      t: str
    - n: suggestion
      t: str
    - n: effort
      t: str
  - n: RefactoringReport
    d: Complete refactoring analysis report.
    dec:
    - dataclass
    fields:
    - n: project_path
      t: str
    - n: total_files
      t: int
    - n: total_functions
      t: int
    - n: duplicates
      t: List[DuplicateGroup]
      factory: list
    - n: quality_issues
      t: List[RefactoringSuggestion]
      factory: list
    - n: security_issues
      t: List[RefactoringSuggestion]
      factory: list
    - n: suggestions
      t: List[RefactoringSuggestion]
      factory: list
    attrs:
    - n: project_path
      t: str
    - n: total_files
      t: int
    - n: total_functions
      t: int
    - n: duplicates
      t: List[DuplicateGroup]
    - n: quality_issues
      t: List[RefactoringSuggestion]
    - n: security_issues
      t: List[RefactoringSuggestion]
    - n: suggestions
      t: List[RefactoringSuggestion]
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
    - n: to_markdown
      sig: ()
      ret: str
      d: converts markdown
  f:
  - n: find_duplicates
    sig: (project_path:str,threshold:float=0.8)
    ret: List[DuplicateGroup]
    d: retrieves duplicates
  - n: analyze_quality
    sig: (project_path:str,include_security:bool=True,include_performance:bool=True)
    ret: RefactoringReport
    d: processes quality
  - n: suggest_refactoring
    sig: (project_path:str,use_llm:bool=False,client:BaseLLMClient=None)
    ret: RefactoringReport
    d: suggest refactoring
  - n: compare_codebases
    sig: (project1:str,project2:str)
    ret: Dict[str, Any]
    d: compare codebases
  - n: quick_analyze
    sig: (project_path:str)
    ret: Dict[str, Any]
    d: quick analyze
  dataclasses:
  - DuplicateGroup
  - RefactoringSuggestion
  - RefactoringReport
- p: logicml.py
  l: 281
  kb: 12.8
  i:
  - dataclasses.dataclass
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo}
  - pathlib.Path
  - shared_utils.{compact_imports,remove_self_from_params,truncate_docstring}
  - typing.{Dict,List,Optional,Set}
  e:
  - LogicMLSpec
  - LogicMLGenerator
  - generate_logicml
  - LOGICML_EXAMPLE
  const:
  - n: LOGICML_EXAMPLE
    t: str
    v: ''''''' # sample_class.py | Calculator | 74 lines  imports:   stdlib: [typing.List, typing.Optional]  Calculator:   doc:
      ...'
  c:
  - n: LogicMLSpec
    d: LogicML specification output.
    dec:
    - dataclass
    fields:
    - n: content
      t: str
    - n: token_estimate
      t: int
    - n: file_count
      t: int
    - n: class_count
      t: int
    - n: function_count
      t: int
    attrs:
    - n: content
      t: str
    - n: token_estimate
      t: int
    - n: file_count
      t: int
    - n: class_count
      t: int
    - n: function_count
      t: int
  - n: LogicMLGenerator
    d: Generates LogicML format - optimized for LLM code reproduction.
    attrs:
    - n: verbose
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: LogicMLSpec
      d: creates
    - n: _generate_module
      sig: (module:ModuleInfo,detail:str)
      ret: str
      d: creates module
    - n: _generate_imports
      sig: (imports:List[str])
      ret: str
      d: creates imports
    - n: _generate_class
      sig: (cls:ClassInfo,detail:str)
      ret: str
      d: creates class
    - n: _generate_method
      sig: (method:FunctionInfo,detail:str,indent:int=2)
      ret: str
      d: creates method
    - n: _generate_functions
      sig: (functions:List[FunctionInfo],detail:str)
      ret: str
      d: creates functions
    - n: _detect_side_effects
      sig: (method:FunctionInfo)
      ret: Optional[str]
      d: detect side effects
  f:
  - n: generate_logicml
    sig: (project:ProjectInfo,detail:str='standard')
    ret: str
    d: creates logicml
  dataclasses:
  - LogicMLSpec
- p: function_logic.py
  l: 209
  kb: 9.3
  i:
  - models.{FunctionInfo,ProjectInfo}
  - shared_utils.{remove_self_from_params,truncate_docstring}
  - toon_format.TOONGenerator
  - typing.{List,Tuple}
  e:
  - FunctionLogicGenerator
  c:
  - n: FunctionLogicGenerator
    attrs:
    - n: verbose
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='full')
      ret: str
      d: creates
    - n: generate_json
      sig: (project:ProjectInfo,detail:str='full')
      ret: str
      d: creates json
    - n: generate_yaml
      sig: (project:ProjectInfo,detail:str='full')
      ret: str
      d: creates yaml
    - n: generate_toon
      sig: (project:ProjectInfo,detail:str='full')
      ret: str
      d: creates toon
    - n: _build_data
      sig: (project:ProjectInfo,detail:str)
      ret: dict
      d: creates data
    - n: _module_items
      sig: (module)
      ret: List[Tuple[str, str, FunctionInfo]]
      d: module items
    - n: _build_sig
      sig: (func:FunctionInfo,include_async_prefix:bool=True)
      ret: str
      d: creates sig
    - n: _build_loc
      sig: (func:FunctionInfo)
      ret: str
      d: creates loc
    - n: _build_does
      sig: (func:FunctionInfo)
      ret: str
      d: creates does
- p: utils.py
  l: 16
  kb: 0.6
  i:
  - shutil
  - pathlib.Path
  e:
  - estimate_tokens
  - write_text_atomic
  - cleanup_generated_root
  f:
  - n: estimate_tokens
    sig: (text:str)
    ret: int
    d: estimate tokens
  - n: write_text_atomic
    sig: (path:Path,content:str)
    d: logs text atomic
  - n: cleanup_generated_root
    sig: (generated_root:Path,allowed_dirs:set[str])
    d: cleanup generated root
- p: generators.py
  l: 1763
  kb: 85.7
  i:
  - json
  - collections.defaultdict
  - models
  - pathlib.Path
  - shared_utils.{categorize_function,compute_hash,extract_domain,remove_self_from_params}
  - typing.{List,Optional}
  e:
  - bytes_to_kb
  - MarkdownGenerator
  - CompactGenerator
  - JSONGenerator
  - YAMLGenerator
  - CSVGenerator
  c:
  - n: MarkdownGenerator
    d: Generates Markdown output for project analysis.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo,detail_level:str='standard')
      ret: str
      d: creates
    - n: _gen_tree
      sig: (lines:List[str],project:ProjectInfo)
      d: gen tree
    - n: _print_tree
      sig: (lines:List[str],tree:dict,prefix:str,depth:int=0)
      d: logs tree
    - n: _gen_module
      sig: (lines:List[str],m:ModuleInfo,detail:str,proj:ProjectInfo)
      d: gen module
    - n: _gen_class
      sig: (lines:List[str],cls:ClassInfo,detail:str)
      d: gen class
    - n: _sig
      sig: (f:FunctionInfo)
      ret: str
      d: sig
  - n: CompactGenerator
    d: Generates ultra-compact output for token efficiency.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo)
      ret: str
      d: creates
  - n: JSONGenerator
    d: Generates JSON output for machine processing.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo,flat:bool=False,detail:str='standard')
      ret: str
      d: creates
    - n: generate_from_module
      sig: (module:ModuleInfo,detail:str='full')
      ret: str
      d: creates from module
    - n: _generate_nested
      sig: (project:ProjectInfo,detail:str)
      ret: str
      d: creates nested
    - n: _field_to_dict
      sig: (field:FieldInfo)
      ret: dict
      d: field to dict
    - n: _generate_flat
      sig: (project:ProjectInfo,detail:str)
      ret: str
      d: creates flat
    - n: _build_element_row
      sig: (m:ModuleInfo,elem_type:str,name:str,signature:str,f:FunctionInfo,...+2)
      ret: dict
      d: creates element row
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _compute_hash
      sig: (name:str,signature:str)
      ret: str
      d: processes hash
  - n: YAMLGenerator
    d: Generates YAML output for human-readable representation.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo,flat:bool=False,detail:str='standard',compact:bool=True)
      ret: str
      d: creates
    - n: generate_schema
      sig: (format_type:str='compact')
      ret: str
      d: creates schema
    - n: _generate_compact_schema
      sig: ()
      ret: str
      d: creates compact schema
    - n: _generate_full_schema
      sig: ()
      ret: str
      d: creates full schema
    - n: _generate_hybrid_schema
      sig: ()
      ret: str
      d: creates hybrid schema
    - n: generate_hybrid
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates hybrid
    - n: _build_enhanced_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates enhanced signature
    - n: _extract_constants
      sig: (module:ModuleInfo)
      ret: list
      d: parses constants
    - n: _extract_dataclasses
      sig: (module:ModuleInfo)
      ret: list
      d: parses dataclasses
    - n: _extract_conditional_imports
      sig: (module:ModuleInfo)
      ret: list
      d: parses conditional imports
  - n: CSVGenerator
    d: Generates CSV output optimized for LLM processing.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _build_row
      sig: (m:ModuleInfo,elem_type:str,name:str,signature:str,calls:list,...+2)
      ret: dict
      d: creates row
    - n: _build_function_row
      sig: (m:ModuleInfo,elem_type:str,name:str,f:FunctionInfo,deps:str,...+2)
      ret: dict
      d: creates function row
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _compute_hash
      sig: (name:str,signature:str)
      ret: str
      d: processes hash
    - n: _escape_csv
      sig: (text:str)
      ret: str
      d: escape csv
  f:
  - n: bytes_to_kb
    sig: (bytes_value:int)
    ret: float
    d: bytes to kb
- p: markdown_format.py
  l: 265
  kb: 13.8
  i:
  - dataclasses.dataclass
  - generators.YAMLGenerator
  - gherkin.GherkinGenerator
  - models.ProjectInfo
  - pathlib.Path
  - typing.{Dict,List}
  e:
  - MarkdownSpec
  - MarkdownHybridGenerator
  - generate_markdown_hybrid
  - generate_file_markdown
  c:
  - n: MarkdownSpec
    d: Markdown specification for a project.
    dec:
    - dataclass
    fields:
    - n: content
      t: str
    - n: file_count
      t: int
    - n: total_chars
      t: int
    - n: sections
      t: Dict[str, int]
    attrs:
    - n: content
      t: str
    - n: file_count
      t: int
    - n: total_chars
      t: int
    - n: sections
      t: Dict[str, int]
  - n: MarkdownHybridGenerator
    d: Generates optimized Markdown hybrid format.
    attrs:
    - n: verbose
    - n: gherkin_gen
    - n: yaml_gen
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='full')
      ret: MarkdownSpec
      d: creates
    - n: _generate_header
      sig: (project:ProjectInfo)
      ret: str
      d: creates header
    - n: _generate_tree
      sig: (project:ProjectInfo)
      ret: str
      d: creates tree
    - n: _generate_imports
      sig: (project:ProjectInfo)
      ret: str
      d: creates imports
    - n: _generate_classes_yaml
      sig: (project:ProjectInfo)
      ret: str
      d: creates classes yaml
    - n: _generate_functions_gherkin
      sig: (project:ProjectInfo)
      ret: str
      d: creates functions gherkin
    - n: _generate_dependencies
      sig: (project:ProjectInfo)
      ret: str
      d: creates dependencies
  f:
  - n: generate_markdown_hybrid
    sig: (project:ProjectInfo,detail:str='full')
    ret: str
    d: creates markdown hybrid
  - n: generate_file_markdown
    sig: (file_path:str)
    ret: str
    d: creates file markdown
  dataclasses:
  - MarkdownSpec
- p: models.py
  l: 296
  kb: 10.6
  i:
  - dataclasses.{dataclass,field}
  - typing.{Dict,List,Optional}
  e:
  - FunctionInfo
  - ClassInfo
  - TypeInfo
  - ModuleInfo
  - DependencyNode
  - ProjectInfo
  - ConstantInfo
  - FieldInfo
  - AttributeInfo
  - PropertyInfo
  c:
  - n: FunctionInfo
    d: Information about a function or method.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: params
      t: List[str]
    - n: return_type
      t: Optional[str]
    - n: docstring
      t: Optional[str]
    - n: calls
      t: List[str]
    - n: raises
      t: List[str]
    - n: complexity
      t: int
    - n: lines
      t: int
    - n: decorators
      t: List[str]
    - n: is_async
      t: bool
    - n: is_static
      t: bool
    - n: is_private
      t: bool
    - n: intent
      t: str
    - n: start_line
      t: int
      default: '0'
    - n: end_line
      t: int
      default: '0'
    attrs:
    - n: name
      t: str
    - n: params
      t: List[str]
    - n: return_type
      t: Optional[str]
    - n: docstring
      t: Optional[str]
    - n: calls
      t: List[str]
    - n: raises
      t: List[str]
    - n: complexity
      t: int
    - n: lines
      t: int
    - n: decorators
      t: List[str]
    - n: is_async
      t: bool
  - n: ClassInfo
    d: Information about a class or interface.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: bases
      t: List[str]
    - n: docstring
      t: Optional[str]
    - n: methods
      t: List[FunctionInfo]
    - n: properties
      t: List[str]
    - n: is_interface
      t: bool
    - n: is_abstract
      t: bool
    - n: generic_params
      t: List[str]
    - n: is_dataclass
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: bases
      t: List[str]
    - n: docstring
      t: Optional[str]
    - n: methods
      t: List[FunctionInfo]
    - n: properties
      t: List[str]
    - n: is_interface
      t: bool
    - n: is_abstract
      t: bool
    - n: generic_params
      t: List[str]
    - n: is_dataclass
      t: bool
  - n: TypeInfo
    d: Information about a type alias, interface, or enum.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: kind
      t: str
    - n: definition
      t: str
    - n: values
      t: Optional[List[str]]
      default: None
    attrs:
    - n: name
      t: str
    - n: kind
      t: str
    - n: definition
      t: str
    - n: values
      t: Optional[List[str]]
  - n: ModuleInfo
    d: Information about a source file/module.
    dec:
    - dataclass
    fields:
    - n: path
      t: str
    - n: language
      t: str
    - n: imports
      t: List[str]
    - n: exports
      t: List[str]
    - n: classes
      t: List[ClassInfo]
    - n: functions
      t: List[FunctionInfo]
    - n: types
      t: List[TypeInfo]
    - n: constants
      t: List[ConstantInfo]
    - n: docstring
      t: Optional[str]
    - n: lines_total
      t: int
    - n: lines_code
      t: int
    attrs:
    - n: path
      t: str
    - n: language
      t: str
    - n: imports
      t: List[str]
    - n: exports
      t: List[str]
    - n: classes
      t: List[ClassInfo]
    - n: functions
      t: List[FunctionInfo]
    - n: types
      t: List[TypeInfo]
    - n: constants
      t: List[ConstantInfo]
    - n: docstring
      t: Optional[str]
    - n: lines_total
      t: int
  - n: DependencyNode
    d: Node in the dependency graph with metrics.
    dec:
    - dataclass
    fields:
    - n: path
      t: str
    - n: in_degree
      t: int
      default: '0'
    - n: out_degree
      t: int
      default: '0'
    - n: pagerank
      t: float
      default: '0.0'
    - n: is_hub
      t: bool
      default: 'False'
    - n: cluster
      t: int
      default: '0'
    attrs:
    - n: path
      t: str
    - n: in_degree
      t: int
    - n: out_degree
      t: int
    - n: pagerank
      t: float
    - n: is_hub
      t: bool
    - n: cluster
      t: int
  - n: ProjectInfo
    d: Complete project analysis results.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: root_path
      t: str
    - n: languages
      t: Dict[str, int]
    - n: modules
      t: List[ModuleInfo]
    - n: dependency_graph
      t: Dict[str, List[str]]
    - n: dependency_metrics
      t: Dict[str, DependencyNode]
    - n: entrypoints
      t: List[str]
    - n: similar_functions
      t: Dict[str, List[str]]
    - n: total_files
      t: int
    - n: total_lines
      t: int
    - n: total_bytes
      t: int
      default: '0'
    - n: generated_at
      t: str
      default: '""'
    attrs:
    - n: name
      t: str
    - n: root_path
      t: str
    - n: languages
      t: Dict[str, int]
    - n: modules
      t: List[ModuleInfo]
    - n: dependency_graph
      t: Dict[str, List[str]]
    - n: dependency_metrics
      t: Dict[str, DependencyNode]
    - n: entrypoints
      t: List[str]
    - n: similar_functions
      t: Dict[str, List[str]]
    - n: total_files
      t: int
    - n: total_lines
      t: int
  - n: ConstantInfo
    d: Module-level constant information.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: type_annotation
      t: str
      default: '""'
    - n: value
      t: Optional[str]
      default: None
    - n: value_keys
      t: Optional[List[str]]
      default: None
    attrs:
    - n: name
      t: str
    - n: type_annotation
      t: str
    - n: value
      t: Optional[str]
    - n: value_keys
      t: Optional[List[str]]
  - n: FieldInfo
    d: Dataclass field information.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: type_annotation
      t: str
    - n: default
      t: Optional[str]
      default: None
    - n: default_factory
      t: Optional[str]
      default: None
    attrs:
    - n: name
      t: str
    - n: type_annotation
      t: str
    - n: default
      t: Optional[str]
    - n: default_factory
      t: Optional[str]
  dataclasses:
  - FunctionInfo
  - ClassInfo
  - TypeInfo
- p: llm_clients_new.py
  l: 0
- p: similarity.py
  l: 178
  kb: 7.8
  i:
  - models.ModuleInfo
  - rapidfuzz.{fuzz,process}
  - typing.{Dict,List}
  e:
  - RAPIDFUZZ_AVAILABLE
  - SimilarityDetector
  - is_rapidfuzz_available
  - get_refactoring_suggestions
  const:
  - n: RAPIDFUZZ_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: SimilarityDetector
    d: Detects similar functions using fuzzy string matching.
    attrs:
    - n: threshold
    m:
    - n: __init__
      sig: (threshold:float=80.0)
      d: creates
    - n: find_similar_functions
      sig: (modules:List[ModuleInfo])
      ret: Dict[str, List[str]]
      d: retrieves similar functions
    - n: find_duplicate_signatures
      sig: (modules:List[ModuleInfo])
      ret: Dict[str, List[str]]
      d: retrieves duplicate signatures
    - n: _build_signature
      sig: (name:str,params:List[str],return_type:str=None)
      ret: str
      d: creates signature
  f:
  - n: is_rapidfuzz_available
    sig: ()
    ret: bool
    d: is rapidfuzz available
  - n: get_refactoring_suggestions
    sig: (similar_functions:Dict[str,List[str]])
    ret: List[Dict[str, any]]
    d: retrieves refactoring suggestions
  conditional_imports:
  - rapidfuzz.fuzz
  - rapidfuzz.process
- p: universal.py
  l: 829
  kb: 39.6
  i:
  - re
  - json
  - hashlib
  - dataclasses.{asdict,dataclass,field}
  - dotenv.load_dotenv
  - enum.Enum
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - typing.{Any,Dict,List,Union}
  e:
  - ElementType
  - Language
  - Parameter
  - CodeElement
  - CodeLogic
  - UniversalParser
  - CodeGenerator
  - UniversalReproducer
  - reproduce_file
  c:
  - n: ElementType
    b:
    - Enum
    values:
    - IMPORT="import"
    - CLASS="class"
    - INTERFACE="interface"
    - STRUCT="struct"
    - FUNCTION="function"
    - METHOD="method"
    - PROPERTY="property"
    - CONSTANT="constant"
    - TYPE_ALIAS="type_alias"
    - ENUM="enum"
    - MODULE="module"
    d: Types of code elements.
    attrs: []
  - n: Language
    b:
    - Enum
    values:
    - PYTHON="python"
    - JAVASCRIPT="javascript"
    - TYPESCRIPT="typescript"
    - GO="go"
    - RUST="rust"
    - JAVA="java"
    - CSHARP="csharp"
    - SQL="sql"
    - UNKNOWN="unknown"
    d: Supported languages.
    attrs: []
  - n: Parameter
    d: Function/method parameter.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: type
      t: str
      default: '""'
    - n: default
      t: str
      default: '""'
    - n: is_optional
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: type
      t: str
    - n: default
      t: str
    - n: is_optional
      t: bool
  - n: CodeElement
    d: Universal representation of a code element.
    dec:
    - dataclass
    fields:
    - n: type
      t: ElementType
    - n: name
      t: str
    - n: docstring
      t: str
      default: '""'
    - n: signature
      t: str
      default: '""'
    - n: parameters
      t: List[Parameter]
      factory: list
    - n: return_type
      t: str
      default: '""'
    - n: body_hash
      t: str
      default: '""'
    - n: attributes
      t: List[Dict[str, str]]
      factory: list
    - n: children
      t: List['CodeElement']
      factory: list
    - n: decorators
      t: List[str]
      factory: list
    - n: modifiers
      t: List[str]
      factory: list
    - n: extends
      t: List[str]
      factory: list
    - n: implements
      t: List[str]
      factory: list
    attrs:
    - n: type
      t: ElementType
    - n: name
      t: str
    - n: docstring
      t: str
    - n: signature
      t: str
    - n: parameters
      t: List[Parameter]
    - n: return_type
      t: str
    - n: body_hash
      t: str
    - n: attributes
      t: List[Dict[str, str]]
    - n: children
      t: List['CodeElement']
    - n: decorators
      t: List[str]
  - n: CodeLogic
    d: Universal code logic representation for a single file.
    dec:
    - dataclass
    fields:
    - n: source_file
      t: str
    - n: source_language
      t: Language
    - n: source_hash
      t: str
    - n: elements
      t: List[CodeElement]
      factory: list
    - n: imports
      t: List[str]
      factory: list
    - n: module_doc
      t: str
      default: '""'
    - n: metadata
      t: Dict[str, Any]
      factory: dict
    attrs:
    - n: source_file
      t: str
    - n: source_language
      t: Language
    - n: source_hash
      t: str
    - n: elements
      t: List[CodeElement]
    - n: imports
      t: List[str]
    - n: module_doc
      t: str
    - n: metadata
      t: Dict[str, Any]
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
    - n: _element_to_dict
      sig: (elem:CodeElement)
      ret: Dict[str, Any]
      d: element to dict
    - n: to_compact
      sig: ()
      ret: str
      d: converts compact
    - n: _element_to_compact
      sig: (elem:CodeElement,indent:int)
      ret: List[str]
      d: element to compact
  - n: UniversalParser
    d: Parse source code into universal CodeLogic format.
    attrs: []
    m:
    - n: detect_language
      sig: (content:str,file_ext:str)
      ret: Language
      d: detect language
    - n: parse
      sig: (file_path:Union[str,Path])
      ret: CodeLogic
      d: parses
    - n: _parse_python
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses python
    - n: _parse_js_ts
      sig: (path:Path,content:str,hash_:str,lang:Language)
      ret: CodeLogic
      d: parses js ts
    - n: _parse_go
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses go
    - n: _parse_sql
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses sql
    - n: _parse_generic
      sig: (path:Path,content:str,hash_:str,lang:Language)
      ret: CodeLogic
      d: parses generic
  - n: CodeGenerator
    d: Generate code from CodeLogic in target language.
    attrs: []
    m:
    - n: generate
      sig: (logic:CodeLogic,target_lang:Language)
      ret: str
      d: creates
    - n: _generate_python
      sig: (logic:CodeLogic)
      ret: str
      d: creates python
    - n: _generate_python_element
      sig: (elem:CodeElement,indent:int=0)
      ret: List[str]
      d: creates python element
    - n: _generate_typescript
      sig: (logic:CodeLogic)
      ret: str
      d: creates typescript
    - n: _generate_go
      sig: (logic:CodeLogic)
      ret: str
      d: creates go
    - n: _generate_sql
      sig: (logic:CodeLogic)
      ret: str
      d: creates sql
    - n: _generate_generic
      sig: (logic:CodeLogic,target:Language)
      ret: str
      d: creates generic
  - n: UniversalReproducer
    d: Universal code reproduction system.
    attrs:
    - n: client
    - n: parser
    - n: generator
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None)
      d: creates
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: retrieves client
    - n: extract_logic
      sig: (file_path:str)
      ret: CodeLogic
      d: parses logic
    - n: reproduce
      sig: (source_path:str,target_lang:str=None,output_dir:str=None,use_llm:bool=True)
      ret: Dict[str, Any]
      d: reproduce
    - n: _generate_with_llm
      sig: (logic:CodeLogic,target:Language)
      ret: str
      d: creates with llm
    - n: _save_result
      sig: (output_dir:Path,original:str,logic:CodeLogic,generated:str,result:Dict[str,Any])
      d: caches result
  f:
  - n: reproduce_file
    sig: (source_path:str,target_lang:str=None,output_dir:str=None,use_llm:bool=True)
    ret: Dict[str, Any]
    d: reproduce file
  dataclasses:
  - Parameter
  - CodeElement
  - CodeLogic
  conditional_imports:
  - dotenv.load_dotenv
- p: benchmark.py
  l: 349
  kb: 14.3
  i:
  - json
  - time
  - datetime
  - analyzer.analyze_project
  - dataclasses.{asdict,dataclass}
  - dotenv.load_dotenv
  - generators.{JSONGenerator,MarkdownGenerator,YAMLGenerator}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  e:
  - FormatResult
  - BenchmarkResult
  - FORMAT_PROMPTS
  - ReproductionBenchmark
  - run_benchmark
  const:
  - n: FORMAT_PROMPTS
    t: Dict
    keys:
    - gherkin
    - csv
  c:
  - n: FormatResult
    d: Result for a single format test.
    dec:
    - dataclass
    fields:
    - n: format_name
      t: str
    - n: spec_chars
      t: int
    - n: spec_tokens
      t: int
    - n: generated_chars
      t: int
    - n: similarity
      t: float
    - n: structural_score
      t: float
    - n: classes_match
      t: bool
    - n: functions_match
      t: bool
    - n: generation_time
      t: float
    - n: error
      t: Optional[str]
      default: None
    attrs:
    - n: format_name
      t: str
    - n: spec_chars
      t: int
    - n: spec_tokens
      t: int
    - n: generated_chars
      t: int
    - n: similarity
      t: float
    - n: structural_score
      t: float
    - n: classes_match
      t: bool
    - n: functions_match
      t: bool
    - n: generation_time
      t: float
    - n: error
      t: Optional[str]
  - n: BenchmarkResult
    d: Complete benchmark result.
    dec:
    - dataclass
    fields:
    - n: source_file
      t: str
    - n: source_chars
      t: int
    - n: source_classes
      t: int
    - n: source_functions
      t: int
    - n: timestamp
      t: str
    - n: model
      t: str
    - n: formats
      t: List[FormatResult]
    - n: best_format
      t: str
    - n: best_similarity
      t: float
    attrs:
    - n: source_file
      t: str
    - n: source_chars
      t: int
    - n: source_classes
      t: int
    - n: source_functions
      t: int
    - n: timestamp
      t: str
    - n: model
      t: str
    - n: formats
      t: List[FormatResult]
    - n: best_format
      t: str
    - n: best_similarity
      t: float
  - n: ReproductionBenchmark
    d: Benchmark reproduction quality across formats.
    attrs:
    - n: client
    - n: generators
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None)
      d: creates
    - n: generate_spec
      sig: (file_path:Path,format_name:str,detail:str='full')
      ret: str
      d: creates spec
    - n: reproduce_with_format
      sig: (file_path:Path,format_name:str,original_code:str)
      ret: FormatResult
      d: reproduce with format
    - n: run_single
      sig: (file_path:str,formats:List[str]=None)
      ret: BenchmarkResult
      d: starts single
    - n: run_all
      sig: (files:List[str],output_dir:str=None)
      ret: Dict[str, Any]
      d: starts all
    - n: _generate_summary
      sig: (results:List[BenchmarkResult])
      ret: Dict[str, Any]
      d: creates summary
    - n: _save_results
      sig: (output_dir:Path,results:List[BenchmarkResult],summary:Dict)
      d: caches results
    - n: _generate_report
      sig: (results:List[BenchmarkResult],summary:Dict)
      ret: str
      d: creates report
  f:
  - n: run_benchmark
    sig: (files:List[str],output_dir:str='benchmark_results',provider:str=None,model:str=None)
    ret: Dict[str, Any]
    d: starts benchmark
  dataclasses:
  - FormatResult
  - BenchmarkResult
  conditional_imports:
  - dotenv.load_dotenv
- p: terminal.py
  l: 496
  kb: 21.6
  i:
  - os
  - re
  - sys
  - typing.{Any,List,Literal,Optional}
  e:
  - COLORS
  - ShellRenderer
  - get_renderer
  - set_renderer
  - RenderAPI
  const:
  - n: COLORS
    t: Dict
    v: '{     "reset": "\033[0m",     "bold": "\033[1m",     "dim": "\033[2m",     "italic": "\033[3m",     "underline": "\03...'
  c:
  - n: ShellRenderer
    d: Renders colorized markdown output in terminal.
    attrs:
    - n: verbose
    - n: use_colors
    - n: log_buffer
      t: List
    - n: log_enabled
    m:
    - n: __init__
      sig: (use_colors:bool=True,verbose:bool=True)
      d: creates
    - n: _supports_colors
      sig: ()
      ret: bool
      d: supports colors
    - n: enable_log
      sig: ()
      d: enable log
    - n: get_log
      sig: ()
      ret: str
      d: retrieves log
    - n: clear_log
      sig: ()
      d: deletes log
    - n: _log
      sig: (text:str)
      d: logs
    - n: _c
      sig: (color:str,text:str)
      ret: str
      d: c
    - n: heading
      sig: (level:int,text:str)
      d: heading
    - n: codeblock
      sig: (language:Language,content:str)
      d: codeblock
    - n: render_markdown
      sig: (text:str)
      d: formats markdown
  - n: RenderAPI
    d: Convenience API for terminal rendering.
    attrs: []
    m:
    - n: heading
      sig: (level:int,text:str)
      dec:
      - staticmethod
      d: heading
      static: true
    - n: code
      sig: (lang:Language,content:str)
      dec:
      - staticmethod
      d: code
      static: true
    - n: codeblock
      sig: (lang:Language,content:str)
      dec:
      - staticmethod
      d: codeblock
      static: true
    - n: markdown
      sig: (text:str)
      dec:
      - staticmethod
      d: markdown
      static: true
    - n: success
      sig: (message:str)
      dec:
      - staticmethod
      d: success
      static: true
    - n: error
      sig: (message:str)
      dec:
      - staticmethod
      d: error
      static: true
    - n: warning
      sig: (message:str)
      dec:
      - staticmethod
      d: warning
      static: true
    - n: info
      sig: (message:str)
      dec:
      - staticmethod
      d: info
      static: true
    - n: status
      sig: (icon:str,message:str,type:Literal[info,success,warning,error]='info')
      dec:
      - staticmethod
      d: status
      static: true
    - n: kv
      sig: (key:str,value:Any)
      dec:
      - staticmethod
      d: kv
      static: true
  f:
  - n: get_renderer
    sig: (use_colors:bool=True,verbose:bool=True)
    ret: ShellRenderer
    d: retrieves renderer
  - n: set_renderer
    sig: (renderer:ShellRenderer)
    d: updates renderer
- p: toon_format.py
  l: 540
  kb: 29.7
  i:
  - re
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo,TypeInfo}
  - shared_utils.{compact_imports,truncate_docstring}
  - typing.{Any,Dict,List}
  e:
  - TOONGenerator
  - TOONParser
  - generate_toon
  - parse_toon
  c:
  - n: TOONGenerator
    d: Generates TOON format output from ProjectInfo.
    attrs:
    - n: delimiter
    - n: delim_marker
    m:
    - n: __init__
      sig: (delimiter:str=',',use_tabs:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _generate_modules
      sig: (modules:List[ModuleInfo],detail:str)
      ret: List[str]
      d: creates modules
    - n: _generate_types
      sig: (types:List[TypeInfo],indent:int=0)
      ret: List[str]
      d: creates types
    - n: _generate_classes
      sig: (classes:List[ClassInfo],detail:str,indent:int=0)
      ret: List[str]
      d: creates classes
    - n: _generate_methods
      sig: (methods:List[FunctionInfo],detail:str='standard',indent:int=0)
      ret: List[str]
      d: creates methods
    - n: _generate_functions
      sig: (functions:List[FunctionInfo],detail:str,indent:int=0)
      ret: List[str]
      d: creates functions
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _quote
      sig: (value:Any)
      ret: str
      d: quote
    - n: generate_compact
      sig: (project:ProjectInfo)
      ret: str
      d: creates compact
  - n: TOONParser
    d: Parse TOON format back to Python dict.
    attrs:
    - n: delimiter
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: parse
      sig: (content:str)
      ret: Dict[str, Any]
      d: parses
    - n: _parse_value
      sig: (value:str)
      ret: Any
      d: parses value
  f:
  - n: generate_toon
    sig: (project:ProjectInfo,detail:str='standard',use_tabs:bool=False)
    ret: str
    d: creates toon
  - n: parse_toon
    sig: (content:str)
    ret: Dict[str, Any]
    d: parses toon
- p: dependency.py
  l: 187
  kb: 7.5
  i:
  - networkx
  - models.{DependencyNode,ModuleInfo}
  - pathlib.Path
  - typing.{Dict,List}
  e:
  - NETWORKX_AVAILABLE
  - DependencyAnalyzer
  - is_networkx_available
  const:
  - n: NETWORKX_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: DependencyAnalyzer
    d: Analyzes dependency graphs using NetworkX.
    attrs:
    - n: graph
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: build_graph
      sig: (modules:List[ModuleInfo])
      ret: Dict[str, List[str]]
      d: creates graph
    - n: analyze_metrics
      sig: ()
      ret: Dict[str, DependencyNode]
      d: processes metrics
    - n: get_entrypoints
      sig: ()
      ret: List[str]
      d: retrieves entrypoints
    - n: get_hubs
      sig: ()
      ret: List[str]
      d: retrieves hubs
    - n: detect_cycles
      sig: ()
      ret: List[List[str]]
      d: detect cycles
    - n: get_strongly_connected_components
      sig: ()
      ret: List[List[str]]
      d: retrieves strongly connected components
    - n: _detect_clusters
      sig: ()
      ret: Dict[str, int]
      d: detect clusters
    - n: _module_name
      sig: (path:str)
      ret: str
      d: module name
    - n: get_dependency_depth
      sig: (module_path:str)
      ret: int
      d: retrieves dependency depth
  f:
  - n: is_networkx_available
    sig: ()
    ret: bool
    d: is networkx available
  conditional_imports:
  - networkx
- p: mcp_server.py
  l: 291
  kb: 12.1
  i:
  - json
  - sys
  - __version__
  e:
  - handle_request
  - call_tool
  - run_server
  f:
  - n: handle_request
    sig: (request:dict)
    ret: dict
    d: handles request
  - n: call_tool
    sig: (tool_name:str,arguments:dict)
    ret: str
    d: call tool
  - n: run_server
    sig: ()
    d: starts server
- p: reproduction.py
  l: 333
  kb: 15.3
  i:
  - re
  - difflib
  - datetime
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - typing.{Any,Dict,List}
  e:
  - generate_file_gherkin
  - compare_code
  - extract_code_block
  - CodeReproducer
  c:
  - n: CodeReproducer
    d: Code reproduction workflow using LLM.
    attrs:
    - n: client
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,provider:str=None)
      d: creates
    - n: reproduce_file
      sig: (source_path:str,output_dir:str=None)
      ret: Dict[str, Any]
      d: reproduce file
    - n: generate_from_gherkin
      sig: (gherkin:str,language:str='python')
      ret: str
      d: creates from gherkin
    - n: _save_results
      sig: (output_dir:Path,results:Dict[str,Any])
      d: caches results
    - n: _generate_report
      sig: (results:Dict[str,Any])
      ret: str
      d: creates report
  f:
  - n: generate_file_gherkin
    sig: (file_path:Path)
    ret: str
    d: creates file gherkin
  - n: compare_code
    sig: (original:str,generated:str)
    ret: Dict[str, Any]
    d: compare code
  - n: extract_code_block
    sig: (text:str,language:str='python')
    ret: str
    d: parses code block
- p: gherkin.py
  l: 764
  kb: 35.3
  i:
  - re
  - collections.defaultdict
  - dataclasses.dataclass
  - models.{FunctionInfo,ProjectInfo}
  - typing.{Any,Dict,List,Optional}
  e:
  - GherkinScenario
  - GherkinFeature
  - StepDefinition
  - GherkinGenerator
  - StepDefinitionGenerator
  - CucumberYAMLGenerator
  - csv_to_gherkin
  - gherkin_to_test_data
  c:
  - n: GherkinScenario
    d: Represents a single Gherkin scenario.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: given
      t: List[str]
    - n: when
      t: List[str]
    - n: then
      t: List[str]
    - n: tags
      t: List[str]
    - n: examples
      t: Optional[List[Dict[str, str]]]
      default: None
    - n: data_table
      t: Optional[List[Dict[str, str]]]
      default: None
    attrs:
    - n: name
      t: str
    - n: given
      t: List[str]
    - n: when
      t: List[str]
    - n: then
      t: List[str]
    - n: tags
      t: List[str]
    - n: examples
      t: Optional[List[Dict[str, str]]]
    - n: data_table
      t: Optional[List[Dict[str, str]]]
  - n: GherkinFeature
    d: Represents a Gherkin feature file.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: description
      t: str
    - n: tags
      t: List[str]
    - n: scenarios
      t: List[GherkinScenario]
    - n: background
      t: Optional[List[str]]
      default: None
    - n: rules
      t: Optional[List[Dict[str, Any]]]
      default: None
    attrs:
    - n: name
      t: str
    - n: description
      t: str
    - n: tags
      t: List[str]
    - n: scenarios
      t: List[GherkinScenario]
    - n: background
      t: Optional[List[str]]
    - n: rules
      t: Optional[List[Dict[str, Any]]]
  - n: StepDefinition
    d: Represents a step definition.
    dec:
    - dataclass
    fields:
    - n: pattern
      t: str
    - n: step_type
      t: str
    - n: function_name
      t: str
    - n: params
      t: List[str]
    - n: implementation_hint
      t: str
    attrs:
    - n: pattern
      t: str
    - n: step_type
      t: str
    - n: function_name
      t: str
    - n: params
      t: List[str]
    - n: implementation_hint
      t: str
  - n: GherkinGenerator
    d: Generates Gherkin feature files from code analysis.
    attrs:
    - n: language
    - n: keywords
    - n: _step_registry
      t: Dict
    m:
    - n: __init__
      sig: (language:str='en')
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard',group_by:str='domain')
      ret: str
      d: creates
    - n: generate_test_scenarios
      sig: (project:ProjectInfo,group_by:str='domain')
      ret: List[GherkinFeature]
      d: creates test scenarios
    - n: get_step_definitions
      sig: ()
      ret: List[StepDefinition]
      d: retrieves step definitions
    - n: _extract_features
      sig: (project:ProjectInfo,group_by:str)
      ret: List[GherkinFeature]
      d: parses features
    - n: _create_feature
      sig: (group_name:str,items:List[dict],project:ProjectInfo,group_by:str)
      ret: GherkinFeature
      d: creates feature
    - n: _create_scenario
      sig: (category:str,items:List[dict],domain:str)
      ret: GherkinScenario
      d: creates scenario
    - n: _create_edge_case_scenarios
      sig: (category:str,items:List[dict])
      ret: List[GherkinScenario]
      d: creates edge case scenarios
    - n: _create_when_step
      sig: (func:FunctionInfo,verb:str)
      ret: str
      d: creates when step
    - n: _create_background
      sig: (domain:str,items:List[dict])
      ret: Optional[List[str]]
      d: creates background
  - n: StepDefinitionGenerator
    d: Generates step definition stubs from Gherkin features.
    attrs: []
    m:
    - n: generate_pytest_bdd
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates pytest bdd
    - n: generate_behave
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates behave
    - n: generate_cucumber_js
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates cucumber js
    - n: _step_to_func_name
      sig: (step:str)
      ret: str
      d: step to func name
  - n: CucumberYAMLGenerator
    d: Generates Cucumber YAML configuration and test data.
    attrs: []
    m:
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
  f:
  - n: csv_to_gherkin
    sig: (csv_content:str,language:str='en')
    ret: str
    d: csv to gherkin
  - n: gherkin_to_test_data
    sig: (gherkin_content:str)
    ret: Dict[str, Any]
    d: gherkin to test data
  dataclasses:
  - GherkinScenario
  - GherkinFeature
  - StepDefinition
- p: schemas/logicml_schema.py
  l: 184
  kb: 6.5
  i:
  - re
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - LogicMLMethod
  - LogicMLClass
  - LogicMLModule
  - LogicMLSchema
  - validate_logicml
  - parse_logicml_header
  - extract_logicml_signature
  c:
  - n: LogicMLMethod
    d: Schema for LogicML method.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
    - n: does
      t: str
      default: '""'
    - n: edge
      t: List[str]
      factory: list
    - n: side
      t: str
      default: '""'
    - n: is_async
      t: bool
      default: 'False'
    - n: is_property
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: does
      t: str
    - n: edge
      t: List[str]
    - n: side
      t: str
    - n: is_async
      t: bool
    - n: is_property
      t: bool
  - n: LogicMLClass
    d: Schema for LogicML class.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: doc
      t: str
      default: '""'
    - n: bases
      t: List[str]
      factory: list
    - n: attrs
      t: Dict[str, str]
      factory: dict
    - n: methods
      t: List[LogicMLMethod]
      factory: list
    - n: is_pydantic
      t: bool
      default: 'False'
    - n: is_enum
      t: bool
      default: 'False'
    - n: is_dataclass
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: doc
      t: str
    - n: bases
      t: List[str]
    - n: attrs
      t: Dict[str, str]
    - n: methods
      t: List[LogicMLMethod]
    - n: is_pydantic
      t: bool
    - n: is_enum
      t: bool
    - n: is_dataclass
      t: bool
  - n: LogicMLModule
    d: Schema for LogicML module.
    dec:
    - dataclass
    fields:
    - n: filename
      t: str
    - n: lines
      t: int
      default: '0'
    - n: classes
      t: List[str]
      factory: list
    - n: imports
      t: Dict[str, List[str]]
      factory: dict
    - n: module_classes
      t: List[LogicMLClass]
      factory: list
    - n: functions
      t: List[LogicMLMethod]
      factory: list
    - n: module_type
      t: str
      default: '"standard"'
    - n: exports
      t: List[str]
      factory: list
    attrs:
    - n: filename
      t: str
    - n: lines
      t: int
    - n: classes
      t: List[str]
    - n: imports
      t: Dict[str, List[str]]
    - n: module_classes
      t: List[LogicMLClass]
    - n: functions
      t: List[LogicMLMethod]
    - n: module_type
      t: str
    - n: exports
      t: List[str]
  - n: LogicMLSchema
    d: Complete LogicML specification schema.
    dec:
    - dataclass
    fields:
    - n: modules
      t: List[LogicMLModule]
      factory: list
    - n: token_estimate
      t: int
      default: '0'
    - n: file_count
      t: int
      default: '0'
    - n: class_count
      t: int
      default: '0'
    - n: function_count
      t: int
      default: '0'
    attrs:
    - n: modules
      t: List[LogicMLModule]
    - n: token_estimate
      t: int
    - n: file_count
      t: int
    - n: class_count
      t: int
    - n: function_count
      t: int
  f:
  - n: validate_logicml
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates logicml
  - n: parse_logicml_header
    sig: (line:str)
    ret: Optional[Dict[str, Any]]
    d: parses logicml header
  - n: extract_logicml_signature
    sig: (sig_line:str)
    ret: Dict[str, Any]
    d: parses logicml signature
  dataclasses:
  - LogicMLMethod
  - LogicMLClass
  - LogicMLModule
- p: schemas/__init__.py
  l: 25
  kb: 0.7
  i:
  - json_schema.{JSONSchema,parse_json_spec,validate_json}
  - logicml_schema.{LogicMLSchema,validate_logicml}
  - markdown_schema.{MarkdownSchema,validate_markdown}
  - yaml_schema.{YAMLSchema,validate_yaml}
- p: schemas/yaml_schema.py
  l: 164
  kb: 6.7
  i:
  - yaml
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Tuple}
  e:
  - MethodSchema
  - ClassSchema
  - FunctionSchema
  - ModuleSchema
  - YAMLSchema
  - validate_yaml
  c:
  - n: MethodSchema
    d: Schema for method definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
      default: '""'
    - n: lines
      t: int
      default: '0'
    - n: is_async
      t: bool
      default: 'False'
    - n: decorators
      t: List[str]
      factory: list
    - n: raises
      t: List[str]
      factory: list
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
    - n: lines
      t: int
    - n: is_async
      t: bool
    - n: decorators
      t: List[str]
    - n: raises
      t: List[str]
  - n: ClassSchema
    d: Schema for class definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: bases
      t: List[str]
      factory: list
    - n: docstring
      t: str
      default: '""'
    - n: methods
      t: List[MethodSchema]
      factory: list
    - n: properties
      t: List[str]
      factory: list
    - n: is_abstract
      t: bool
      default: 'False'
    - n: is_dataclass
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: bases
      t: List[str]
    - n: docstring
      t: str
    - n: methods
      t: List[MethodSchema]
    - n: properties
      t: List[str]
    - n: is_abstract
      t: bool
    - n: is_dataclass
      t: bool
  - n: FunctionSchema
    d: Schema for function definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
      default: '""'
    - n: lines
      t: int
      default: '0'
    - n: is_async
      t: bool
      default: 'False'
    - n: decorators
      t: List[str]
      factory: list
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
    - n: lines
      t: int
    - n: is_async
      t: bool
    - n: decorators
      t: List[str]
  - n: ModuleSchema
    d: Schema for module definition.
    dec:
    - dataclass
    fields:
    - n: path
      t: str
    - n: language
      t: str
      default: '"python"'
    - n: lines
      t: int
      default: '0'
    - n: imports
      t: List[str]
      factory: list
    - n: exports
      t: List[str]
      factory: list
    - n: classes
      t: List[ClassSchema]
      factory: list
    - n: functions
      t: List[FunctionSchema]
      factory: list
    attrs:
    - n: path
      t: str
    - n: language
      t: str
    - n: lines
      t: int
    - n: imports
      t: List[str]
    - n: exports
      t: List[str]
    - n: classes
      t: List[ClassSchema]
    - n: functions
      t: List[FunctionSchema]
  - n: YAMLSchema
    d: Complete YAML specification schema.
    dec:
    - dataclass
    fields:
    - n: project
      t: str
    - n: statistics
      t: Dict[str, Any]
      factory: dict
    - n: modules
      t: List[ModuleSchema]
      factory: list
    attrs:
    - n: project
      t: str
    - n: statistics
      t: Dict[str, Any]
    - n: modules
      t: List[ModuleSchema]
  f:
  - n: validate_yaml
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates yaml
  - n: _validate_module
    sig: (module:Dict,index:int)
    ret: List[str]
    d: validates module
  - n: _validate_class
    sig: (cls:Dict,prefix:str)
    ret: List[str]
    d: validates class
  dataclasses:
  - MethodSchema
  - ClassSchema
  - FunctionSchema
- p: schemas/json_schema.py
  l: 206
  kb: 7.2
  i:
  - json
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - JSONMethodSchema
  - JSONClassSchema
  - JSONFunctionSchema
  - JSONModuleSchema
  - JSONSchema
  - validate_json
  - parse_json_spec
  c:
  - n: JSONMethodSchema
    d: Schema for JSON method definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
      default: '""'
    - n: intent
      t: str
      default: '""'
    - n: is_async
      t: bool
      default: 'False'
    - n: decorators
      t: List[str]
      factory: list
    - n: params
      t: List[str]
      factory: list
    - n: return_type
      t: str
      default: '"None"'
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
    - n: is_async
      t: bool
    - n: decorators
      t: List[str]
    - n: params
      t: List[str]
    - n: return_type
      t: str
  - n: JSONClassSchema
    d: Schema for JSON class definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: bases
      t: List[str]
      factory: list
    - n: docstring
      t: str
      default: '""'
    - n: methods
      t: List[JSONMethodSchema]
      factory: list
    - n: properties
      t: Dict[str, str]
      factory: dict
    - n: is_abstract
      t: bool
      default: 'False'
    - n: is_dataclass
      t: bool
      default: 'False'
    attrs:
    - n: name
      t: str
    - n: bases
      t: List[str]
    - n: docstring
      t: str
    - n: methods
      t: List[JSONMethodSchema]
    - n: properties
      t: Dict[str, str]
    - n: is_abstract
      t: bool
    - n: is_dataclass
      t: bool
  - n: JSONFunctionSchema
    d: Schema for JSON function definition.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
      default: '""'
    - n: intent
      t: str
      default: '""'
    - n: is_async
      t: bool
      default: 'False'
    - n: params
      t: List[str]
      factory: list
    - n: return_type
      t: str
      default: '"None"'
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: intent
      t: str
    - n: is_async
      t: bool
    - n: params
      t: List[str]
    - n: return_type
      t: str
  - n: JSONModuleSchema
    d: Schema for JSON module definition.
    dec:
    - dataclass
    fields:
    - n: path
      t: str
    - n: language
      t: str
      default: '"python"'
    - n: lines
      t: int
      default: '0'
    - n: imports
      t: List[str]
      factory: list
    - n: exports
      t: List[str]
      factory: list
    - n: classes
      t: List[JSONClassSchema]
      factory: list
    - n: functions
      t: List[JSONFunctionSchema]
      factory: list
    attrs:
    - n: path
      t: str
    - n: language
      t: str
    - n: lines
      t: int
    - n: imports
      t: List[str]
    - n: exports
      t: List[str]
    - n: classes
      t: List[JSONClassSchema]
    - n: functions
      t: List[JSONFunctionSchema]
  - n: JSONSchema
    d: Complete JSON specification schema.
    dec:
    - dataclass
    fields:
    - n: project
      t: str
      default: '""'
    - n: statistics
      t: Dict[str, Any]
      factory: dict
    - n: modules
      t: List[JSONModuleSchema]
      factory: list
    attrs:
    - n: project
      t: str
    - n: statistics
      t: Dict[str, Any]
    - n: modules
      t: List[JSONModuleSchema]
  f:
  - n: validate_json
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates json
  - n: _validate_json_module
    sig: (module:Dict,index:int)
    ret: List[str]
    d: validates json module
  - n: _validate_json_class
    sig: (cls:Dict,prefix:str)
    ret: List[str]
    d: validates json class
  - n: parse_json_spec
    sig: (spec:str)
    ret: Optional[JSONSchema]
    d: parses json spec
  dataclasses:
  - JSONMethodSchema
  - JSONClassSchema
  - JSONFunctionSchema
- p: schemas/markdown_schema.py
  l: 118
  kb: 4.0
  i:
  - re
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Tuple}
  e:
  - MarkdownMethod
  - MarkdownClass
  - MarkdownModule
  - MarkdownSchema
  - validate_markdown
  - extract_markdown_sections
  c:
  - n: MarkdownMethod
    d: Schema for Markdown method.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: signature
      t: str
      default: '""'
    - n: is_async
      t: bool
      default: 'False'
    - n: gherkin_scenarios
      t: List[str]
      factory: list
    attrs:
    - n: name
      t: str
    - n: signature
      t: str
    - n: is_async
      t: bool
    - n: gherkin_scenarios
      t: List[str]
  - n: MarkdownClass
    d: Schema for Markdown class.
    dec:
    - dataclass
    fields:
    - n: name
      t: str
    - n: bases
      t: List[str]
      factory: list
    - n: attributes
      t: Dict[str, str]
      factory: dict
    - n: methods
      t: List[MarkdownMethod]
      factory: list
    attrs:
    - n: name
      t: str
    - n: bases
      t: List[str]
    - n: attributes
      t: Dict[str, str]
    - n: methods
      t: List[MarkdownMethod]
  - n: MarkdownModule
    d: Schema for Markdown module.
    dec:
    - dataclass
    fields:
    - n: filename
      t: str
    - n: language
      t: str
      default: '"python"'
    - n: lines
      t: int
      default: '0'
    - n: imports
      t: List[str]
      factory: list
    - n: classes
      t: List[MarkdownClass]
      factory: list
    - n: functions
      t: List[MarkdownMethod]
      factory: list
    attrs:
    - n: filename
      t: str
    - n: language
      t: str
    - n: lines
      t: int
    - n: imports
      t: List[str]
    - n: classes
      t: List[MarkdownClass]
    - n: functions
      t: List[MarkdownMethod]
  - n: MarkdownSchema
    d: Complete Markdown specification schema.
    dec:
    - dataclass
    fields:
    - n: modules
      t: List[MarkdownModule]
      factory: list
    - n: token_estimate
      t: int
      default: '0'
    attrs:
    - n: modules
      t: List[MarkdownModule]
    - n: token_estimate
      t: int
  f:
  - n: validate_markdown
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates markdown
  - n: extract_markdown_sections
    sig: (spec:str)
    ret: Dict[str, Any]
    d: parses markdown sections
  dataclasses:
  - MarkdownMethod
  - MarkdownClass
  - MarkdownModule
- p: benchmarks/common.py
  l: 206
  kb: 8.5
  i:
  - datetime
  - json
  - generators.{JSONGenerator,YAMLGenerator}
  - gherkin.GherkinGenerator
  - logicml.LogicMLGenerator
  - markdown_format.MarkdownHybridGenerator
  - models.ProjectInfo
  - pathlib.Path
  - toon_format.TOONGenerator
  e:
  - create_single_project
  - generate_spec
  - generate_spec_token
  - get_async_reproduction_prompt
  - get_token_reproduction_prompt
  - get_simple_reproduction_prompt
  f:
  - n: create_single_project
    sig: (module_info,file_path:Path)
    ret: ProjectInfo
    d: creates single project
  - n: generate_spec
    sig: (project:ProjectInfo,fmt:str)
    ret: str
    d: creates spec
  - n: _generate_token_json
    sig: (project:ProjectInfo)
    ret: str
    d: creates token json
  - n: _generate_token_json_compact
    sig: (project:ProjectInfo)
    ret: str
    d: creates token json compact
  - n: generate_spec_token
    sig: (project:ProjectInfo,fmt:str)
    ret: str
    d: creates spec token
  - n: get_async_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str,with_tests:bool=False)
    ret: str
    d: retrieves async reproduction prompt
  - n: get_token_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str)
    ret: str
    d: retrieves token reproduction prompt
  - n: get_simple_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str)
    ret: str
    d: retrieves simple reproduction prompt
- p: benchmarks/runner.py
  l: 633
  kb: 27.0
  i:
  - sys
  - time
  - analyzer.analyze_project
  - llm_clients.{BaseLLMClient,get_client}
  - metrics.ReproductionMetrics
  - pathlib.Path
  - results.{BenchmarkConfig,BenchmarkResult,FileResult,FunctionResult}
  - terminal.render
  - typing.{List,Optional}
  - utils.estimate_tokens
  e:
  - BenchmarkRunner
  - run_benchmark
  c:
  - n: BenchmarkRunner
    d: Unified benchmark runner for code2logic.
    attrs:
    - n: client
    - n: config
    - n: _metrics
    m:
    - n: __init__
      sig: (client:Optional[BaseLLMClient]=None,config:Optional[BenchmarkConfig]=None)
      d: creates
    - n: _should_use_llm
      sig: ()
      ret: bool
      d: checks use llm
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: retrieves client
    - n: _template_generate_code
      sig: (spec:str,fmt:str,file_name:str)
      ret: str
      d: template generate code
    - n: run_format_benchmark
      sig: (folder:str,formats:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts format benchmark
    - n: _test_format
      sig: (project,original:str,fmt:str,file_name:str,...+1,verbose:bool=False)
      ret: FormatResult
      d: checks format
    - n: run_file_benchmark
      sig: (file_path:str,formats:List[str]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts file benchmark
    - n: run_function_benchmark
      sig: (file_path:str,function_names:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts function benchmark
    - n: _test_function
      sig: (func,content:str,language:str,file_path:Path,...+1,verbose:bool=False)
      ret: FunctionResult
      d: checks function
    - n: run_project_benchmark
      sig: (project_path:str,formats:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts project benchmark
  f:
  - n: _test_python_syntax
    sig: (code:str)
    ret: bool
    d: checks python syntax
  - n: _test_python_runs
    sig: (code:str,timeout:int=5)
    ret: bool
    d: checks python runs
  - n: _extract_code
    sig: (response:str)
    ret: str
    d: parses code
  - n: run_benchmark
    sig: (source:str,...+1,formats:List[str]=None,limit:Optional[int]=None,output:Optional[str]=None,verbose:bool=False)
    ret: BenchmarkResult
    d: starts benchmark
- p: benchmarks/__init__.py
  l: 19
  kb: 0.4
  i:
  - common
  - results.{BenchmarkConfig,BenchmarkResult,FileResult,FormatResult,FunctionResult}
  - runner.{BenchmarkRunner,run_benchmark}
- p: benchmarks/results.py
  l: 148
  kb: 6.3
  i:
  - datetime
  - json
  - dataclasses.{asdict,dataclass,field}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  e:
  - FormatResult
  - FileResult
  - FunctionResult
  - BenchmarkResult
  - BenchmarkConfig
  c:
  - n: FormatResult
    d: Result for a single format test.
    dec:
    - dataclass
    fields:
    - n: format_name
      t: str
    - n: spec_size
      t: int
      default: '0'
    - n: spec_tokens
      t: int
      default: '0'
    - n: generated_size
      t: int
      default: '0'
    - n: score
      t: float
      default: '0.0'
    - n: similarity
      t: float
      default: '0.0'
    - n: syntax_ok
      t: bool
      default: 'False'
    - n: runs_ok
      t: bool
      default: 'False'
    - n: compression_ratio
      t: float
      default: '0.0'
    - n: token_efficiency
      t: float
      default: '0.0'
    - n: gen_time
      t: float
      default: '0.0'
    - n: error
      t: str
      default: '""'
    attrs:
    - n: format_name
      t: str
    - n: spec_size
      t: int
    - n: spec_tokens
      t: int
    - n: generated_size
      t: int
    - n: score
      t: float
    - n: similarity
      t: float
    - n: syntax_ok
      t: bool
    - n: runs_ok
      t: bool
    - n: compression_ratio
      t: float
    - n: token_efficiency
      t: float
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: FileResult
    d: Result for single file reproduction.
    dec:
    - dataclass
    fields:
    - n: file_path
      t: str
    - n: language
      t: str
    - n: original_size
      t: int
      default: '0'
    - n: spec_size
      t: int
      default: '0'
    - n: generated_size
      t: int
      default: '0'
    - n: score
      t: float
      default: '0.0'
    - n: similarity
      t: float
      default: '0.0'
    - n: syntax_ok
      t: bool
      default: 'False'
    - n: runs_ok
      t: bool
      default: 'False'
    - n: format_results
      t: Dict[str, FormatResult]
      factory: dict
    - n: gen_time
      t: float
      default: '0.0'
    - n: error
      t: str
      default: '""'
    attrs:
    - n: file_path
      t: str
    - n: language
      t: str
    - n: original_size
      t: int
    - n: spec_size
      t: int
    - n: generated_size
      t: int
    - n: score
      t: float
    - n: similarity
      t: float
    - n: syntax_ok
      t: bool
    - n: runs_ok
      t: bool
    - n: format_results
      t: Dict[str, FormatResult]
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: FunctionResult
    d: Result for single function reproduction.
    dec:
    - dataclass
    fields:
    - n: file_path
      t: str
    - n: function_name
      t: str
    - n: language
      t: str
    - n: original_code
      t: str
      default: '""'
    - n: reproduced_code
      t: str
      default: '""'
    - n: similarity
      t: float
      default: '0.0'
    - n: syntax_ok
      t: bool
      default: 'False'
    - n: gen_time
      t: float
      default: '0.0'
    - n: error
      t: str
      default: '""'
    attrs:
    - n: file_path
      t: str
    - n: function_name
      t: str
    - n: language
      t: str
    - n: original_code
      t: str
    - n: reproduced_code
      t: str
    - n: similarity
      t: float
    - n: syntax_ok
      t: bool
    - n: gen_time
      t: float
    - n: error
      t: str
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  - n: BenchmarkResult
    d: Complete benchmark result.
    dec:
    - dataclass
    fields:
    - n: benchmark_type
      t: str
    - n: timestamp
      t: str
      default: '""'
    - n: source_path
      t: str
      default: '""'
    - n: total_files
      t: int
      default: '0'
    - n: total_functions
      t: int
      default: '0'
    - n: avg_score
      t: float
      default: '0.0'
    - n: avg_similarity
      t: float
      default: '0.0'
    - n: syntax_ok_rate
      t: float
      default: '0.0'
    - n: runs_ok_rate
      t: float
      default: '0.0'
    - n: best_format
      t: str
      default: '""'
    - n: best_score
      t: float
      default: '0.0'
    - n: file_results
      t: List[FileResult]
      factory: list
    - n: function_results
      t: List[FunctionResult]
      factory: list
    - n: format_results
      t: List[FormatResult]
      factory: list
    - n: format_scores
      t: Dict[str, float]
      factory: dict
    - n: provider
      t: str
      default: '""'
    - n: model
      t: str
      default: '""'
    - n: total_time
      t: float
      default: '0.0'
    attrs:
    - n: benchmark_type
      t: str
    - n: timestamp
      t: str
    - n: source_path
      t: str
    - n: total_files
      t: int
    - n: total_functions
      t: int
    - n: avg_score
      t: float
    - n: avg_similarity
      t: float
    - n: syntax_ok_rate
      t: float
    - n: runs_ok_rate
      t: float
    - n: best_format
      t: str
    m:
    - n: __post_init__
      sig: ()
      d: creates init
    - n: calculate_aggregates
      sig: ()
      d: processes aggregates
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
    - n: to_json
      sig: (indent:int=2)
      ret: str
      d: converts json
    - n: save
      sig: (path:str)
      d: caches
    - n: load
      sig: (path:str)
      ret: '''BenchmarkResult'''
      dec:
      - classmethod
      d: retrieves
      classmethod: true
  - n: BenchmarkConfig
    d: Configuration for benchmark runs.
    dec:
    - dataclass
    fields:
    - n: formats
      t: List[str]
      factory: 'lambda: [''yaml'''
    - n: max_files
      t: Optional[int]
      default: None
    - n: max_functions
      t: Optional[int]
      default: None
    - n: max_spec_tokens
      t: int
      default: '5000'
    - n: workers
      t: int
      default: '3'
    - n: output_dir
      t: str
      default: '"benchmark_output"'
    - n: save_generated
      t: bool
      default: 'True'
    - n: verbose
      t: bool
      default: 'False'
    - n: use_llm
      t: bool
      default: 'True'
    - n: max_tokens
      t: int
      default: '4000'
    attrs:
    - n: formats
      t: List[str]
    - n: max_files
      t: Optional[int]
    - n: max_functions
      t: Optional[int]
    - n: max_spec_tokens
      t: int
    - n: workers
      t: int
    - n: output_dir
      t: str
    - n: save_generated
      t: bool
    - n: verbose
      t: bool
    - n: use_llm
      t: bool
    - n: max_tokens
      t: int
    m:
    - n: to_dict
      sig: ()
      ret: Dict[str, Any]
      d: converts dict
  dataclasses:
  - FormatResult
  - FileResult
  - FunctionResult
- p: core/__init__.py
  l: 20
  kb: 0.7
  i:
  - analyzer.{ProjectAnalyzer,analyze_project}
  - dependency.DependencyAnalyzer
  - errors
  - models
- p: formats/__init__.py
  l: 27
  kb: 1.2
  i:
  - generators.{CSVGenerator,CompactGenerator,JSONGenerator,MarkdownGenerator,YAMLGenerator}
  - gherkin.{CucumberYAMLGenerator,GherkinGenerator,StepDefinitionGenerator,csv_to_gherkin,gherkin_to_test_data}
  - logicml.{LogicMLGenerator,LogicMLSpec}
  - markdown_format.{MarkdownHybridGenerator,MarkdownSpec}
  - toon_format.TOONGenerator
- p: tools/__init__.py
  l: 21
  kb: 1.0
  i:
  - benchmark.{BenchmarkResult,FormatResult,ReproductionBenchmark,run_benchmark}
  - code_review.{CodeReviewer,analyze_code_quality,check_performance_issues,check_security_issues}
  - refactor
- p: llm/__init__.py
  l: 28
  kb: 0.8
  i:
  - intent.EnhancedIntentGenerator
  - lolm
  aliases:
    OllamaLocalClient: OllamaClient
- p: integrations/__init__.py
  l: 5
  kb: 0.2
  i:
  - mcp_server.{call_tool,handle_request,run_server}
defaults:
  lang: python
