# LiteLLM Configuration for local Ollama models
# See: https://docs.litellm.ai/docs/proxy/configs

model_list:
  # Code analysis model - Qwen2.5-Coder
  - model_name: code-analyzer
    litellm_params:
      model: ollama/qwen2.5-coder:7b
      api_base: http://localhost:11434

  # General purpose model
  - model_name: general
    litellm_params:
      model: ollama/llama3.2:3b
      api_base: http://localhost:11434

  # Large model for complex tasks
  - model_name: complex
    litellm_params:
      model: ollama/qwen2.5:14b
      api_base: http://localhost:11434

  # Fast model for simple tasks
  - model_name: fast
    litellm_params:
      model: ollama/qwen2.5:1.5b
      api_base: http://localhost:11434

# Router settings
router_settings:
  routing_strategy: simple-shuffle
  num_retries: 3
  timeout: 120

# General settings
general_settings:
  master_key: sk-code2logic-dev
  database_url: ""