# Code2Logic Environment Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM PROVIDERS
# =============================================================================

# OpenRouter (https://openrouter.ai)
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENROUTER_MODEL=qwen/qwen-2.5-coder-32b-instruct

# OpenAI (https://platform.openai.com)
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo

# Anthropic (https://console.anthropic.com)
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Groq (https://console.groq.com)
GROQ_API_KEY=gsk_your-key-here
GROQ_MODEL=llama-3.1-70b-versatile

# Together AI (https://together.ai)
TOGETHER_API_KEY=your-key-here
TOGETHER_MODEL=mistralai/Mixtral-8x7B-Instruct-v0.1

# =============================================================================
# LOCAL LLM
# =============================================================================

# Ollama (local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5-coder:14b

# =============================================================================
# DEFAULT SETTINGS
# =============================================================================

# Default provider: openrouter, openai, anthropic, groq, together, ollama
CODE2LOGIC_DEFAULT_PROVIDER=ollama

# Default model (overrides provider-specific model)
# CODE2LOGIC_DEFAULT_MODEL=

# Verbose logging
CODE2LOGIC_VERBOSE=false

# Cache directory
CODE2LOGIC_CACHE_DIR=~/.code2logic/cache
