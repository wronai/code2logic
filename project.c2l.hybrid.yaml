header:
  project: code2logic
  files: 52
  lines: 21770
  kb: 740.5
  languages:
    python: 52
  modules_count: 52
M:
- llm_profiler.py:491:20.4kb
- config.py:168:7.4kb
- file_formats.py:279:12.3kb
- project_reproducer.py:322:12.2kb
- base.py:50:1.8kb
- cli.py:779:33.1kb
- llm.py:376:14.6kb
- errors.py:372:13.7kb
- code_review.py:205:9.0kb
- analyzer.py:235:9.6kb
- quality.py:212:8.8kb
- shared_utils.py:279:11.6kb
- parsers.py:1473:70.4kb
- intent.py:429:20.5kb
- adaptive.py:475:19.9kb
- reproducer.py:534:22.0kb
- llm_clients.py:415:16.5kb
- prompts.py:120:4.0kb
- chunked_reproduction.py:357:14.2kb
- __init__.py:323:7.7kb
- metrics.py:447:22.7kb
- __main__.py:9:0.2kb
- refactor.py:313:11.4kb
- logicml.py:281:12.8kb
- function_logic.py:71:3.2kb
- utils.py:16:0.6kb
- generators.py:1646:80.4kb
- markdown_format.py:266:13.9kb
- models.py:296:10.6kb
- similarity.py:178:7.8kb
- universal.py:831:39.7kb
- benchmark.py:351:14.4kb
- terminal.py:500:21.6kb
- toon_format.py:541:29.7kb
- dependency.py:187:7.5kb
- mcp_server.py:293:12.2kb
- reproduction.py:333:15.3kb
- gherkin.py:766:35.4kb
- schemas/logicml_schema.py:190:6.7kb
- schemas/__init__.py:25:0.7kb
- schemas/yaml_schema.py:164:6.7kb
- schemas/json_schema.py:206:7.2kb
- schemas/markdown_schema.py:121:4.2kb
- benchmarks/common.py:206:8.5kb
- benchmarks/runner.py:638:27.3kb
- benchmarks/__init__.py:19:0.4kb
- benchmarks/results.py:148:6.3kb
- core/__init__.py:20:0.7kb
- formats/__init__.py:27:1.2kb
- tools/__init__.py:21:1.0kb
- llm/__init__.py:13:0.4kb
- integrations/__init__.py:5:0.2kb
modules:
- p: llm_profiler.py
  l: 491
  kb: 20.4
  i:
  - json
  - os
  - time
  - hashlib
  - datetime
  - dataclasses.{asdict,dataclass,field}
  - difflib.SequenceMatcher
  - pathlib.Path
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - LLMProfile
  - ProfileTestResult
  - LLMProfiler
  - AdaptiveChunker
  - load_profiles
  - save_profile
  - get_profile
  - get_or_create_profile
  - profile_llm
  - get_adaptive_chunker
  const:
  - n: PROFILE_TEST_CASES
    t: Dict
    keys:
    - simple_function
    - class_with_methods
    - async_function
    - decorator_usage
    - complex_logic
  c:
  - n: LLMProfile
    d: Profile of LLM capabilities for code reproduction.
    m:
    - n: __post_init__
      sig: ()
      d: creates init
  - n: ProfileTestResult
    d: Result of a single profile test.
  - n: LLMProfiler
    d: Profile LLM capabilities for code reproduction.
    m:
    - n: __init__
      sig: (client,verbose:bool=True)
      d: Initialize profiler.
    - n: run_profile
      sig: (quick:bool=False)
      ret: LLMProfile
      d: Run full profiling suite.
    - n: _test_reproduction
      sig: (name:str,code:str)
      ret: ProfileTestResult
      d: Test reproduction of a code snippet.
    - n: _code_to_spec
      sig: (code:str)
      ret: str
      d: Convert code to simple YAML spec.
    - n: _extract_code
      sig: (response:str)
      ret: str
      d: Extract code from LLM response.
    - n: _check_syntax
      sig: (code:str)
      ret: bool
      d: Check if code has valid Python syntax.
    - n: _calculate_similarity
      sig: (original:str,reproduced:str)
      ret: float
      d: Calculate code similarity.
    - n: _calculate_metrics
      sig: (profile:LLMProfile,results:List[ProfileTestResult])
      ret: LLMProfile
      d: Calculate aggregate metrics from test results.
    - n: _test_consistency
      sig: (profile:LLMProfile)
      ret: LLMProfile
      d: Test output consistency by running same prompt twice.
  - n: AdaptiveChunker
    d: Adaptive chunking based on LLM profile.
    m:
    - n: __init__
      sig: (profile:Optional[LLMProfile]=None)
      d: Initialize chunker.
    - n: get_optimal_settings
      sig: ()
      ret: Dict[str,Any]
      d: optimal settings for the profiled model.
    - n: chunk_spec
      sig: (spec:str,format:str='yaml')
      ret: List[Dict[str,Any]]
      d: Chunk specification based on profile.
    - n: recommend_format
      sig: (spec_size_tokens:int)
      ret: str
      d: Recommend best format based on spec size and model.
    - n: estimate_chunks_needed
      sig: (spec_size_tokens:int)
      ret: int
      d: Estimate number of chunks needed.
  f:
  - n: _get_profiles_path
    sig: ()
    ret: Path
    d: path to profiles storage.
  - n: load_profiles
    sig: ()
    ret: Dict[str,LLMProfile]
    d: Load all saved profiles.
  - n: save_profile
    sig: (profile:LLMProfile)
    d: Save a profile to storage.
  - n: get_profile
    sig: (provider:str,model:str)
    ret: Optional[LLMProfile]
    d: profile for a specific model.
  - n: get_or_create_profile
    sig: (provider:str,model:str)
    ret: LLMProfile
    d: existing profile or create default one.
  - n: _create_default_profile
    sig: (provider:str,model:str)
    ret: LLMProfile
    d: default profile based on model characteristics.
  - n: profile_llm
    sig: (client,quick:bool=False)
    ret: LLMProfile
    d: Profile an LLM client.
  - n: get_adaptive_chunker
    sig: (provider:str,model:str)
    ret: AdaptiveChunker
    d: adaptive chunker for a model.
- p: config.py
  l: 168
  kb: 7.4
  i:
  - os
  - json
  - pathlib.Path
  - typing.{Any,Dict,Optional}
  e:
  - Config
  - load_env
  - get_api_key
  - get_model
  const:
  - n: SHELL_COMMANDS
    t: str
    v: '''\n# =============================================================================\n# Code2Logic API Configuration
      Co...'
  c:
  - n: Config
    d: Configuration manager for Code2Logic.
    m:
    - n: __init__
      sig: (env_file:str=None)
      d: Initialize configuration.
    - n: _load_env_file
      sig: (env_file:str=None)
      d: Load environment variables from .env file.
    - n: _parse_env_file
      sig: (path:Path)
      d: Parse .env file and set environment variables.
    - n: _load_config_file
      sig: ()
      d: Load configuration from JSON file.
    - n: get_api_key
      sig: (provider:str)
      ret: Optional[str]
      d: API key for a provider.
    - n: get_model
      sig: (provider:str)
      ret: str
      d: model for a provider.
    - n: get_ollama_host
      sig: ()
      ret: str
      d: Ollama host URL.
    - n: get_default_provider
      sig: ()
      ret: str
      d: default LLM provider.
    - n: is_verbose
      sig: ()
      ret: bool
      d: Check if verbose mode is enabled.
    - n: get_cache_dir
      sig: ()
      ret: Path
      d: cache directory path.
  f:
  - n: load_env
    sig: ()
    d: Load environment variables from .env file.
  - n: get_api_key
    sig: (provider:str)
    ret: Optional[str]
    d: Convenience function to get API key.
  - n: get_model
    sig: (provider:str)
    ret: str
    d: Convenience function to get model.
- p: file_formats.py
  l: 279
  kb: 12.3
  i:
  - re
  - json
  - pathlib.Path
  - typing.{Any,Dict,List}
  e:
  - generate_file_csv
  - generate_file_json
  - generate_file_yaml
  f:
  - n: generate_file_csv
    sig: (file_path:Path)
    ret: str
    d: creates file csv
  - n: generate_file_json
    sig: (file_path:Path)
    ret: str
    d: creates file json
  - n: generate_file_yaml
    sig: (file_path:Path)
    ret: str
    d: creates file yaml
  - n: _parse_file_elements
    sig: (content:str)
    ret: Dict[str, Any]
    d: parses file elements
- p: project_reproducer.py
  l: 322
  kb: 12.2
  i:
  - os
  - json
  - hashlib
  - datetime
  - concurrent.futures.{ThreadPoolExecutor,as_completed}
  - dataclasses.{asdict,dataclass,field}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional,Set}
  e:
  - FileResult
  - ProjectResult
  - ProjectReproducer
  - reproduce_project
  const:
  - n: SUPPORTED_EXTENSIONS
    t: Dict
    keys:
    - .py
    - .js
    - .ts
    - .tsx
    - .go
    - .rs
    - .java
    - .sql
    - .cs
  c:
  - n: FileResult
    d: Result for a single file reproduction.
  - n: ProjectResult
    d: Result for project reproduction.
  - n: ProjectReproducer
    d: Multi-file project reproduction system.
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,max_workers:int=4,target_lang:str=None,use_llm:bool=True)
      d: Initialize project reproducer.
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: or create LLM client.
    - n: find_source_files
      sig: (project_path:str,extensions:Set[str]=None,exclude_patterns:List[str]=None)
      ret: List[Path]
      d: Find all source files in project.
    - n: reproduce_file
      sig: (file_path:Path,output_dir:Path)
      ret: FileResult
      d: Reproduce a single file.
    - n: reproduce_project
      sig: (project_path:str,output_dir:str=None,parallel:bool=False)
      ret: ProjectResult
      d: Reproduce entire project.
    - n: _aggregate_results
      sig: (project_path:str,results:List[FileResult])
      ret: ProjectResult
      d: Aggregate file results into project result.
    - n: _save_report
      sig: (output_dir:Path,result:ProjectResult)
      d: Save project reproduction report.
  f:
  - n: reproduce_project
    sig: (project_path:str,output_dir:str=None,target_lang:str=None,parallel:bool=False,use_llm:bool=True)
    ret: ProjectResult
    d: Convenience function for project reproduction.
- p: base.py
  l: 50
  kb: 1.8
  i:
  - logging
  - typing.Optional
  e:
  - VerboseMixin
  - BaseParser
  - BaseGenerator
  c:
  - n: VerboseMixin
    d: Mixin providing verbose logging functionality.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: log
      sig: (msg:str,level:str='info')
      d: logs
    - n: debug
      sig: (msg:str)
      d: debug
    - n: info
      sig: (msg:str)
      d: info
    - n: warn
      sig: (msg:str)
      d: warn
    - n: error
      sig: (msg:str)
      d: error
  - n: BaseParser
    b:
    - VerboseMixin
    d: Base class for code parsers.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: parse
      sig: (content:str,language:str=None)
      d: parses
    - n: parse_file
      sig: (path:str)
      d: parses file
  - n: BaseGenerator
    b:
    - VerboseMixin
    d: Base class for output generators.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project,detail:str='full')
      ret: str
      d: creates
- p: cli.py
  l: 779
  kb: 33.1
  i:
  - argparse
  - os
  - sys
  - subprocess
  - time
  - logging
  - json
  - signal
  - datetime
  - __version__
  e:
  - Colors
  - Logger
  - ensure_dependencies
  - main
  c:
  - n: Colors
  - n: Logger
    d: Enhanced logger for CLI output.
    m:
    - n: __init__
      sig: (verbose:bool=False,debug:bool=False)
      d: creates
    - n: _elapsed
      sig: ()
      ret: str
      d: elapsed
    - n: info
      sig: (msg:str)
      d: info
    - n: success
      sig: (msg:str)
      d: success
    - n: warning
      sig: (msg:str)
      d: warning
    - n: error
      sig: (msg:str)
      d: error
    - n: step
      sig: (msg:str)
      d: step
    - n: detail
      sig: (msg:str)
      d: detail
    - n: debug_msg
      sig: (msg:str)
      d: debug msg
    - n: stats
      sig: (label:str,value)
      d: stats
  f:
  - n: ensure_dependencies
    sig: ()
    d: ensure dependencies
  - n: _get_env_file_path
    sig: ()
    ret: str
    d: retrieves env file path
  - n: _read_text_file
    sig: (path:str)
    ret: str
    d: retrieves text file
  - n: _write_text_file
    sig: (path:str,content:str)
    d: logs text file
  - n: _set_env_var
    sig: (var_name:str,value:str)
    ret: str
    d: updates env var
  - n: _unset_env_var
    sig: (var_name:str)
    ret: str
    d: unset env var
  - n: _get_litellm_config_path
    sig: ()
    ret: str
    d: retrieves litellm config path
  - n: _get_user_llm_config_path
    sig: ()
    ret: str
    d: retrieves user llm config path
  - n: _load_user_llm_config
    sig: ()
    ret: dict
    d: retrieves user llm config
  - n: _save_user_llm_config
    sig: (data:dict)
    ret: str
    d: caches user llm config
  - n: _load_litellm_yaml
    sig: ()
    ret: dict
    d: retrieves litellm yaml
  - n: _save_litellm_yaml
    sig: (data:dict)
    ret: str
    d: caches litellm yaml
- p: llm.py
  l: 376
  kb: 14.6
  i:
  - json
  - os
  - httpx
  - dataclasses.dataclass
  - litellm.completion
  - llm_clients.{BaseLLMClient,LiteLLMClient,OllamaLocalClient,OpenRouterClient,get_client}
  - typing.{Any,Dict,List,Optional}
  e:
  - OllamaClient
  - LiteLLMClient
  - CodeAnalyzer
  - get_available_backends
  c:
  - n: OllamaClient
    d: Direct Ollama API client.
    m:
    - n: __init__
      sig: (config:LLMConfig)
      d: creates
    - n: generate
      sig: (prompt:str,system:Optional[str]=None)
      ret: str
      d: creates
    - n: chat
      sig: (messages:List[Dict[str,str]])
      ret: str
      d: chat
    - n: is_available
      sig: ()
      ret: bool
      d: is available
    - n: list_models
      sig: ()
      ret: List[str]
      d: list models
  - n: LiteLLMClient
    d: LiteLLM client for unified API access.
    m:
    - n: __init__
      sig: (config:LLMConfig)
      d: creates
    - n: generate
      sig: (prompt:str,system:Optional[str]=None)
      ret: str
      d: creates
    - n: chat
      sig: (messages:List[Dict[str,str]])
      ret: str
      d: chat
    - n: is_available
      sig: ()
      ret: bool
      d: is available
  - n: CodeAnalyzer
    d: LLM-powered code analysis for Code2Logic.
    m:
    - n: __init__
      sig: (model:str=None,provider:str=None,base_url:str=None,api_key:str=None)
      d: creates
    - n: is_available
      sig: ()
      ret: bool
      d: is available
    - n: suggest_refactoring
      sig: (project)
      ret: List[Dict[str, Any]]
      d: suggest refactoring
    - n: find_semantic_duplicates
      sig: (project)
      ret: List[Dict[str, Any]]
      d: retrieves semantic duplicates
    - n: generate_code
      sig: (project,target_lang:str,module_filter:Optional[str]=None)
      ret: Dict[str, str]
      d: creates code
    - n: translate_function
      sig: (name:str,signature:str,intent:str,source_lang:str,target_lang:str)
      ret: str
      d: converts function
    - n: _build_signature
      sig: (f)
      ret: str
      d: creates signature
  f:
  - n: get_available_backends
    sig: ()
    ret: Dict[str, bool]
    d: retrieves available backends
  conditional_imports:
  - httpx
  - litellm.completion
- p: errors.py
  l: 372
  kb: 13.7
  i:
  - logging
  - traceback
  - dataclasses.{dataclass,field}
  - enum.Enum
  - pathlib.Path
  - typing.{Any,Callable,Dict,List,Optional}
  e:
  - ErrorSeverity
  - ErrorType
  - ErrorHandler
  - create_error_handler
  c:
  - n: ErrorSeverity
    b:
    - Enum
    values:
    - WARNING="warning"
    - ERROR="error"
    - CRITICAL="critical"
    d: Error severity levels.
  - n: ErrorType
    b:
    - Enum
    values:
    - FILE_NOT_FOUND="file_not_found"
    - PERMISSION_DENIED="permission_denied"
    - FILE_TOO_LARGE="file_too_large"
    - ENCODING_ERROR="encoding_error"
    - SYMLINK_LOOP="symlink_loop"
    - DISK_FULL="disk_full"
    - PATH_TOO_LONG="path_too_long"
    - SYNTAX_ERROR="syntax_error"
    - PARSE_TIMEOUT="parse_timeout"
    - UNSUPPORTED_LANGUAGE="unsupported_language"
    - BINARY_FILE="binary_file"
    - EMPTY_FILE="empty_file"
    - YAML_SERIALIZATION="yaml_serialization"
    - JSON_SERIALIZATION="json_serialization"
    - OUTPUT_WRITE_ERROR="output_write_error"
    - MEMORY_ERROR="memory_error"
    - TIMEOUT="timeout"
    - UNKNOWN="unknown"
    d: Types of errors that can occur during analysis.
  - n: ErrorHandler
    d: Handles errors during analysis with configurable behavior.
    m:
    - n: __init__
      sig: (mode:str='lenient',max_file_size_mb:float=10.0,timeout_seconds:float=30.0,logger:Optional[Any]=None)
      d: creates
    - n: reset
      sig: ()
      d: reset
    - n: handle_error
      sig: (error_type:ErrorType,path:str,message:str,exception:Optional[Exception]=None,severity:Optional[ErrorSeverity]=None)
      ret: bool
      d: handles error
    - n: _default_severity
      sig: (error_type:ErrorType)
      ret: ErrorSeverity
      d: default severity
    - n: _log_error
      sig: (error:AnalysisError)
      d: logs error
    - n: safe_read_file
      sig: (path:Path)
      ret: Optional[str]
      d: safe read file
    - n: safe_write_file
      sig: (path:Path,content:str)
      ret: bool
      d: safe write file
    - n: safe_parse
      sig: (path:str,content:str,parser_func:Callable)
      ret: Any
      d: safe parse
  f:
  - n: create_error_handler
    sig: (mode:str='lenient',max_file_size_mb:float=10.0)
    ret: ErrorHandler
    d: creates error handler
- p: code_review.py
  l: 205
  kb: 9.0
  i:
  - collections.defaultdict
  - typing.{Any,Dict,List}
  e:
  - CodeReviewer
  - analyze_code_quality
  - check_security_issues
  - check_performance_issues
  const:
  - n: SECURITY_PATTERNS
    t: Dict
    keys:
    - sql_injection
    - command_injection
    - path_traversal
    - hardcoded_secrets
    - insecure_random
  - n: PERFORMANCE_PATTERNS
    t: Dict
    keys:
    - n_plus_one
    - large_memory
    - blocking_io
  - n: COMPLEXITY_HIGH
    t: int
    v: '15'
  - n: COMPLEXITY_MEDIUM
    t: int
    v: '10'
  - n: LINES_MAX
    t: int
    v: '50'
  - n: FILE_LINES_MAX
    t: int
    v: '500'
  c:
  - n: CodeReviewer
    d: Automated code review with optional LLM enhancement.
    m:
    - n: __init__
      sig: (client=None)
      d: Initialize reviewer.
    - n: review
      sig: (project,focus:str='all')
      ret: Dict[str,Any]
      d: Perform code review.
    - n: generate_report
      sig: (results:Dict[str,Any],project_name:str='Project')
      ret: str
      d: Generate markdown review report.
  f:
  - n: analyze_code_quality
    sig: (project)
    ret: Dict[str,List[Dict]]
    d: Analyze code quality issues.
  - n: check_security_issues
    sig: (project)
    ret: Dict[str,List[Dict]]
    d: Check for security vulnerabilities.
  - n: check_performance_issues
    sig: (project)
    ret: Dict[str,List[Dict]]
    d: Check for performance anti-patterns.
- p: analyzer.py
  l: 235
  kb: 9.6
  i:
  - sys
  - datetime
  - collections.defaultdict
  - dependency.{DependencyAnalyzer,NETWORKX_AVAILABLE}
  - models.{ModuleInfo,ProjectInfo}
  - parsers.{TREE_SITTER_AVAILABLE,TreeSitterParser,UniversalParser}
  - pathlib.Path
  - similarity.SimilarityDetector
  - typing.{Dict,List,Optional}
  e:
  - ProjectAnalyzer
  - analyze_project
  - get_library_status
  c:
  - n: ProjectAnalyzer
    d: Main class for analyzing software projects.
    m:
    - n: __init__
      sig: (root_path:str,use_treesitter:bool=True,verbose:bool=False,include_private:bool=False)
      d: creates
    - n: _print_status
      sig: ()
      d: logs status
    - n: analyze
      sig: ()
      ret: ProjectInfo
      d: processes
    - n: _scan_files
      sig: ()
      d: scan files
    - n: _detect_entrypoints
      sig: ()
      ret: List[str]
      d: detect entrypoints
    - n: get_statistics
      sig: ()
      ret: Dict
      d: retrieves statistics
  f:
  - n: analyze_project
    sig: (path:str,use_treesitter:bool=True,verbose:bool=False)
    ret: ProjectInfo
    d: processes project
  - n: get_library_status
    sig: ()
    ret: Dict[str, bool]
    d: retrieves library status
- p: quality.py
  l: 212
  kb: 8.8
  i:
  - dataclasses.{dataclass,field}
  - models.{ModuleInfo,ProjectInfo}
  - typing.{Any,Dict,List}
  e:
  - QualityAnalyzer
  - analyze_quality
  - get_quality_summary
  c:
  - n: QualityAnalyzer
    d: Analyzes code quality and generates recommendations.
    m:
    - n: __init__
      sig: (thresholds:Dict[str,int]=None)
      d: creates
    - n: analyze
      sig: (project:ProjectInfo)
      ret: QualityReport
      d: processes
    - n: analyze_modules
      sig: (modules:List[ModuleInfo])
      ret: QualityReport
      d: processes modules
    - n: _analyze_module
      sig: (module:ModuleInfo,report:QualityReport)
      d: processes module
    - n: _check_function
      sig: (func,file_path:str,report:QualityReport)
      d: checks function
    - n: _check_class
      sig: (file_path:str,report:QualityReport)
      d: checks class
    - n: _get_file_recommendation
      sig: (module:ModuleInfo)
      ret: str
      d: retrieves file recommendation
  f:
  - n: analyze_quality
    sig: (project:ProjectInfo,thresholds:Dict[str,int]=None)
    ret: QualityReport
    d: processes quality
  - n: get_quality_summary
    sig: (report:QualityReport)
    ret: str
    d: retrieves quality summary
- p: shared_utils.py
  l: 279
  kb: 11.6
  i:
  - hashlib
  - re
  - typing.{Dict,List,Optional,Set}
  e:
  - compact_imports
  - deduplicate_imports
  - abbreviate_type
  - expand_type
  - build_signature
  - remove_self_from_params
  - categorize_function
  - extract_domain
  - compute_hash
  - truncate_docstring
  const:
  - n: TYPE_ABBREVIATIONS
    t: Dict
    keys:
    - str
    - int
    - bool
    - float
    - None
    - Any
    - List
    - Dict
    - Set
    - Tuple
  - n: CATEGORY_PATTERNS
    t: Dict
    keys:
    - read
    - create
    - update
    - delete
    - validate
    - transform
    - lifecycle
    - communicate
  - n: DOMAIN_KEYWORDS
    t: List
    v: '[''auth'', ''user'', ''order'', ''payment'', ''product'', ''cart'', ''config'', ''util'', ''api'', ''service'', ''model'',
      ''controller'', ''v...'
  f:
  - n: compact_imports
    sig: (imports:List[str],max_items:int=10)
    ret: List[str]
    d: Compact imports by grouping submodules.
  - n: deduplicate_imports
    sig: (imports:List[str])
    ret: List[str]
    d: Remove redundant imports.
  - n: abbreviate_type
    sig: (type_str:str)
    ret: str
    d: Abbreviate type annotations for compactness.
  - n: expand_type
    sig: (abbrev:str)
    ret: str
    d: Expand abbreviated type back to full form.
  - n: build_signature
    sig: (params:List[str],return_type:Optional[str]=None,include_self:bool=False,abbreviate:bool=False,max_params:int=6)
    ret: str
    d: Build compact function signature.
  - n: remove_self_from_params
    sig: (params:List[str])
    ret: List[str]
    d: Remove 'self' and 'cls' from parameter list.
  - n: categorize_function
    sig: (name:str)
    ret: str
    d: Categorize function by name pattern.
  - n: extract_domain
    sig: (path:str)
    ret: str
    d: Extract domain from file path.
  - n: compute_hash
    sig: (name:str,signature:str,length:int=8)
    ret: str
    d: Compute short hash for quick comparison.
  - n: truncate_docstring
    sig: (docstring:Optional[str],max_length:int=60)
    ret: str
    d: Truncate docstring to first sentence or max_length.
  - n: escape_for_yaml
    sig: (text:str)
    ret: str
    d: Escape text for safe YAML inclusion.
  - n: clean_identifier
    sig: (name:str)
    ret: str
    d: Clean identifier by removing whitespace and special characte
- p: parsers.py
  l: 1473
  kb: 70.4
  i:
  - ast
  - re
  - textwrap
  - intent.EnhancedIntentGenerator
  - models
  - typing.{List,Optional}
  e:
  - TreeSitterParser
  - UniversalParser
  - is_tree_sitter_available
  const:
  - n: TREE_SITTER_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: _PyFunctionBodyAnalyzer
    b:
    - NodeVisitor
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: _add_call
      sig: (name:str)
      d: creates call
    - n: _add_raise
      sig: (name:str)
      d: creates raise
    - n: visit_Call
      sig: (node)
      d: visit call
    - n: visit_Raise
      sig: (node)
      d: visit raise
    - n: visit_If
      sig: (node)
      d: visit if
    - n: visit_For
      sig: (node)
      d: visit for
    - n: visit_AsyncFor
      sig: (node)
      d: visit asyncfor
    - n: visit_While
      sig: (node)
      d: visit while
    - n: visit_IfExp
      sig: (node)
      d: visit ifexp
  - n: TreeSitterParser
    d: Parser using Tree-sitter for high-accuracy AST parsing.
    m:
    - n: __init__
      sig: ()
      d: Initialize Tree-sitter parsers for available languages.
    - n: _init_parsers
      sig: ()
      d: Initialize parsers for each supported language.
    - n: is_available
      sig: (language:str)
      ret: bool
      d: Check if Tree-sitter parser is available for a language.
    - n: get_supported_languages
      sig: ()
      ret: List[str]
      dec:
      - classmethod
      d: list of potentially supported languages.
    - n: parse
      sig: (filepath:str,content:str,language:str)
      ret: Optional[ModuleInfo]
      d: Parse a source file using Tree-sitter.
    - n: _parse_python
      sig: (filepath:str,content:str,tree)
      ret: ModuleInfo
      d: Parse Python source using Tree-sitter AST.
    - n: _extract_constants
      sig: (tree,content:str)
      ret: List[ConstantInfo]
      d: Extract module-level UPPERCASE constants.
    - n: _extract_type_checking_imports
      sig: (tree,content:str)
      ret: List[str]
      d: Extract TYPE_CHECKING block imports.
    - n: _extract_conditional_imports
      sig: (node,content:str)
      ret: List[str]
      d: Extract imports from try/except blocks.
    - n: _extract_aliases
      sig: (tree,content:str)
      ret: dict
      d: Extract module aliases (import X as Y).
  - n: UniversalParser
    d: Fallback parser using Python AST and regex.
    m:
    - n: __init__
      sig: ()
      d: Initialize the universal parser.
    - n: parse
      sig: (filepath:str,content:str,language:str)
      ret: Optional[ModuleInfo]
      d: Parse a source file using AST or regex.
    - n: _parse_python
      sig: (filepath:str,content:str)
      ret: Optional[ModuleInfo]
      d: Parse Python using built-in AST.
    - n: _extract_ast_enum
      sig: (node:Any)
      ret: Optional[TypeInfo]
      d: Extract Enum values from Python AST class.
    - n: _extract_ast_function
      sig: (node)
      ret: FunctionInfo
      d: Extract function from Python AST node.
    - n: _extract_ast_class
      sig: (node:Any)
      ret: ClassInfo
      d: Extract class from Python AST node.
    - n: _extract_ast_constant
      sig: (node:Any,content:str)
      ret: Optional[ConstantInfo]
      d: Extract ConstantInfo from an AST assignment node if applicab
    - n: _format_ast_value
      sig: (value_node:Any,content:str)
      ret: str
      d: Best-effort string representation of an AST value node.
    - n: _ann_str
      sig: (node)
      ret: str
      d: Convert AST annotation to string.
    - n: _parse_js_ts
      sig: (filepath:str,content:str,language:str)
      ret: ModuleInfo
      d: Parse JS/TS using regex patterns.
  f:
  - n: _normalize_import_path
    sig: (import_path:str)
    ret: str
    d: Normalize import path by removing duplicate suffix segments.
  - n: _clean_imports
    sig: (imports:List[str])
    ret: List[str]
    d: Deduplicate and normalize import paths while preserving orde
  - n: _combine_import_name
    sig: (module_name:str,identifier:str)
    ret: str
    d: Combine module and identifier while avoiding duplicate suffi
  - n: _truncate_constant_value
    sig: (value_text:str,limit:int=400)
    ret: str
    d: a trimmed single-line snippet for constant values.
  - n: _py_expr_to_dotted_name
    sig: (expr)
    ret: str
    d: py expr to dotted name
  - n: _analyze_python_function_node
    sig: (func_node)
    d: processes python function node
  - n: is_tree_sitter_available
    sig: ()
    ret: bool
    d: Check if Tree-sitter is available.
- p: intent.py
  l: 429
  kb: 20.5
  i:
  - re
  - spacy
  - dataclasses.{dataclass,field}
  - enum.{Enum,auto}
  - nltk.stem.WordNetLemmatizer
  - typing.{Any,List,Optional,TYPE_CHECKING,Tuple}
  e:
  - IntentType
  - EnhancedIntentGenerator
  - IntentAnalyzer
  c:
  - n: IntentType
    b:
    - Enum
    values:
    - REFACTOR=auto()
    - ANALYZE=auto()
    - OPTIMIZE=auto()
    - DEBUG=auto()
    - DOCUMENT=auto()
    - TEST=auto()
    d: Types of user intents for code analysis.
  - n: EnhancedIntentGenerator
    d: Generator intencji z NLP - lemmatyzacja, ekstrakcja z docstring√≥w.
    m:
    - n: __init__
      sig: (lang:str='en')
      d: creates
    - n: generate
      sig: (name:str,docstring:Optional[str]=None)
      ret: str
      d: creates
    - n: _extract_from_docstring
      sig: (docstring:str)
      ret: Optional[str]
      d: parses from docstring
    - n: _split_name
      sig: (name:str)
      ret: List[str]
      d: splits name
    - n: get_available_features
      sig: ()
      ret: dict[str, bool]
      dec:
      - classmethod
      d: retrieves available features
      classmethod: true
  - n: IntentAnalyzer
    d: Analyzes user queries to detect intent and provide suggestions.
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: _extract_keywords
      sig: (query:str)
      ret: List[str]
      d: parses keywords
    - n: _calculate_intent_confidence
      sig: (keywords:List[str],patterns:List[str])
      ret: float
      d: processes intent confidence
    - n: _identify_target
      sig: (query:str,project:Any)
      ret: str
      d: identify target
    - n: _generate_description
      sig: (intent_type:IntentType,target:str)
      ret: str
      d: creates description
    - n: _generate_suggestions
      sig: (intent_type:IntentType,target:str,project:Any)
      ret: List[str]
      d: creates suggestions
    - n: analyze_intent
      sig: (query:str,project:Any)
      ret: List[Intent]
      d: processes intent
    - n: detect_code_smells
      sig: (project:Any)
      ret: List[dict]
      d: detect code smells
    - n: suggest_refactoring
      sig: (target:str,project:Any)
      ret: List[str]
      d: suggest refactoring
    - n: _find_target_object
      sig: (target:str,project:Any)
      ret: Any
      d: retrieves target object
  conditional_imports:
  - nltk
  - nltk.stem.WordNetLemmatizer
  - spacy
- p: adaptive.py
  l: 475
  kb: 19.9
  i:
  - os
  - re
  - dataclasses.dataclass
  - file_formats.{generate_file_csv,generate_file_json}
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - reproduction.{compare_code,extract_code_block}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - ChunkInfo
  - AdaptiveResult
  - AdaptiveReproducer
  - get_llm_capabilities
  const:
  - n: LLM_CAPABILITIES
    t: Dict
    keys:
    - qwen/qwen-2.5-coder-32b-instruct
    - nvidia/nemotron-3-nano-30b-a3b:free
    - meta-llama/llama-3.3-70b-instruct:free
    - deepseek/deepseek-coder-33b-instruct
    - qwen2.5-coder:14b
    - qwen2.5-coder:7b
    - codellama:7b-instruct
    - default
  c:
  - n: ChunkInfo
    d: Information about a code chunk.
  - n: AdaptiveResult
    d: Result of adaptive reproduction.
  - n: AdaptiveReproducer
    d: Adaptive code reproduction with LLM capability detection.
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,model:str=None)
      d: Initialize adaptive reproducer.
    - n: _get_capabilities
      sig: ()
      ret: Dict[str,Any]
      d: LLM capabilities for current model.
    - n: select_format
      sig: (file_path:Path,content:str)
      ret: str
      d: Select optimal format based on file and LLM capabilities.
    - n: should_chunk
      sig: (content:str)
      ret: bool
      d: Determine if content should be chunked.
    - n: chunk_content
      sig: (content:str,file_path:Path)
      ret: List[ChunkInfo]
      d: Split content into logical chunks.
    - n: generate_chunk_spec
      sig: (chunk:ChunkInfo,format_name:str)
      ret: str
      d: Generate specification for a single chunk.
    - n: _gherkin_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: Generate Gherkin for a chunk.
    - n: _yaml_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: Generate YAML for a chunk.
    - n: _json_for_chunk
      sig: (chunk:ChunkInfo)
      ret: str
      d: Generate JSON for a chunk.
    - n: reproduce
      sig: (file_path:str,output_dir:str=None)
      ret: AdaptiveResult
      d: Reproduce code with adaptive format selection.
  f:
  - n: get_llm_capabilities
    sig: (model:str)
    ret: Dict[str,Any]
    d: capabilities for a specific model.
- p: reproducer.py
  l: 534
  kb: 22.0
  i:
  - os
  - yaml
  - json
  - re
  - dataclasses.{dataclass,field}
  - enum.Enum
  - pathlib.Path
  - typing.{Any,Callable,Dict,List,Optional}
  e:
  - ReproductionStatus
  - SpecReproducer
  - SpecValidator
  - reproduce_project
  - validate_files
  c:
  - n: ReproductionStatus
    b:
    - Enum
    values:
    - SUCCESS="success"
    - PARTIAL="partial"
    - FAILED="failed"
    - SKIPPED="skipped"
    d: Status of file reproduction.
  - n: SpecReproducer
    d: Reproduces code structure from logic specifications.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: reproduce_from_yaml
      sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce from yaml
    - n: reproduce_from_json
      sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce from json
    - n: _reproduce
      sig: (spec:Dict[str,Any],output_dir:str,filter_paths:Optional[List[str]]=None)
      ret: ReproductionResult
      d: reproduce
    - n: _generate_file
      sig: (module:Dict[str,Any],output_path:Path)
      ret: bool
      d: creates file
    - n: _generate_python
      sig: (module:Dict[str,Any])
      ret: str
      d: creates python
    - n: _render_docstring
      sig: (text:str,indent:str)
      ret: List[str]
      d: formats docstring
    - n: _sanitize_python_property
      sig: (prop:str)
      ret: str
      d: sanitize python property
    - n: _generate_python_class
      sig: (cls:Dict[str,Any])
      ret: List[str]
      d: creates python class
    - n: _generate_python_method
      sig: (method:Dict[str,Any])
      ret: List[str]
      d: creates python method
  - n: SpecValidator
    d: Validates generated files against logic specification.
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: validate
      sig: (spec_path:str,generated_dir:str,filter_paths:Optional[List[str]]=None)
      ret: List[FileValidation]
      d: validates
    - n: _validate_file
      sig: (module:Dict[str,Any],base_path:Path)
      ret: FileValidation
      d: validates file
    - n: _check_python_syntax
      sig: (content:str,validation:FileValidation)
      ret: bool
      d: checks python syntax
  f:
  - n: reproduce_project
    sig: (spec_path:str,output_dir:str,filter_paths:Optional[List[str]]=None,validate:bool=True,verbose:bool=True)
    ret: ReproductionResult
    d: reproduce project
  - n: validate_files
    sig: (spec_path:str,generated_dir:str,filter_paths:Optional[List[str]]=None)
    ret: List[FileValidation]
    d: validates files
- p: llm_clients.py
  l: 415
  kb: 16.5
  i:
  - os
  - json
  - abc.{ABC,abstractmethod}
  - typing.{Any,Dict,List,Optional}
  e:
  - BaseLLMClient
  - OpenRouterClient
  - OllamaLocalClient
  - LiteLLMClient
  - get_priority_mode
  - get_client
  - get_effective_provider_priorities
  const:
  - n: RECOMMENDED_MODELS
    t: Dict
    keys:
    - openrouter
    - ollama
  - n: DEFAULT_MODELS
    t: Dict
    keys:
    - openrouter
    - openai
    - anthropic
    - groq
    - together
    - ollama
    - litellm
  - n: DEFAULT_PROVIDER_PRIORITIES
    t: Dict
    keys:
    - ollama
    - openrouter
    - groq
    - together
    - openai
    - anthropic
    - litellm
  c:
  - n: BaseLLMClient
    b:
    - ABC
    d: Abstract base class for LLM clients.
    m:
    - n: generate
      sig: (prompt:str,system:str=None,max_tokens:int=4000)
      ret: str
      dec:
      - abstractmethod
      d: Generate completion.
    - n: is_available
      sig: ()
      ret: bool
      dec:
      - abstractmethod
      d: Check if client is available.
    - n: chat
      sig: (messages:List[Dict[str,str]],max_tokens:int=4000)
      ret: str
      d: Chat completion (default implementation).
  - n: OpenRouterClient
    b:
    - BaseLLMClient
    d: OpenRouter API client for cloud LLM access.
    m:
    - n: __init__
      sig: (api_key:str=None,model:str=None)
      d: Initialize OpenRouter client.
    - n: generate
      sig: (prompt:str,system:str=None,max_tokens:int=4000)
      ret: str
      d: Generate completion using OpenRouter.
    - n: is_available
      sig: ()
      ret: bool
      d: Check if OpenRouter is configured.
    - n: list_recommended_models
      sig: ()
      ret: List[tuple]
      dec:
      - staticmethod
      d: List recommended models for code tasks.
      static: true
  - n: OllamaLocalClient
    b:
    - BaseLLMClient
    d: Ollama client for local LLM inference.
    m:
    - n: __init__
      sig: (model:str=None,host:str=None)
      d: Initialize Ollama client.
    - n: generate
      sig: (prompt:str,system:str=None,max_tokens:int=4000)
      ret: str
      d: Generate completion using Ollama.
    - n: is_available
      sig: ()
      ret: bool
      d: Check if Ollama is running.
    - n: list_models
      sig: ()
      ret: List[str]
      d: List available Ollama models.
    - n: list_recommended_models
      sig: ()
      ret: List[tuple]
      dec:
      - staticmethod
      d: List recommended models for code tasks.
      static: true
  - n: LiteLLMClient
    b:
    - BaseLLMClient
    d: LiteLLM client for universal LLM access.
    m:
    - n: __init__
      sig: (model:str=None)
      d: Initialize LiteLLM client.
    - n: generate
      sig: (prompt:str,system:str=None,max_tokens:int=4000)
      ret: str
      d: Generate completion using LiteLLM.
    - n: is_available
      sig: ()
      ret: bool
      d: Check if LiteLLM is available.
  f:
  - n: _get_user_llm_config_path
    sig: ()
    ret: str
    d: retrieves user llm config path
  - n: _load_user_llm_config
    sig: ()
    ret: Dict[str,Any]
    d: retrieves user llm config
  - n: _get_priority_mode
    sig: ()
    ret: str
    d: retrieves priority mode
  - n: get_priority_mode
    sig: ()
    ret: str
    d: retrieves priority mode
  - n: _get_provider_priority_overrides
    sig: ()
    ret: Dict[str,int]
    d: retrieves provider priority overrides
  - n: _get_model_priority_rules
    sig: ()
    ret: Dict[str,Dict[str,int]]
    d: retrieves model priority rules
  - n: _get_model_priority
    sig: (model_string:str)
    ret: Optional[int]
    d: retrieves model priority
  - n: _get_provider_model_string
    sig: (provider:str)
    ret: str
    d: retrieves provider model string
  - n: get_client
    sig: (provider:str=None,model:str=None)
    ret: BaseLLMClient
    d: appropriate LLM client based on provider.
  - n: _try_client
    sig: (provider:str,model:str=None)
    ret: Optional[BaseLLMClient]
    d: try client
  - n: _get_priority_order
    sig: ()
    ret: List[str]
    d: retrieves priority order
  - n: _get_effective_provider_order
    sig: ()
    ret: List[tuple[str,int]]
    d: retrieves effective provider order
- p: prompts.py
  l: 120
  kb: 4.0
  i:
  - typing.Dict
  e:
  - get_reproduction_prompt
  - get_review_prompt
  - get_fix_prompt
  const:
  - n: FORMAT_HINTS
    t: Dict[str,str]
    v: '{''yaml'': "Parse the YAML structure precisely:\n- ''modules'' contains file definitions\n- ''classes'' with ''methods''
      and ...'
  f:
  - n: get_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str,language:str='python',max_spec_length:int=5000)
    ret: str
    d: Generate optimized reproduction prompt.
  - n: get_review_prompt
    sig: (code:str,spec:str,fmt:str)
    ret: str
    d: Generate code review prompt.
  - n: get_fix_prompt
    sig: (code:str,issues:list,spec:str)
    ret: str
    d: Generate code fix prompt.
- p: chunked_reproduction.py
  l: 357
  kb: 14.2
  i:
  - re
  - dataclasses.{dataclass,field}
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo}
  - pathlib.Path
  - typing.{Dict,List,Optional,Tuple}
  - utils.estimate_tokens
  e:
  - Chunk
  - ChunkedSpec
  - ChunkedResult
  - ChunkedReproducer
  - get_llm_limit
  - chunk_yaml_spec
  - chunk_gherkin_spec
  - chunk_markdown_spec
  - chunk_spec
  - get_chunk_prompt
  const:
  - n: LLM_CONTEXT_LIMITS
    t: Dict
    keys:
    - gpt-4
    - gpt-4-turbo
    - gpt-3.5-turbo
    - claude-3
    - claude-2
    - llama-7b
    - llama-13b
    - llama-70b
    - mistral-7b
    - mixtral-8x7b
  c:
  - n: Chunk
    d: A chunk of specification for reproduction.
  - n: ChunkedSpec
    d: Chunked specification.
  - n: ChunkedResult
    d: Result of chunked reproduction.
  - n: ChunkedReproducer
    d: Reproduce code from chunked specifications.
    m:
    - n: __init__
      sig: (client,model_name:str='default')
      d: creates
    - n: reproduce
      sig: (spec:str,fmt:str,file_name:str)
      ret: ChunkedResult
      d: Reproduce code from specification, chunking if needed.
    - n: _extract_code
      sig: (response:str)
      ret: str
      d: Extract code from LLM response.
  f:
  - n: get_llm_limit
    sig: (model_name:str)
    ret: int
    d: context limit for LLM model.
  - n: chunk_yaml_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: Chunk YAML specification by modules/classes/functions.
  - n: chunk_gherkin_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: Chunk Gherkin specification by Features/Scenarios.
  - n: chunk_markdown_spec
    sig: (spec:str,max_tokens:int=2000)
    ret: List[Chunk]
    d: Chunk Markdown specification by sections.
  - n: chunk_spec
    sig: (spec:str,fmt:str,max_tokens:int=2000)
    ret: ChunkedSpec
    d: Chunk specification based on format.
  - n: get_chunk_prompt
    sig: (chunk:Chunk,fmt:str,file_name:str,chunk_num:int,total_chunks:int)
    ret: str
    d: Generate prompt for a single chunk.
  - n: merge_chunk_codes
    sig: (codes:List[str],file_name:str)
    ret: str
    d: Merge code from multiple chunks.
  - n: auto_chunk_reproduce
    sig: (spec:str,fmt:str,file_name:str,client,model_name:str='default')
    ret: ChunkedResult
    d: Auto-chunking reproduction with LLM adaptation.
  - n: adaptive_chunk_reproduce
    sig: (spec:str,fmt:str,file_name:str,client,provider:str='unknown',...+1)
    ret: ChunkedResult
    d: Adaptive chunking reproduction using LLM profile.
- p: __init__.py
  l: 323
  kb: 7.7
  i:
  - analyzer.{ProjectAnalyzer,analyze_project}
  - generators.{CSVGenerator,CompactGenerator,JSONGenerator,MarkdownGenerator,YAMLGenerator}
  - gherkin.{GherkinGenerator,StepDefinitionGenerator}
  - models
  e:
  - analyze_quality
  - reproduce_project
  aliases:
    _reproduce_project_from_source: reproduce_project
    _analyze_quality_from_path: analyze_quality
    _analyze_quality_from_project: analyze_quality
    SpecReproductionResult: ReproductionResult
    _reproduce_project_from_spec: reproduce_project
  f:
  - n: analyze_quality
    sig: (target)
    d: processes quality
  - n: reproduce_project
    sig: (source:str)
    d: reproduce project
- p: metrics.py
  l: 447
  kb: 22.7
  i:
  - re
  - difflib
  - hashlib
  - logging
  - collections.Counter
  - dataclasses.{asdict,dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - ReproductionMetrics
  - analyze_reproduction
  - compare_formats
  c:
  - n: ReproductionMetrics
    d: Analyze reproduction quality with multiple metrics.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: analyze
      sig: (original:str,generated:str,spec:str='',format_name:str='',source_file:str='')
      ret: ReproductionResult
      d: processes
    - n: _compute_text_metrics
      sig: (original:str,generated:str)
      ret: TextMetrics
      d: processes text metrics
    - n: _cosine_similarity
      sig: (words1:List[str],words2:List[str])
      ret: float
      d: cosine similarity
    - n: _compute_structural_metrics
      sig: (original:str,generated:str)
      ret: StructuralMetrics
      d: processes structural metrics
    - n: _compute_semantic_metrics
      sig: (original:str,generated:str)
      ret: SemanticMetrics
      d: processes semantic metrics
    - n: _compute_format_metrics
      sig: (original:str,generated:str,spec:str,format_name:str)
      ret: FormatMetrics
      d: processes format metrics
    - n: _compute_overall_score
      sig: (result:ReproductionResult)
      ret: float
      d: processes overall score
    - n: _get_grade
      sig: (score:float)
      ret: str
      d: retrieves grade
    - n: _generate_recommendations
      sig: (result:ReproductionResult)
      ret: List[str]
      d: creates recommendations
  f:
  - n: analyze_reproduction
    sig: (original:str,generated:str,spec:str='',format_name:str='',verbose:bool=False)
    ret: ReproductionResult
    d: processes reproduction
  - n: compare_formats
    sig: (original:str,results:Dict[str,Tuple[str,str]],verbose:bool=False)
    ret: Dict[str, Any]
    d: compare formats
- p: __main__.py
  l: 9
  kb: 0.2
  i:
  - cli.main
- p: refactor.py
  l: 313
  kb: 11.4
  i:
  - json
  - analyzer.analyze_project
  - code_review.{analyze_code_quality,check_performance_issues,check_security_issues}
  - dataclasses.{asdict,dataclass,field}
  - llm_clients.get_client
  - pathlib.Path
  - similarity.SimilarityDetector
  - typing.{Any,Dict,List,Optional}
  e:
  - find_duplicates
  - analyze_quality
  - suggest_refactoring
  - compare_codebases
  - quick_analyze
  f:
  - n: find_duplicates
    sig: (project_path:str,threshold:float=0.8)
    ret: List[DuplicateGroup]
    d: retrieves duplicates
  - n: analyze_quality
    sig: (project_path:str,include_security:bool=True,include_performance:bool=True)
    ret: RefactoringReport
    d: processes quality
  - n: suggest_refactoring
    sig: (project_path:str,use_llm:bool=False,client:BaseLLMClient=None)
    ret: RefactoringReport
    d: suggest refactoring
  - n: compare_codebases
    sig: (project1:str,project2:str)
    ret: Dict[str, Any]
    d: compare codebases
  - n: quick_analyze
    sig: (project_path:str)
    ret: Dict[str, Any]
    d: quick analyze
- p: logicml.py
  l: 281
  kb: 12.8
  i:
  - dataclasses.dataclass
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo}
  - pathlib.Path
  - shared_utils.{compact_imports,remove_self_from_params,truncate_docstring}
  - typing.{Any,Dict,List,Optional,Set}
  e:
  - LogicMLSpec
  - LogicMLGenerator
  - generate_logicml
  const:
  - n: LOGICML_EXAMPLE
    t: str
    v: '''\n# sample_class.py | Calculator | 74 lines\n\nimports:\n  stdlib: [typing.List, typing.Optional]\n\nCalculator:\n  ...'
  c:
  - n: LogicMLSpec
    d: LogicML specification output.
  - n: LogicMLGenerator
    d: Generates LogicML format - optimized for LLM code reproduction.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: LogicMLSpec
      d: Generate LogicML specification for a project.
    - n: _generate_module
      sig: (module:ModuleInfo,detail:str)
      ret: str
      d: Generate LogicML for a single module.
    - n: _generate_imports
      sig: (imports:List[str])
      ret: str
      d: Generate compact imports section.
    - n: _generate_class
      sig: (cls:ClassInfo,detail:str)
      ret: str
      d: Generate LogicML for a class.
    - n: _generate_method
      sig: (method:FunctionInfo,detail:str,indent:int=2)
      ret: str
      d: Generate LogicML for a method.
    - n: _generate_functions
      sig: (functions:List[FunctionInfo],detail:str)
      ret: str
      d: Generate LogicML for top-level functions.
    - n: _detect_side_effects
      sig: (method:FunctionInfo)
      ret: Optional[str]
      d: Detect side effects from method calls and name patterns.
  f:
  - n: generate_logicml
    sig: (project:ProjectInfo,detail:str='standard')
    ret: str
    d: Convenience function to generate LogicML format.
- p: function_logic.py
  l: 71
  kb: 3.2
  i:
  - models.{FunctionInfo,ProjectInfo}
  - shared_utils.{remove_self_from_params,truncate_docstring}
  - typing.{List,Tuple}
  e:
  - FunctionLogicGenerator
  c:
  - n: FunctionLogicGenerator
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='full')
      ret: str
      d: creates
    - n: _format_function
      sig: (kind:str,qualified_name:str,func:FunctionInfo,detail:str,indent:int)
      ret: List[str]
      d: formats function
- p: utils.py
  l: 16
  kb: 0.6
  i:
  - shutil
  - pathlib.Path
  e:
  - estimate_tokens
  - write_text_atomic
  - cleanup_generated_root
  f:
  - n: estimate_tokens
    sig: (text:str)
    ret: int
    d: estimate tokens
  - n: write_text_atomic
    sig: (path:Path,content:str)
    d: logs text atomic
  - n: cleanup_generated_root
    sig: (generated_root:Path,allowed_dirs:set[str])
    d: cleanup generated root
- p: generators.py
  l: 1646
  kb: 80.4
  i:
  - json
  - collections.defaultdict
  - models
  - pathlib.Path
  - shared_utils.{categorize_function,compute_hash,extract_domain}
  - typing.{List,Optional}
  e:
  - bytes_to_kb
  - MarkdownGenerator
  - CompactGenerator
  - JSONGenerator
  - YAMLGenerator
  - CSVGenerator
  c:
  - n: MarkdownGenerator
    d: Generates Markdown output for project analysis.
    m:
    - n: generate
      sig: (project:ProjectInfo,detail_level:str='standard')
      ret: str
      d: creates
    - n: _gen_tree
      sig: (lines:List[str],project:ProjectInfo)
      d: gen tree
    - n: _print_tree
      sig: (lines:List[str],tree:dict,prefix:str,depth:int=0)
      d: logs tree
    - n: _gen_module
      sig: (lines:List[str],m:ModuleInfo,detail:str,proj:ProjectInfo)
      d: gen module
    - n: _gen_class
      sig: (lines:List[str],cls:ClassInfo,detail:str)
      d: gen class
    - n: _sig
      sig: (f:FunctionInfo)
      ret: str
      d: sig
  - n: CompactGenerator
    d: Generates ultra-compact output for token efficiency.
    m:
    - n: generate
      sig: (project:ProjectInfo)
      ret: str
      d: creates
  - n: JSONGenerator
    d: Generates JSON output for machine processing.
    m:
    - n: generate
      sig: (project:ProjectInfo,flat:bool=False,detail:str='standard')
      ret: str
      d: creates
    - n: generate_from_module
      sig: (module:ModuleInfo,detail:str='full')
      ret: str
      d: creates from module
    - n: _generate_nested
      sig: (project:ProjectInfo,detail:str)
      ret: str
      d: creates nested
    - n: _field_to_dict
      sig: (field:FieldInfo)
      ret: dict
      d: field to dict
    - n: _generate_flat
      sig: (project:ProjectInfo,detail:str)
      ret: str
      d: creates flat
    - n: _build_element_row
      sig: (m:ModuleInfo,elem_type:str,name:str,signature:str,f:FunctionInfo,...+2)
      ret: dict
      d: creates element row
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _compute_hash
      sig: (name:str,signature:str)
      ret: str
      d: processes hash
  - n: YAMLGenerator
    d: Generates YAML output for human-readable representation.
    m:
    - n: generate
      sig: (project:ProjectInfo,flat:bool=False,detail:str='standard',compact:bool=True)
      ret: str
      d: creates
    - n: generate_schema
      sig: (format_type:str='compact')
      ret: str
      d: creates schema
    - n: _generate_compact_schema
      sig: ()
      ret: str
      d: creates compact schema
    - n: _generate_full_schema
      sig: ()
      ret: str
      d: creates full schema
    - n: _generate_hybrid_schema
      sig: ()
      ret: str
      d: creates hybrid schema
    - n: generate_hybrid
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates hybrid
    - n: _build_enhanced_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates enhanced signature
    - n: _extract_constants
      sig: (module:ModuleInfo)
      ret: list
      d: parses constants
    - n: _extract_dataclasses
      sig: (module:ModuleInfo)
      ret: list
      d: parses dataclasses
    - n: _extract_conditional_imports
      sig: (module:ModuleInfo)
      ret: list
      d: parses conditional imports
  - n: CSVGenerator
    d: Generates CSV output optimized for LLM processing.
    m:
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _build_row
      sig: (m:ModuleInfo,elem_type:str,name:str,signature:str,calls:list,...+2)
      ret: dict
      d: creates row
    - n: _build_function_row
      sig: (m:ModuleInfo,elem_type:str,name:str,f:FunctionInfo,deps:str,...+2)
      ret: dict
      d: creates function row
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _compute_hash
      sig: (name:str,signature:str)
      ret: str
      d: processes hash
    - n: _escape_csv
      sig: (text:str)
      ret: str
      d: escape csv
  f:
  - n: bytes_to_kb
    sig: (bytes_value:int)
    ret: float
    d: bytes to kb
- p: markdown_format.py
  l: 266
  kb: 13.9
  i:
  - os
  - dataclasses.dataclass
  - generators.YAMLGenerator
  - gherkin.GherkinGenerator
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo}
  - pathlib.Path
  - typing.{Dict,List,Optional}
  e:
  - MarkdownHybridGenerator
  - generate_markdown_hybrid
  - generate_file_markdown
  c:
  - n: MarkdownHybridGenerator
    d: Generates optimized Markdown hybrid format.
    m:
    - n: __init__
      sig: (verbose:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='full')
      ret: MarkdownSpec
      d: creates
    - n: _generate_header
      sig: (project:ProjectInfo)
      ret: str
      d: creates header
    - n: _generate_tree
      sig: (project:ProjectInfo)
      ret: str
      d: creates tree
    - n: _generate_imports
      sig: (project:ProjectInfo)
      ret: str
      d: creates imports
    - n: _generate_classes_yaml
      sig: (project:ProjectInfo)
      ret: str
      d: creates classes yaml
    - n: _generate_functions_gherkin
      sig: (project:ProjectInfo)
      ret: str
      d: creates functions gherkin
    - n: _generate_dependencies
      sig: (project:ProjectInfo)
      ret: str
      d: creates dependencies
  f:
  - n: generate_markdown_hybrid
    sig: (project:ProjectInfo,detail:str='full')
    ret: str
    d: creates markdown hybrid
  - n: generate_file_markdown
    sig: (file_path:str)
    ret: str
    d: creates file markdown
- p: models.py
  l: 296
  kb: 10.6
  i:
  - dataclasses.{dataclass,field}
  - typing.{Dict,List,Optional}
- p: similarity.py
  l: 178
  kb: 7.8
  i:
  - models.ModuleInfo
  - typing.{Dict,List}
  e:
  - SimilarityDetector
  - is_rapidfuzz_available
  - get_refactoring_suggestions
  const:
  - n: RAPIDFUZZ_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: SimilarityDetector
    d: Detects similar functions using fuzzy string matching.
    m:
    - n: __init__
      sig: (threshold:float=80.0)
      d: Initialize the similarity detector.
    - n: find_similar_functions
      sig: (modules:List[ModuleInfo])
      ret: Dict[str,List[str]]
      d: Find similar functions across all modules.
    - n: find_duplicate_signatures
      sig: (modules:List[ModuleInfo])
      ret: Dict[str,List[str]]
      d: Find functions with identical signatures.
    - n: _build_signature
      sig: (name:str,params:List[str],return_type:str=None)
      ret: str
      d: Build a normalized signature string.
  f:
  - n: is_rapidfuzz_available
    sig: ()
    ret: bool
    d: Check if Rapidfuzz is available.
  - n: get_refactoring_suggestions
    sig: (similar_functions:Dict[str,List[str]])
    ret: List[Dict[str,any]]
    d: Generate refactoring suggestions based on similar functions.
- p: universal.py
  l: 831
  kb: 39.7
  i:
  - os
  - re
  - json
  - hashlib
  - datetime
  - dataclasses.{asdict,dataclass,field}
  - pathlib.Path
  - typing
  e:
  - ElementType
  - Language
  - UniversalParser
  - CodeGenerator
  - UniversalReproducer
  - reproduce_file
  c:
  - n: ElementType
    b:
    - Enum
    values:
    - IMPORT="import"
    - CLASS="class"
    - INTERFACE="interface"
    - STRUCT="struct"
    - FUNCTION="function"
    - METHOD="method"
    - PROPERTY="property"
    - CONSTANT="constant"
    - TYPE_ALIAS="type_alias"
    - ENUM="enum"
    - MODULE="module"
    d: Types of code elements.
  - n: Language
    b:
    - Enum
    values:
    - PYTHON="python"
    - JAVASCRIPT="javascript"
    - TYPESCRIPT="typescript"
    - GO="go"
    - RUST="rust"
    - JAVA="java"
    - CSHARP="csharp"
    - SQL="sql"
    - UNKNOWN="unknown"
    d: Supported languages.
  - n: UniversalParser
    d: Parse source code into universal CodeLogic format.
    m:
    - n: detect_language
      sig: (content:str,file_ext:str)
      ret: Language
      d: detect language
    - n: parse
      sig: (file_path:Union[str,Path])
      ret: CodeLogic
      d: parses
    - n: _parse_python
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses python
    - n: _parse_js_ts
      sig: (path:Path,content:str,hash_:str,lang:Language)
      ret: CodeLogic
      d: parses js ts
    - n: _parse_go
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses go
    - n: _parse_sql
      sig: (path:Path,content:str,hash_:str)
      ret: CodeLogic
      d: parses sql
    - n: _parse_generic
      sig: (path:Path,content:str,hash_:str,lang:Language)
      ret: CodeLogic
      d: parses generic
  - n: CodeGenerator
    d: Generate code from CodeLogic in target language.
    m:
    - n: generate
      sig: (logic:CodeLogic,target_lang:Language)
      ret: str
      d: creates
    - n: _generate_python
      sig: (logic:CodeLogic)
      ret: str
      d: creates python
    - n: _generate_python_element
      sig: (elem:CodeElement,indent:int=0)
      ret: List[str]
      d: creates python element
    - n: _generate_typescript
      sig: (logic:CodeLogic)
      ret: str
      d: creates typescript
    - n: _generate_go
      sig: (logic:CodeLogic)
      ret: str
      d: creates go
    - n: _generate_sql
      sig: (logic:CodeLogic)
      ret: str
      d: creates sql
    - n: _generate_generic
      sig: (logic:CodeLogic,target:Language)
      ret: str
      d: creates generic
  - n: UniversalReproducer
    d: Universal code reproduction system.
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None)
      d: creates
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: retrieves client
    - n: extract_logic
      sig: (file_path:str)
      ret: CodeLogic
      d: parses logic
    - n: reproduce
      sig: (source_path:str,target_lang:str=None,output_dir:str=None,use_llm:bool=True)
      ret: Dict[str, Any]
      d: reproduce
    - n: _generate_with_llm
      sig: (logic:CodeLogic,target:Language)
      ret: str
      d: creates with llm
    - n: _save_result
      sig: (output_dir:Path,original:str,logic:CodeLogic,generated:str,result:Dict[str,Any])
      d: caches result
  f:
  - n: reproduce_file
    sig: (source_path:str,target_lang:str=None,output_dir:str=None,use_llm:bool=True)
    ret: Dict[str, Any]
    d: reproduce file
  conditional_imports:
  - dotenv.load_dotenv
- p: benchmark.py
  l: 351
  kb: 14.4
  i:
  - os
  - json
  - time
  - datetime
  - analyzer.analyze_project
  - dataclasses.{asdict,dataclass}
  - generators.{CompactGenerator,JSONGenerator,MarkdownGenerator}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  e:
  - FormatResult
  - BenchmarkResult
  - ReproductionBenchmark
  - run_benchmark
  const:
  - n: FORMAT_PROMPTS
    t: Dict
    keys:
    - gherkin
    - csv
    - json
    - yaml
    - markdown
  c:
  - n: FormatResult
    d: Result for a single format test.
  - n: BenchmarkResult
    d: Complete benchmark result.
  - n: ReproductionBenchmark
    d: Benchmark reproduction quality across formats.
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None)
      d: Initialize benchmark.
    - n: generate_spec
      sig: (file_path:Path,format_name:str,detail:str='full')
      ret: str
      d: Generate specification in given format.
    - n: reproduce_with_format
      sig: (file_path:Path,format_name:str,original_code:str)
      ret: FormatResult
      d: Test reproduction with a specific format.
    - n: run_single
      sig: (file_path:str,formats:List[str]=None)
      ret: BenchmarkResult
      d: Run benchmark on a single file.
    - n: run_all
      sig: (files:List[str],output_dir:str=None)
      ret: Dict[str,Any]
      d: Run benchmark on multiple files.
    - n: _generate_summary
      sig: (results:List[BenchmarkResult])
      ret: Dict[str,Any]
      d: Generate summary from benchmark results.
    - n: _save_results
      sig: (output_dir:Path,results:List[BenchmarkResult],summary:Dict)
      d: Save benchmark results.
    - n: _generate_report
      sig: (results:List[BenchmarkResult],summary:Dict)
      ret: str
      d: Generate markdown benchmark report.
  f:
  - n: run_benchmark
    sig: (files:List[str],output_dir:str='benchmark_results',provider:str=None,model:str=None)
    ret: Dict[str,Any]
    d: Run reproduction benchmark.
- p: terminal.py
  l: 500
  kb: 21.6
  i:
  - os
  - re
  - sys
  - typing.{Any,Dict,List,Literal,Optional}
  e:
  - ShellRenderer
  - RenderAPI
  - get_renderer
  - set_renderer
  const:
  - n: COLORS
    t: Dict
    keys:
    - reset
    - bold
    - dim
    - italic
    - underline
    - black
    - red
    - green
    - yellow
    - blue
  c:
  - n: ShellRenderer
    d: Renders colorized markdown output in terminal.
    m:
    - n: __init__
      sig: (use_colors:bool=True,verbose:bool=True)
      d: creates
    - n: _supports_colors
      sig: ()
      ret: bool
      d: Check if terminal supports ANSI colors.
    - n: enable_log
      sig: ()
      d: Enable log buffering for markdown export.
    - n: get_log
      sig: ()
      ret: str
      d: buffered log as clean markdown (no ANSI codes).
    - n: clear_log
      sig: ()
      d: Clear log buffer.
    - n: _log
      sig: (text:str)
      d: Log a line (strips ANSI codes for markdown).
    - n: _c
      sig: (color:str,text:str)
      ret: str
      d: Apply color to text.
    - n: heading
      sig: (level:int,text:str)
      d: Print a markdown heading.
    - n: codeblock
      sig: (language:Language,content:str)
      d: Print a syntax-highlighted code block.
    - n: render_markdown
      sig: (text:str)
      d: Render full markdown text with syntax highlighting.
  - n: RenderAPI
    d: Convenience API for terminal rendering.
    m:
    - n: heading
      sig: (level:int,text:str)
      dec:
      - staticmethod
      d: heading
      static: true
    - n: code
      sig: (lang:Language,content:str)
      dec:
      - staticmethod
      d: code
      static: true
    - n: codeblock
      sig: (lang:Language,content:str)
      dec:
      - staticmethod
      d: codeblock
      static: true
    - n: markdown
      sig: (text:str)
      dec:
      - staticmethod
      d: markdown
      static: true
    - n: success
      sig: (message:str)
      dec:
      - staticmethod
      d: success
      static: true
    - n: error
      sig: (message:str)
      dec:
      - staticmethod
      d: error
      static: true
    - n: warning
      sig: (message:str)
      dec:
      - staticmethod
      d: warning
      static: true
    - n: info
      sig: (message:str)
      dec:
      - staticmethod
      d: info
      static: true
    - n: status
      sig: (icon:str,message:str,type:Literal[info,success,warning,error]='info')
      dec:
      - staticmethod
      d: status
      static: true
    - n: kv
      sig: (key:str,value:Any)
      dec:
      - staticmethod
      d: kv
      static: true
  f:
  - n: get_renderer
    sig: (use_colors:bool=True,verbose:bool=True)
    ret: ShellRenderer
    d: or create the global renderer instance.
  - n: set_renderer
    sig: (renderer:ShellRenderer)
    d: the global renderer instance.
- p: toon_format.py
  l: 541
  kb: 29.7
  i:
  - re
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo,TypeInfo}
  - shared_utils.{compact_imports,truncate_docstring}
  - typing.{Any,Dict,List,Optional}
  e:
  - TOONGenerator
  - TOONParser
  - generate_toon
  - parse_toon
  c:
  - n: TOONGenerator
    d: Generates TOON format output from ProjectInfo.
    m:
    - n: __init__
      sig: (delimiter:str=',',use_tabs:bool=False)
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _generate_modules
      sig: (modules:List[ModuleInfo],detail:str)
      ret: List[str]
      d: creates modules
    - n: _generate_types
      sig: (types:List[TypeInfo],indent:int=0)
      ret: List[str]
      d: creates types
    - n: _generate_classes
      sig: (classes:List[ClassInfo],detail:str,indent:int=0)
      ret: List[str]
      d: creates classes
    - n: _generate_methods
      sig: (methods:List[FunctionInfo],detail:str='standard',indent:int=0)
      ret: List[str]
      d: creates methods
    - n: _generate_functions
      sig: (functions:List[FunctionInfo],detail:str,indent:int=0)
      ret: List[str]
      d: creates functions
    - n: _build_signature
      sig: (f:FunctionInfo)
      ret: str
      d: creates signature
    - n: _quote
      sig: (value:Any)
      ret: str
      d: quote
    - n: generate_compact
      sig: (project:ProjectInfo)
      ret: str
      d: creates compact
  - n: TOONParser
    d: Parse TOON format back to Python dict.
    m:
    - n: __init__
      sig: ()
      d: creates
    - n: parse
      sig: (content:str)
      ret: Dict[str, Any]
      d: parses
    - n: _parse_value
      sig: (value:str)
      ret: Any
      d: parses value
  f:
  - n: generate_toon
    sig: (project:ProjectInfo,detail:str='standard',use_tabs:bool=False)
    ret: str
    d: creates toon
  - n: parse_toon
    sig: (content:str)
    ret: Dict[str, Any]
    d: parses toon
- p: dependency.py
  l: 187
  kb: 7.5
  i:
  - models.{DependencyNode,ModuleInfo}
  - pathlib.Path
  - typing.{Dict,List,Optional}
  e:
  - DependencyAnalyzer
  - is_networkx_available
  const:
  - n: NETWORKX_AVAILABLE
    t: bool
    v: 'False'
  c:
  - n: DependencyAnalyzer
    d: Analyzes dependency graphs using NetworkX.
    m:
    - n: __init__
      sig: ()
      d: Initialize the dependency analyzer.
    - n: build_graph
      sig: (modules:List[ModuleInfo])
      ret: Dict[str,List[str]]
      d: Build dependency graph from modules.
    - n: analyze_metrics
      sig: ()
      ret: Dict[str,DependencyNode]
      d: Compute metrics for each node in the graph.
    - n: get_entrypoints
      sig: ()
      ret: List[str]
      d: entry points (nodes with no incoming edges).
    - n: get_hubs
      sig: ()
      ret: List[str]
      d: hub modules (high centrality).
    - n: detect_cycles
      sig: ()
      ret: List[List[str]]
      d: Detect dependency cycles.
    - n: get_strongly_connected_components
      sig: ()
      ret: List[List[str]]
      d: strongly connected components.
    - n: _detect_clusters
      sig: ()
      ret: Dict[str,int]
      d: Detect clusters using connected components.
    - n: _module_name
      sig: (path:str)
      ret: str
      d: Convert file path to module name.
    - n: get_dependency_depth
      sig: (module_path:str)
      ret: int
      d: the maximum depth of dependencies for a module.
  f:
  - n: is_networkx_available
    sig: ()
    ret: bool
    d: Check if NetworkX is available.
- p: mcp_server.py
  l: 293
  kb: 12.2
  i:
  - json
  - sys
  - __version__
  - pathlib.Path
  - typing.Optional
  e:
  - handle_request
  - call_tool
  - run_server
  f:
  - n: handle_request
    sig: (request:dict)
    ret: dict
    d: handles request
  - n: call_tool
    sig: (tool_name:str,arguments:dict)
    ret: str
    d: call tool
  - n: run_server
    sig: ()
    d: starts server
- p: reproduction.py
  l: 333
  kb: 15.3
  i:
  - re
  - difflib
  - datetime
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
  e:
  - generate_file_gherkin
  - compare_code
  - extract_code_block
  - CodeReproducer
  c:
  - n: CodeReproducer
    d: Code reproduction workflow using LLM.
    m:
    - n: __init__
      sig: (client:BaseLLMClient=None,provider:str=None)
      d: creates
    - n: reproduce_file
      sig: (source_path:str,output_dir:str=None)
      ret: Dict[str, Any]
      d: reproduce file
    - n: generate_from_gherkin
      sig: (gherkin:str,language:str='python')
      ret: str
      d: creates from gherkin
    - n: _save_results
      sig: (output_dir:Path,results:Dict[str,Any])
      d: caches results
    - n: _generate_report
      sig: (results:Dict[str,Any])
      ret: str
      d: creates report
  f:
  - n: generate_file_gherkin
    sig: (file_path:Path)
    ret: str
    d: creates file gherkin
  - n: compare_code
    sig: (original:str,generated:str)
    ret: Dict[str, Any]
    d: compare code
  - n: extract_code_block
    sig: (text:str,language:str='python')
    ret: str
    d: parses code block
- p: gherkin.py
  l: 766
  kb: 35.4
  i:
  - re
  - hashlib
  - collections.defaultdict
  - dataclasses.{dataclass,field}
  - models.{ClassInfo,FunctionInfo,ModuleInfo,ProjectInfo}
  - typing.{Any,Dict,List,Optional,Set}
  e:
  - GherkinGenerator
  - StepDefinitionGenerator
  - CucumberYAMLGenerator
  - csv_to_gherkin
  - gherkin_to_test_data
  c:
  - n: GherkinGenerator
    d: Generates Gherkin feature files from code analysis.
    m:
    - n: __init__
      sig: (language:str='en')
      d: creates
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard',group_by:str='domain')
      ret: str
      d: creates
    - n: generate_test_scenarios
      sig: (project:ProjectInfo,group_by:str='domain')
      ret: List[GherkinFeature]
      d: creates test scenarios
    - n: get_step_definitions
      sig: ()
      ret: List[StepDefinition]
      d: retrieves step definitions
    - n: _extract_features
      sig: (project:ProjectInfo,group_by:str)
      ret: List[GherkinFeature]
      d: parses features
    - n: _create_feature
      sig: (group_name:str,items:List[dict],project:ProjectInfo,group_by:str)
      ret: GherkinFeature
      d: creates feature
    - n: _create_scenario
      sig: (category:str,items:List[dict],domain:str)
      ret: GherkinScenario
      d: creates scenario
    - n: _create_edge_case_scenarios
      sig: (category:str,items:List[dict])
      ret: List[GherkinScenario]
      d: creates edge case scenarios
    - n: _create_when_step
      sig: (func:FunctionInfo,verb:str)
      ret: str
      d: creates when step
    - n: _create_background
      sig: (domain:str,items:List[dict])
      ret: Optional[List[str]]
      d: creates background
  - n: StepDefinitionGenerator
    d: Generates step definition stubs from Gherkin features.
    m:
    - n: generate_pytest_bdd
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates pytest bdd
    - n: generate_behave
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates behave
    - n: generate_cucumber_js
      sig: (features:List[GherkinFeature])
      ret: str
      d: creates cucumber js
    - n: _step_to_func_name
      sig: (step:str)
      ret: str
      d: step to func name
  - n: CucumberYAMLGenerator
    d: Generates Cucumber YAML configuration and test data.
    m:
    - n: generate
      sig: (project:ProjectInfo,detail:str='standard')
      ret: str
      d: creates
    - n: _extract_domain
      sig: (path:str)
      ret: str
      d: parses domain
    - n: _categorize
      sig: (name:str)
      ret: str
      d: categorize
  f:
  - n: csv_to_gherkin
    sig: (csv_content:str,language:str='en')
    ret: str
    d: csv to gherkin
  - n: gherkin_to_test_data
    sig: (gherkin_content:str)
    ret: Dict[str, Any]
    d: gherkin to test data
- p: schemas/logicml_schema.py
  l: 190
  kb: 6.7
  i:
  - re
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - validate_logicml
  - parse_logicml_header
  - extract_logicml_signature
  f:
  - n: validate_logicml
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates logicml
  - n: parse_logicml_header
    sig: (line:str)
    ret: Optional[Dict[str, Any]]
    d: parses logicml header
  - n: extract_logicml_signature
    sig: (sig_line:str)
    ret: Dict[str, Any]
    d: parses logicml signature
- p: schemas/__init__.py
  l: 25
  kb: 0.7
  i:
  - json_schema.{JSONSchema,parse_json_spec,validate_json}
  - logicml_schema.{LogicMLSchema,validate_logicml}
  - markdown_schema.{MarkdownSchema,validate_markdown}
  - yaml_schema.{YAMLSchema,validate_yaml}
- p: schemas/yaml_schema.py
  l: 164
  kb: 6.7
  i:
  - yaml
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - validate_yaml
  f:
  - n: validate_yaml
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates yaml
  - n: _validate_module
    sig: (module:Dict,index:int)
    ret: List[str]
    d: validates module
  - n: _validate_class
    sig: (cls:Dict,prefix:str)
    ret: List[str]
    d: validates class
- p: schemas/json_schema.py
  l: 206
  kb: 7.2
  i:
  - json
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - validate_json
  - parse_json_spec
  f:
  - n: validate_json
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates json
  - n: _validate_json_module
    sig: (module:Dict,index:int)
    ret: List[str]
    d: validates json module
  - n: _validate_json_class
    sig: (cls:Dict,prefix:str)
    ret: List[str]
    d: validates json class
  - n: parse_json_spec
    sig: (spec:str)
    ret: Optional[JSONSchema]
    d: parses json spec
- p: schemas/markdown_schema.py
  l: 121
  kb: 4.2
  i:
  - re
  - dataclasses.{dataclass,field}
  - typing.{Any,Dict,List,Optional,Tuple}
  e:
  - validate_markdown
  - extract_markdown_sections
  f:
  - n: validate_markdown
    sig: (spec:str)
    ret: Tuple[bool, List[str]]
    d: validates markdown
  - n: extract_markdown_sections
    sig: (spec:str)
    ret: Dict[str, Any]
    d: parses markdown sections
- p: benchmarks/common.py
  l: 206
  kb: 8.5
  i:
  - datetime
  - json
  - generators.{JSONGenerator,YAMLGenerator}
  - gherkin.GherkinGenerator
  - logicml.LogicMLGenerator
  - markdown_format.MarkdownHybridGenerator
  - models.ProjectInfo
  - pathlib.Path
  - toon_format.TOONGenerator
  e:
  - create_single_project
  - generate_spec
  - generate_spec_token
  - get_async_reproduction_prompt
  - get_token_reproduction_prompt
  - get_simple_reproduction_prompt
  f:
  - n: create_single_project
    sig: (module_info,file_path:Path)
    ret: ProjectInfo
    d: creates single project
  - n: generate_spec
    sig: (project:ProjectInfo,fmt:str)
    ret: str
    d: creates spec
  - n: _generate_token_json
    sig: (project:ProjectInfo)
    ret: str
    d: creates token json
  - n: _generate_token_json_compact
    sig: (project:ProjectInfo)
    ret: str
    d: creates token json compact
  - n: generate_spec_token
    sig: (project:ProjectInfo,fmt:str)
    ret: str
    d: creates spec token
  - n: get_async_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str,with_tests:bool=False)
    ret: str
    d: retrieves async reproduction prompt
  - n: get_token_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str)
    ret: str
    d: retrieves token reproduction prompt
  - n: get_simple_reproduction_prompt
    sig: (spec:str,fmt:str,file_name:str)
    ret: str
    d: retrieves simple reproduction prompt
- p: benchmarks/runner.py
  l: 638
  kb: 27.3
  i:
  - re
  - sys
  - time
  - analyzer.analyze_project
  - concurrent.futures.{ThreadPoolExecutor,as_completed}
  - dataclasses.dataclass
  - llm_clients.{BaseLLMClient,get_client}
  - pathlib.Path
  - typing.{Callable,Dict,List,Optional,Tuple}
  e:
  - BenchmarkRunner
  - run_benchmark
  c:
  - n: BenchmarkRunner
    d: Unified benchmark runner for code2logic.
    m:
    - n: __init__
      sig: (client:Optional[BaseLLMClient]=None,config:Optional[BenchmarkConfig]=None)
      d: creates
    - n: _should_use_llm
      sig: ()
      ret: bool
      d: checks use llm
    - n: _get_client
      sig: ()
      ret: BaseLLMClient
      d: retrieves client
    - n: _template_generate_code
      sig: (spec:str,fmt:str,file_name:str)
      ret: str
      d: template generate code
    - n: run_format_benchmark
      sig: (folder:str,formats:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts format benchmark
    - n: _test_format
      sig: (project,original:str,fmt:str,file_name:str,client:Optional[BaseLLMClient],...+1)
      ret: FormatResult
      d: checks format
    - n: run_file_benchmark
      sig: (file_path:str,formats:List[str]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts file benchmark
    - n: run_function_benchmark
      sig: (file_path:str,function_names:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts function benchmark
    - n: _test_function
      sig: (func,content:str,language:str,file_path:Path,client:Optional[BaseLLMClient],...+1)
      ret: FunctionResult
      d: checks function
    - n: run_project_benchmark
      sig: (project_path:str,formats:List[str]=None,limit:Optional[int]=None,verbose:bool=False)
      ret: BenchmarkResult
      d: starts project benchmark
  f:
  - n: _test_python_syntax
    sig: (code:str)
    ret: bool
    d: checks python syntax
  - n: _test_python_runs
    sig: (code:str,timeout:int=5)
    ret: bool
    d: checks python runs
  - n: _extract_code
    sig: (response:str)
    ret: str
    d: parses code
  - n: run_benchmark
    sig: (source:str,benchmark_type:str='format',formats:List[str]=None,limit:Optional[int]=None,output:Optional[str]=None,...+1)
    ret: BenchmarkResult
    d: starts benchmark
- p: benchmarks/__init__.py
  l: 19
  kb: 0.4
  i:
  - common
  - results.{BenchmarkConfig,BenchmarkResult,FileResult,FormatResult,FunctionResult}
  - runner.{BenchmarkRunner,run_benchmark}
- p: benchmarks/results.py
  l: 148
  kb: 6.3
  i:
  - datetime
  - json
  - dataclasses.{asdict,dataclass,field}
  - pathlib.Path
  - typing.{Any,Dict,List,Optional}
- p: core/__init__.py
  l: 20
  kb: 0.7
  i:
  - analyzer.{ProjectAnalyzer,analyze_project}
  - dependency.DependencyAnalyzer
  - errors
  - models
- p: formats/__init__.py
  l: 27
  kb: 1.2
  i:
  - generators.{CSVGenerator,CompactGenerator,JSONGenerator,MarkdownGenerator,YAMLGenerator}
  - gherkin.{CucumberYAMLGenerator,GherkinGenerator,StepDefinitionGenerator,csv_to_gherkin,gherkin_to_test_data}
  - logicml.{LogicMLGenerator,LogicMLSpec}
  - markdown_format.{MarkdownHybridGenerator,MarkdownSpec}
  - toon_format.TOONGenerator
- p: tools/__init__.py
  l: 21
  kb: 1.0
  i:
  - benchmark.{BenchmarkResult,FormatResult,ReproductionBenchmark,run_benchmark}
  - code_review.{CodeReviewer,analyze_code_quality,check_performance_issues,check_security_issues}
  - refactor
- p: llm/__init__.py
  l: 13
  kb: 0.4
  i:
  - intent.EnhancedIntentGenerator
  - llm_clients.{BaseLLMClient,LiteLLMClient,OllamaLocalClient,OpenRouterClient,get_client}
- p: integrations/__init__.py
  l: 5
  kb: 0.2
  i:
  - mcp_server.{call_tool,handle_request,run_server}
defaults:
  lang: python
