# Code2Logic - Refactoring Plan

## Overview

This document outlines the refactoring tasks identified during code analysis. Tasks are prioritized by impact and effort.

---

## ğŸ”´ High Priority (Immediate)

### 1. Extract Duplicate Functions
**Effort:** Low | **Impact:** High

Multiple `main()` functions with identical signatures across files:
- `code2logic/cli.py::main`
- `examples/refactor_suggestions.py::main`
- `examples/token_efficiency.py::main`
- `examples/quick_start.py::main`
- `examples/generate_code.py::main`
- `examples/duplicate_detection.py::main`

**Action:** This is acceptable for CLI entry points - no action needed.

---

### 2. Consolidate LLM Client Classes
**Effort:** Medium | **Impact:** High

`OllamaClient` and `LiteLLMClient` have duplicate methods:
- `__init__`
- `generate`
- `chat`
- `is_available`

**Action:** Create abstract `BaseLLMClient` class:

```python
from abc import ABC, abstractmethod

class BaseLLMClient(ABC):
    def __init__(self, model: str, host: str = None):
        self.model = model
        self.host = host
    
    @abstractmethod
    def generate(self, prompt: str, system: str = None) -> str:
        pass
    
    @abstractmethod
    def chat(self, messages: List[Dict]) -> str:
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        pass
```

**Files:** `code2logic/llm.py`

---

### 3. Consolidate Parser Init Methods
**Effort:** Low | **Impact:** Medium

`TreeSitterParser`, `UniversalParser`, and `DependencyAnalyzer` have similar `__init__`:

```python
def __init__(self, verbose: bool = False):
    self.verbose = verbose
```

**Action:** Create mixin or base class:

```python
class VerboseMixin:
    def __init__(self, verbose: bool = False):
        self.verbose = verbose
    
    def log(self, msg: str):
        if self.verbose:
            print(f"[{self.__class__.__name__}] {msg}")
```

**Files:** `code2logic/parsers.py`, `code2logic/dependency.py`

---

## ğŸŸ¡ Medium Priority (Short-term)

### 4. Split Long Files
**Effort:** Medium | **Impact:** Medium

Files exceeding 500 lines:
- `code2logic/generators.py` (1017 lines) - Split into separate generator modules
- `code2logic/gherkin.py` (975 lines) - Extract step definitions
- `code2logic/parsers.py` (908 lines) - Split by language

**Action:** Create subpackages:

```
code2logic/
â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ markdown.py
â”‚   â”œâ”€â”€ json.py
â”‚   â”œâ”€â”€ yaml.py
â”‚   â”œâ”€â”€ csv.py
â”‚   â””â”€â”€ compact.py
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ treesitter.py
â”‚   â””â”€â”€ fallback.py
â””â”€â”€ gherkin/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ generator.py
    â”œâ”€â”€ steps.py
    â””â”€â”€ cucumber.py
```

---

### 5. Refactor Long Functions
**Effort:** Medium | **Impact:** Medium

Functions exceeding 50 lines:
- `generators.py::MarkdownGenerator._generate_module_section` (85 lines)
- `gherkin.py::GherkinGenerator._categorize_functions` (72 lines)
- `parsers.py::TreeSitterParser._parse_python_function` (68 lines)

**Action:** Extract helper methods for each logical block.

---

### 6. Add Type Hints
**Effort:** Low | **Impact:** Medium

Several functions lack complete type annotations. Run mypy and fix:

```bash
mypy code2logic --strict
```

---

### 7. Improve Test Coverage
**Effort:** Medium | **Impact:** High

Current coverage: ~31%

Priority areas:
- `code2logic/generators.py` (40% coverage)
- `code2logic/gherkin.py` (10% coverage)
- `code2logic/parsers.py` (18% coverage)
- `code2logic/llm.py` (0% coverage)
- `code2logic/cli.py` (0% coverage)

**Target:** 80% coverage

---

## ğŸŸ¢ Low Priority (Long-term)

### 8. Large Classes (SRP Violation)
**Effort:** High | **Impact:** Medium

Classes with >20 methods:
- `GherkinGenerator` (24 methods)
- `MarkdownGenerator` (18 methods)

**Action:** Consider splitting by responsibility:
- `GherkinGenerator` â†’ `GherkinParser`, `GherkinFormatter`, `GherkinWriter`

---

### 9. Signature Duplicates
**Effort:** Low | **Impact:** Low

17 groups of functions with identical signatures but different names.

**Action:** Review for potential generic implementations.

---

### 10. Documentation Improvements
**Effort:** Low | **Impact:** Medium

- [ ] Add docstrings to all public functions
- [ ] Add usage examples to README
- [ ] Create API reference docs
- [ ] Add architecture diagrams

---

### 11. Performance Optimization
**Effort:** Medium | **Impact:** Low

- [ ] Profile large codebases (>500 files)
- [ ] Consider parallel file parsing
- [ ] Add caching for repeated analyses
- [ ] Optimize regex patterns in fallback parser

---

### 12. Error Handling
**Effort:** Medium | **Impact:** Medium

- [ ] Add custom exception classes
- [ ] Improve error messages
- [ ] Add recovery mechanisms for parse failures
- [ ] Log warnings for unsupported syntax

---

## ğŸ“‹ Task Checklist

### Immediate (Week 1)
- [x] Create `BaseLLMClient` abstract class (Done: llm_clients.py)
- [x] Create `VerboseMixin` for common init (Done: metrics.py)
- [x] Consolidate examples (19 â†’ 6 files)
- [x] Add advanced metrics system (metrics.py)
- [x] Add refactoring utilities (refactor.py)
- [x] Add universal reproduction (universal.py)
- [x] Add project reproduction (project_reproducer.py)
- [ ] Fix remaining test failures
- [ ] Update CHANGELOG

### Short-term (Week 2-3)
- [ ] Split `generators.py` into subpackage
- [ ] Split `parsers.py` into subpackage
- [ ] Refactor long functions
- [ ] Add missing type hints

### Long-term (Month 1-2)
- [ ] Increase test coverage to 80%
- [ ] Split `gherkin.py` into subpackage
- [ ] Add comprehensive documentation
- [ ] Performance optimization

---

## ğŸ“Š Metrics to Track

| Metric | Current | Target |
|--------|---------|--------|
| Test Coverage | 31% | 80% |
| Duplicate Groups | 17 | 5 |
| Long Files (>500) | 3 | 0 |
| Long Functions (>50) | 21 | 5 |
| Large Classes (>20 methods) | 2 | 0 |
| mypy Errors | ? | 0 |

---

## ğŸ”§ Development Commands

```bash
# Run tests with coverage
make test-cov

# Run linter
make lint

# Run type checker
mypy code2logic --strict

# Find duplicates
python examples/duplicate_detection.py .

# Analyze refactoring needs
python examples/refactor_suggestions.py . --no-llm
```

---

## Notes

- All changes should maintain backward compatibility
- Each refactoring should have corresponding tests
- Update documentation after each change
- Use feature branches for large refactorings




celem projektu jest moÅ¼liwoÅ›c wygenerowania poÅ›redniego formatu, ktory bÄ™dzie przechowywaÅ‚ logikÄ™ w taki sposob, by reprodukcja
pozwalaÅ‚a na zachowanie bazowych wÅ‚aÅ›ciwoÅ›ci kodu, w taki sposob, aby dziaÅ‚aÅ‚poprawnie, aby moÅ¼liwe byÅ‚o odtworzenie tysiÄ™cy plikÃ³w z zzachowaniem funkcjonalnoÅ›ci, miarÄ… efektywnosci jest iloÅ›Ä‡ bajtÃ³w potrzebnych  do rpzechowania logiki w stosunku do bajtÃ³w zajmowanego kodu, czym mniejszy jest pliki reprezntuajÄ…cy logikÄ™ w stosunku do wielkoÅ›ci pliku wygenerowanego na jego podstawie tym bardziej efektywne  jest przechowywanie  logiki, 
trzeba jednak sprawdzaÄ‡ czy model LLM jest w stanie sobie z tym poradziÄ‡, dlatego trzeba teÅ¼ w oparciu o uÅ¼ywany LLM do preprodukcji uuÅ¼yÄ‡ innej formy, stworz rozwiÄ…zanie, ktore bÄ™dzie badaÅ‚o moÅ¼liwoÅ›ci LLM i dopasowywaÅ‚o format i typ przechowania logiki aby unikknÄ…Ä‡ problemÃ³w przy niespojnosci regeneracji kodu z logiki
dodatkowo sprawdz jakie optymalizacje moÅ¼na zastosowaÄ‡, aby przy mniejszych modelach generowaÄ‡ mniejsze fragmenty  logiki zamiast wszystko na raz z uwagi na ograniczenia LLM, ale rob to automatycznie na bazie danych LLM i logiki  rpzechowywanej w pliku

kontynuuj, dodaj wiÄ™cej przykladow  kodu, do testow reprodukcji, aby reprodukowac z dowolnego jÄ™zyka do dowolnego jÄ™zyka, rowniez z jÄ™zykow DSL jak SQL, przetestuj i popraw jakoÅ›Ä‡ reprodukcji code2logic, sparwdz czy sÄ… inne  dodatkowe biblitoeki, ktore mogÄ… pomÃ³c w  lepszej regenracji, czy sÄ… jakieÅ› lepsze biblitoeki, ktore uÅ‚atwiajÄ… reprodukcje kodu niezaleznie od jezyka programowania

prztetsuj z benchmarkiem wszystkie testowe przypadki i kontynuuj improvement, do uzysklania lepszych rezultatow dla kazdego przykladu
